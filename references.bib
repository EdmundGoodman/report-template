
@article{woodruff_cheri_2019,
	title = {{CHERI} Concentrate: Practical Compressed Capabilities},
	volume = {68},
	issn = {1557-9956},
	url = {https://ieeexplore.ieee.org/abstract/document/8703061},
	doi = {10.1109/TC.2019.2914037},
	shorttitle = {{CHERI} Concentrate},
	abstract = {We present {CHERI} Concentrate, a new fat-pointer compression scheme applied to {CHERI}, the most developed capability-pointer system at present. Capability fat pointers are a primary candidate to enforce fine-grained and non-bypassable security properties in future computer systems, although increased pointer size can severely affect performance. Thus, several proposals for capability compression have been suggested elsewhere that do not support legacy instruction sets, ignore features critical to the existing software base, and also introduce design inefficiencies to {RISC}-style processor pipelines. {CHERI} Concentrate improves on the state-of-the-art region-encoding efficiency, solves important pipeline problems, and eases semantic restrictions of compressed encoding, allowing it to protect a full legacy software stack. We present the first quantitative analysis of compiled capability code, which we use to guide the design of the encoding format. We analyze and extend logic from the open-source {CHERI} prototype processor design on {FPGA} to demonstrate encoding efficiency, minimize delay of pointer arithmetic, and eliminate additional load-to-use delay. To verify correctness of our proposed high-performance logic, we present a {HOL}4 machine-checked proof of the decode and pointer-modify operations. Finally, we measure a 50 to 75 percent reduction in L2 misses for many compiled C-language benchmarks running under a commodity operating system using compressed 128-bit and 64-bit formats, demonstrating both compatibility with and increased performance over the uncompressed, 256-bit format.},
	pages = {1455--1469},
	number = {10},
	journaltitle = {{IEEE} Transactions on Computers},
	author = {Woodruff, Jonathan and Joannou, Alexandre and Xia, Hongyan and Fox, Anthony and Norton, Robert M. and Chisnall, David and Davis, Brooks and Gudka, Khilan and Filardo, Nathaniel W. and Markettos, A. Theodore and Roe, Michael and Neumann, Peter G. and Watson, Robert N. M. and Moore, Simon W.},
	urldate = {2024-11-15},
	date = {2019-10},
	note = {Conference Name: {IEEE} Transactions on Computers},
	keywords = {Capabilities, Delays, Encoding, Pipelines, Registers, Safety, Semantics, Software, compression, computer architecture, fat pointers, memory safety},
}

@inproceedings{wesley_filardo_cornucopia_2020,
	title = {Cornucopia: Temporal Safety for {CHERI} Heaps},
	url = {https://ieeexplore.ieee.org/abstract/document/9152640},
	doi = {10.1109/SP40000.2020.00098},
	shorttitle = {Cornucopia},
	abstract = {Use-after-free violations of temporal memory safety continue to plague software systems, underpinning many high-impact exploits. The {CHERI} capability system shows great promise in achieving C and C++ language spatial memory safety, preventing out-of-bounds accesses. Enforcing language-level temporal safety on {CHERI} requires capability revocation, traditionally achieved either via table lookups (avoided for performance in the {CHERI} design) or by identifying capabilities in memory to revoke them (similar to a garbage-collector sweep). {CHERIvoke}, a prior feasibility study, suggested that {CHERI}'s tagged capabilities could make this latter strategy viable, but modeled only architectural limits and did not consider the full implementation or evaluation of the approach.Cornucopia is a lightweight capability revocation system for {CHERI} that implements non-probabilistic C/C++ temporal memory safety for standard heap allocations. It extends the {CheriBSD} virtual-memory subsystem to track capability flow through memory and provides a concurrent kernel-resident revocation service that is amenable to multi-processor and hardware acceleration. We demonstrate an average overhead of less than 2\% and a worst-case of 8.9\% for concurrent revocation on compatible {SPEC} {CPU}2006 benchmarks on a multi-core {CHERI} {CPU} on {FPGA}, and we validate Cornucopia against the Juliet test suite's corpus of temporally unsafe programs. We test its compatibility with a large corpus of C programs by using a revoking allocator as the system allocator while booting multi-user {CheriBSD}. Cornucopia is a viable strategy for always-on temporal heap memory safety, suitable for production environments.},
	eventtitle = {2020 {IEEE} Symposium on Security and Privacy ({SP})},
	pages = {608--625},
	booktitle = {2020 {IEEE} Symposium on Security and Privacy ({SP})},
	author = {Wesley Filardo, Nathaniel and Gutstein, Brett F. and Woodruff, Jonathan and Ainsworth, Sam and Paul-Trifu, Lucian and Davis, Brooks and Xia, Hongyan and Tomasz Napierala, Edward and Richardson, Alexander and Baldwin, John and Chisnall, David and Clarke, Jessica and Gudka, Khilan and Joannou, Alexandre and Theodore Markettos, A. and Mazzinghi, Alfredo and Norton, Robert M. and Roe, Michael and Sewell, Peter and Son, Stacey and Jones, Timothy M. and Moore, Simon W. and Neumann, Peter G. and Watson, Robert N. M.},
	urldate = {2024-11-15},
	date = {2020-05},
	note = {{ISSN}: 2375-1207},
	keywords = {Integrated circuits, Licenses, Privacy, {RNA}, Security},
}

@report{watson_capability_2023,
	title = {Capability Hardware Enhanced {RISC} Instructions: {CHERI} Instruction-Set Architecture (Version 9)},
	url = {https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-987.html},
	shorttitle = {Capability Hardware Enhanced {RISC} Instructions},
	number = {{UCAM}-{CL}-{TR}-987},
	institution = {University of Cambridge, Computer Laboratory},
	author = {Watson, Robert N. M. and Neumann, Peter G. and Woodruff, Jonathan and Roe, Michael and Almatary, Hesham and Anderson, Jonathan and Baldwin, John and Barnes, Graeme and Chisnall, David and Clarke, Jessica and Davis, Brooks and Eisen, Lee and Filardo, Nathaniel Wesley and Fuchs, Franz A. and Grisenthwaite, Richard and Joannou, Alexandre and Laurie, Ben and Markettos, A. Theodore and Moore, Simon W. and Murdoch, Steven J. and Nienhuis, Kyndylan and Norton, Robert and Richardson, Alexander and Rugg, Peter and Sewell, Peter and Son, Stacey and Xia, Hongyan},
	urldate = {2024-11-15},
	date = {2023},
	langid = {english},
	doi = {10.48456/tr-987},
}

@inproceedings{xia_cherivoke_2019,
	location = {New York, {NY}, {USA}},
	title = {{CHERIvoke}: Characterising Pointer Revocation using {CHERI} Capabilities for Temporal Memory Safety},
	isbn = {978-1-4503-6938-1},
	url = {https://dl.acm.org/doi/10.1145/3352460.3358288},
	doi = {10.1145/3352460.3358288},
	series = {{MICRO} '52},
	shorttitle = {{CHERIvoke}},
	abstract = {A lack of temporal safety in low-level languages has led to an epidemic of use-after-free exploits. These have surpassed in number and severity even the infamous buffer-overflow exploits violating spatial safety. Capability addressing can directly enforce spatial safety for the C language by enforcing bounds on pointers and by rendering pointers unforgeable. Nevertheless, an efficient solution for strong temporal memory safety remains elusive.{CHERI} is an architectural extension to provide hardware capability addressing that is seeing significant commercial and open-source interest. We show that {CHERI} capabilities can be used as a foundation to enable low-cost heap temporal safety by facilitating out-of-date pointer revocation, as capabilities enable precise and efficient identification and invalidation of pointers, even when using unsafe languages such as C. We develop {CHERIvoke}, a technique for deterministic and fast sweeping revocation to enforce temporal safety on {CHERI} systems. {CHERIvoke} quarantines freed data before periodically using a small shadow map to revoke all dangling pointers in a single sweep of memory, and provides a tunable trade-off between performance and heap growth. We evaluate the performance of such a system using high-performance x86 processors, and further analytically examine its primary overheads. When configured with a heap-size overhead of 25\%, we find that {CHERIvoke} achieves an average execution-time overhead of under 5\%, far below the overheads associated with traditional garbage collection, revocation, or page-table systems.},
	pages = {545--557},
	booktitle = {Proceedings of the 52nd Annual {IEEE}/{ACM} International Symposium on Microarchitecture},
	publisher = {Association for Computing Machinery},
	author = {Xia, Hongyan and Woodruff, Jonathan and Ainsworth, Sam and Filardo, Nathaniel W. and Roe, Michael and Richardson, Alexander and Rugg, Peter and Neumann, Peter G. and Moore, Simon W. and Watson, Robert N. M. and Jones, Timothy M.},
	urldate = {2024-11-15},
	date = {2019-10-12},
}

@inproceedings{joannou_efficient_2017,
	title = {Efficient Tagged Memory},
	url = {https://ieeexplore.ieee.org/abstract/document/8119285},
	doi = {10.1109/ICCD.2017.112},
	abstract = {We characterize the cache behavior of an in-memory tag table and demonstrate that an optimized implementation can typically achieve a near-zero memory traffic overhead. Both industry and academia have repeatedly demonstrated tagged memory as a key mechanism to enable enforcement of powerful security invariants, including capabilities, pointer integrity, watchpoints, and information-flow tracking. A single-bit tag shadowspace is the most commonly proposed requirement, as one bit is the minimum metadata needed to distinguish between an untyped data word and any number of new hardware-enforced types. We survey various tag shadowspace approaches and identify their common requirements and positive features of their implementations. To avoid non-standard memory widths, we identify the most practical implementation for tag storage to be an in-memory table managed next to the {DRAM} controller. We characterize the caching performance of such a tag table and demonstrate a {DRAM} traffic overhead below 5\% for the vast majority of applications. We identify spatial locality on a page scale as the primary factor that enables surprisingly high table cache-ability. We then demonstrate tag-table compression for a set of common applications. A hierarchical structure with elegantly simple optimizations reduces {DRAM} traffic overhead to below 1\% for most applications. These insights and optimizations pave the way for commercial applications making use of single-bit tags stored in commodity memory.},
	eventtitle = {2017 {IEEE} International Conference on Computer Design ({ICCD})},
	pages = {641--648},
	booktitle = {2017 {IEEE} International Conference on Computer Design ({ICCD})},
	author = {Joannou, Alexandre and Woodruff, Jonathan and Kovacsics, Robert and Moore, Simon W. and Bradbury, Alex and Xia, Hongyan and Watson, Robert N.M. and Chisnall, David and Roe, Michael and Davis, Brooks and Napierala, Edward and Baldwin, John and Gudka, Khilan and Neumann, Peter G. and Mazzinghi, Alfredo and Richardson, Alex and Son, Stacey and Markettos, A. Theodore},
	urldate = {2024-11-15},
	date = {2017-11},
	note = {{ISSN}: 1063-6404},
	keywords = {Caches, Computer architecture, Error correction codes, Hardware, Memory, Metadata, Pipelines, Processor, Random access memory, Safety, Security},
}

@article{grisenthwaite_arm_2023,
	title = {The Arm Morello Evaluation Platform—Validating {CHERI}-Based Security in a High-Performance System},
	volume = {43},
	issn = {1937-4143},
	url = {https://ieeexplore.ieee.org/document/10123148},
	doi = {10.1109/MM.2023.3264676},
	abstract = {Memory safety issues are a persistent source of security vulnerabilities, with conventional architectures and the C/C++ codebase chronically prone to exploitable errors. The Capability Hardware Enhanced {RISC} Instructions ({CHERI}) research project has explored a novel architectural approach to ameliorate such issues using unforgeable hardware capabilities to implement pointers. Morello is an Arm experimental platform for evaluation of {CHERI} in the Arm architecture context to explore its potential for mass-market adoption. This article describes the Morello Evaluation Platform, covering the motivation and functionality of the Morello architectural hardware extensions; their potential for fine-grained memory safety and software compartmentalization; formally proven security properties; impact on the microarchitecture of the high-performance, out-of-order multiprocessor Arm Morello processor; and the software-enablement program by Arm, the University of Cambridge, and Linaro. Together, this allows a wide range of researchers in both industry and academia to explore and assess the Morello platform.},
	pages = {50--57},
	number = {3},
	journaltitle = {{IEEE} Micro},
	author = {Grisenthwaite, Richard and Barnes, Graeme and Watson, Robert N. M. and Moore, Simon W. and Sewell, Peter and Woodruff, Jonathan},
	urldate = {2024-11-15},
	date = {2023-05},
	note = {Conference Name: {IEEE} Micro},
	keywords = {Architecture, Computer architecture, Computer security, Ecosystems, Memory, Microarchitecture, Performance evaluation, Reduced instruction set computing, Safety},
}

@inproceedings{davoodi2019tensorrt,
	title = {{TensorRT} inference with {TensorFlow}},
	booktitle = {{GPU} technology conference},
	author = {Davoodi, Pooya and Gwon, Chul and Lai, Guangda and Morris, Trevor},
	date = {2019},
}

@misc{jouppi_-datacenter_2017,
	title = {In-Datacenter Performance Analysis of a Tensor Processing Unit},
	url = {http://arxiv.org/abs/1704.04760},
	doi = {10.48550/arXiv.1704.04760},
	abstract = {Many architects believe that major improvements in cost-energy-performance must now come from domain-specific hardware. This paper evaluates a custom {ASIC}---called a Tensor Processing Unit ({TPU})---deployed in datacenters since 2015 that accelerates the inference phase of neural networks ({NN}). The heart of the {TPU} is a 65,536 8-bit {MAC} matrix multiply unit that offers a peak throughput of 92 {TeraOps}/second ({TOPS}) and a large (28 {MiB}) software-managed on-chip memory. The {TPU}'s deterministic execution model is a better match to the 99th-percentile response-time requirement of our {NN} applications than are the time-varying optimizations of {CPUs} and {GPUs} (caches, out-of-order execution, multithreading, multiprocessing, prefetching, ...) that help average throughput more than guaranteed latency. The lack of such features helps explain why, despite having myriad {MACs} and a big memory, the {TPU} is relatively small and low power. We compare the {TPU} to a server-class Intel Haswell {CPU} and an Nvidia K80 {GPU}, which are contemporaries deployed in the same datacenters. Our workload, written in the high-level {TensorFlow} framework, uses production {NN} applications ({MLPs}, {CNNs}, and {LSTMs}) that represent 95\% of our datacenters' {NN} inference demand. Despite low utilization for some applications, the {TPU} is on average about 15X - 30X faster than its contemporary {GPU} or {CPU}, with {TOPS}/Watt about 30X - 80X higher. Moreover, using the {GPU}'s {GDDR}5 memory in the {TPU} would triple achieved {TOPS} and raise {TOPS}/Watt to nearly 70X the {GPU} and 200X the {CPU}.},
	number = {{arXiv}:1704.04760},
	publisher = {{arXiv}},
	author = {Jouppi, Norman P. and Young, Cliff and Patil, Nishant and Patterson, David and Agrawal, Gaurav and Bajwa, Raminder and Bates, Sarah and Bhatia, Suresh and Boden, Nan and Borchers, Al and Boyle, Rick and Cantin, Pierre-luc and Chao, Clifford and Clark, Chris and Coriell, Jeremy and Daley, Mike and Dau, Matt and Dean, Jeffrey and Gelb, Ben and Ghaemmaghami, Tara Vazir and Gottipati, Rajendra and Gulland, William and Hagmann, Robert and Ho, C. Richard and Hogberg, Doug and Hu, John and Hundt, Robert and Hurt, Dan and Ibarz, Julian and Jaffey, Aaron and Jaworski, Alek and Kaplan, Alexander and Khaitan, Harshit and Koch, Andy and Kumar, Naveen and Lacy, Steve and Laudon, James and Law, James and Le, Diemthu and Leary, Chris and Liu, Zhuyuan and Lucke, Kyle and Lundin, Alan and {MacKean}, Gordon and Maggiore, Adriana and Mahony, Maire and Miller, Kieran and Nagarajan, Rahul and Narayanaswami, Ravi and Ni, Ray and Nix, Kathy and Norrie, Thomas and Omernick, Mark and Penukonda, Narayana and Phelps, Andy and Ross, Jonathan and Ross, Matt and Salek, Amir and Samadiani, Emad and Severn, Chris and Sizikov, Gregory and Snelham, Matthew and Souter, Jed and Steinberg, Dan and Swing, Andy and Tan, Mercedes and Thorson, Gregory and Tian, Bo and Toma, Horia and Tuttle, Erick and Vasudevan, Vijay and Walter, Richard and Wang, Walter and Wilcox, Eric and Yoon, Doe Hyun},
	urldate = {2024-11-14},
	date = {2017-04-16},
	eprinttype = {arxiv},
	eprint = {1704.04760},
	keywords = {Computer Science - Hardware Architecture, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@software{onednn_contributors_oneapi_2024,
	title = {{oneAPI} Deep Neural Network Library ({oneDNN})},
	rights = {Apache-2.0},
	url = {https://github.com/oneapi-src/oneDNN},
	abstract = {{oneAPI} Deep Neural Network Library ({oneDNN})},
	version = {v3.7},
	author = {{oneDNN Contributors}},
	urldate = {2024-11-14},
	date = {2024-11-14},
	note = {original-date: 2016-05-09T23:26:42Z},
}

@software{noauthor_microsoftnnfusion_2024,
	title = {microsoft/nnfusion},
	rights = {{MIT}},
	url = {https://github.com/microsoft/nnfusion},
	abstract = {A flexible and efficient deep neural network ({DNN}) compiler that generates high-performance executable from a {DNN} model description.},
	publisher = {Microsoft},
	urldate = {2024-11-14},
	date = {2024-11-09},
	note = {original-date: 2020-04-01T04:15:38Z},
}

@article{ILSVRC15,
	title = {{ImageNet} large scale visual recognition challenge},
	volume = {115},
	doi = {10.1007/s11263-015-0816-y},
	pages = {211--252},
	number = {3},
	journaltitle = {International Journal of Computer Vision ({IJCV})},
	author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and Berg, Alexander C. and Fei-Fei, Li},
	date = {2015},
}

@misc{alom_history_2018,
	title = {The History Began from {AlexNet}: A Comprehensive Survey on Deep Learning Approaches},
	url = {http://arxiv.org/abs/1803.01164},
	doi = {10.48550/arXiv.1803.01164},
	shorttitle = {The History Began from {AlexNet}},
	abstract = {Deep learning has demonstrated tremendous success in variety of application domains in the past few years. This new field of machine learning has been growing rapidly and applied in most of the application domains with some new modalities of applications, which helps to open new opportunity. There are different methods have been proposed on different category of learning approaches, which includes supervised, semi-supervised and un-supervised learning. The experimental results show state-of-the-art performance of deep learning over traditional machine learning approaches in the field of Image Processing, Computer Vision, Speech Recognition, Machine Translation, Art, Medical imaging, Medical information processing, Robotics and control, Bio-informatics, Natural Language Processing ({NLP}), Cyber security, and many more. This report presents a brief survey on development of {DL} approaches, including Deep Neural Network ({DNN}), Convolutional Neural Network ({CNN}), Recurrent Neural Network ({RNN}) including Long Short Term Memory ({LSTM}) and Gated Recurrent Units ({GRU}), Auto-Encoder ({AE}), Deep Belief Network ({DBN}), Generative Adversarial Network ({GAN}), and Deep Reinforcement Learning ({DRL}). In addition, we have included recent development of proposed advanced variant {DL} techniques based on the mentioned {DL} approaches. Furthermore, {DL} approaches have explored and evaluated in different application domains are also included in this survey. We have also comprised recently developed frameworks, {SDKs}, and benchmark datasets that are used for implementing and evaluating deep learning approaches. There are some surveys have published on Deep Learning in Neural Networks [1, 38] and a survey on {RL} [234]. However, those papers have not discussed the individual advanced techniques for training large scale deep learning models and the recently developed method of generative models [1].},
	number = {{arXiv}:1803.01164},
	publisher = {{arXiv}},
	author = {Alom, Md Zahangir and Taha, Tarek M. and Yakopcic, Christopher and Westberg, Stefan and Sidike, Paheding and Nasrin, Mst Shamima and Esesn, Brian C. Van and Awwal, Abdul A. S. and Asari, Vijayan K.},
	urldate = {2024-11-12},
	date = {2018-09-12},
	eprinttype = {arxiv},
	eprint = {1803.01164},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{krizhevsky_imagenet_2012,
	title = {{ImageNet} Classification with Deep Convolutional Neural Networks},
	volume = {25},
	url = {https://papers.nips.cc/paper_files/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html},
	abstract = {We trained a large, deep convolutional neural network to classify the 1.3 million high-resolution images in the {LSVRC}-2010 {ImageNet} training set into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 39.7{\textbackslash}\% and 18.9{\textbackslash}\% which is considerably better than the previous state-of-the-art results. The neural network, which has 60 million parameters and 500,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and two globally connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient {GPU} implementation of convolutional nets. To reduce overfitting in the globally connected layers we employed a new regularization method that proved to be very effective.},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {Curran Associates, Inc.},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	urldate = {2024-11-12},
	date = {2012},
}

@inproceedings{abadi_tensorflow_2016,
	title = {\{{TensorFlow}\}: A System for \{Large-Scale\} Machine Learning},
	isbn = {978-1-931971-33-1},
	url = {https://www.usenix.org/conference/osdi16/technical-sessions/presentation/abadi},
	shorttitle = {\{{TensorFlow}\}},
	eventtitle = {12th {USENIX} Symposium on Operating Systems Design and Implementation ({OSDI} 16)},
	pages = {265--283},
	author = {Abadi, Martin and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and Kudlur, Manjunath and Levenberg, Josh and Monga, Rajat and Moore, Sherry and Murray, Derek G. and Steiner, Benoit and Tucker, Paul and Vasudevan, Vijay and Warden, Pete and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
	urldate = {2024-11-12},
	date = {2016},
	langid = {english},
}

@inproceedings{chen_learning_2018,
	title = {Learning to Optimize Tensor Programs},
	volume = {31},
	url = {https://proceedings.neurips.cc/paper/2018/hash/8b5700012be65c9da25f49408d959ca0-Abstract.html},
	abstract = {We introduce a learning-based framework to optimize tensor programs for deep learning workloads. Efficient implementations of tensor operators, such as matrix multiplication and high dimensional convolution are key enablers of effective deep learning systems. However, existing systems rely on manually optimized libraries such as {cuDNN} where only a narrow range of server class {GPUs} are well-supported. The reliance on hardware specific operator libraries limits the applicability of high-level graph optimizations and incurs significant engineering costs when deploying to new hardware targets. We use learning to remove this engineering burden. We learn domain specific statistical cost models to guide the search of tensor operator implementations over billions of possible program variants. We further accelerate the search by effective model transfer across workloads. Experimental results show that our framework delivers performance competitive with state-of-the-art hand-tuned libraries for low-power {CPU}, mobile {GPU}, and server-class {GPU}.},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {Curran Associates, Inc.},
	author = {Chen, Tianqi and Zheng, Lianmin and Yan, Eddie and Jiang, Ziheng and Moreau, Thierry and Ceze, Luis and Guestrin, Carlos and Krishnamurthy, Arvind},
	urldate = {2024-11-12},
	date = {2018},
}

@inproceedings{jia_taso_2019,
	location = {New York, {NY}, {USA}},
	title = {{TASO}: optimizing deep learning computation with automatic generation of graph substitutions},
	isbn = {978-1-4503-6873-5},
	url = {https://dl.acm.org/doi/10.1145/3341301.3359630},
	doi = {10.1145/3341301.3359630},
	series = {{SOSP} '19},
	shorttitle = {{TASO}},
	abstract = {Existing deep neural network ({DNN}) frameworks optimize the computation graph of a {DNN} by applying graph transformations manually designed by human experts. This approach misses possible graph optimizations and is difficult to scale, as new {DNN} operators are introduced on a regular basis.We propose {TASO}, the first {DNN} computation graph optimizer that automatically generates graph substitutions. {TASO} takes as input a list of operator specifications and generates candidate substitutions using the given operators as basic building blocks. All generated substitutions are formally verified against the operator specifications using an automated theorem prover. To optimize a given {DNN} computation graph, {TASO} performs a cost-based backtracking search, applying the substitutions to find an optimized graph, which can be directly used by existing {DNN} frameworks.Our evaluation on five real-world {DNN} architectures shows that {TASO} outperforms existing {DNN} frameworks by up to 2.8X, while requiring significantly less human effort. For example, {TensorFlow} currently contains approximately 53,000 lines of manual optimization rules, while the operator specifications needed by {TASO} are only 1,400 lines of code.},
	pages = {47--62},
	booktitle = {Proceedings of the 27th {ACM} Symposium on Operating Systems Principles},
	publisher = {Association for Computing Machinery},
	author = {Jia, Zhihao and Padon, Oded and Thomas, James and Warszawski, Todd and Zaharia, Matei and Aiken, Alex},
	urldate = {2024-11-12},
	date = {2019-10-27},
}

@article{paszke_automatic_2017,
	title = {Automatic differentiation in {PyTorch}},
	url = {https://openreview.net/forum?id=BJJsrmfCZ},
	abstract = {In this article, we describe an automatic differentiation module of {PyTorch} — a library designed to enable rapid research on machine learning models. It builds upon a few projects, most notably Lua Torch, Chainer, and {HIPS} Autograd, and provides a high performance environment with easy access to automatic differentiation of models executed on different devices ({CPU} and {GPU}). To make prototyping easier, {PyTorch} does not follow the symbolic approach used in many other deep learning frameworks, but focuses on differentiation of purely imperative programs, with a focus on extensibility and low overhead. Note that this preprint is a draft of certain sections from an upcoming paper covering all {PyTorch} features.},
	author = {Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and {DeVito}, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
	urldate = {2024-11-12},
	date = {2017-10-28},
	langid = {english},
}

@misc{chetlur_cudnn_2014,
	title = {{cuDNN}: Efficient Primitives for Deep Learning},
	url = {http://arxiv.org/abs/1410.0759},
	doi = {10.48550/arXiv.1410.0759},
	shorttitle = {{cuDNN}},
	abstract = {We present a library of efficient implementations of deep learning primitives. Deep learning workloads are computationally intensive, and optimizing their kernels is difficult and time-consuming. As parallel architectures evolve, kernels must be reoptimized, which makes maintaining codebases difficult over time. Similar issues have long been addressed in the {HPC} community by libraries such as the Basic Linear Algebra Subroutines ({BLAS}). However, there is no analogous library for deep learning. Without such a library, researchers implementing deep learning workloads on parallel processors must create and optimize their own implementations of the main computational kernels, and this work must be repeated as new parallel processors emerge. To address this problem, we have created a library similar in intent to {BLAS}, with optimized routines for deep learning workloads. Our implementation contains routines for {GPUs}, although similarly to the {BLAS} library, these routines could be implemented for other platforms. The library is easy to integrate into existing frameworks, and provides optimized performance and memory usage. For example, integrating {cuDNN} into Caffe, a popular framework for convolutional networks, improves performance by 36\% on a standard model while also reducing memory consumption.},
	number = {{arXiv}:1410.0759},
	publisher = {{arXiv}},
	author = {Chetlur, Sharan and Woolley, Cliff and Vandermersch, Philippe and Cohen, Jonathan and Tran, John and Catanzaro, Bryan and Shelhamer, Evan},
	urldate = {2024-11-12},
	date = {2014-12-18},
	eprinttype = {arxiv},
	eprint = {1410.0759},
	keywords = {Computer Science - Machine Learning, Computer Science - Mathematical Software, Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{chen_tvm_2018,
	title = {\{{TVM}\}: An Automated \{End-to-End\} Optimizing Compiler for Deep Learning},
	isbn = {978-1-939133-08-3},
	url = {https://www.usenix.org/conference/osdi18/presentation/chen},
	shorttitle = {\{{TVM}\}},
	eventtitle = {13th {USENIX} Symposium on Operating Systems Design and Implementation ({OSDI} 18)},
	pages = {578--594},
	author = {Chen, Tianqi and Moreau, Thierry and Jiang, Ziheng and Zheng, Lianmin and Yan, Eddie and Shen, Haichen and Cowan, Meghan and Wang, Leyuan and Hu, Yuwei and Ceze, Luis and Guestrin, Carlos and Krishnamurthy, Arvind},
	urldate = {2024-11-12},
	date = {2018},
	langid = {english},
}

@article{mirhoseini_graph_2021,
	title = {A graph placement methodology for fast chip design},
	volume = {594},
	rights = {2021 The Author(s), under exclusive licence to Springer Nature                 Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-021-03544-w},
	doi = {10.1038/s41586-021-03544-w},
	abstract = {Chip floorplanning is the engineering task of designing the physicallayout of a computer chip. Despite five decades of research1, chip floorplanning hasdefied automation, requiring months of intense effort by physical design engineersto produce manufacturable layouts. Here we present adeep reinforcement learning approach to chip floorplanning. In undersix hours, our method automatically generates chip floorplans that are superior orcomparable to those produced by humans in all key metrics, including powerconsumption, performance and chip area. To achieve this, we pose chip floorplanningas a reinforcement learning problem, and develop an edge-based graphconvolutional neural network architecture capable of learning rich and transferablerepresentations of the chip. As a result, our method utilizes past experience tobecome better and faster at solving new instances of the problem, allowing chipdesign to be performed by artificial agents with more experience than any humandesigner. Our method was used to design the next generation of Google’sartificial intelligence ({AI}) accelerators, and has the potential to save thousandsof hours of human effort for each new generation. Finally, we believe that morepowerful {AI}-designed hardware will fuel advances in {AI}, creating a symbioticrelationship between the two fields.},
	pages = {207--212},
	number = {7862},
	journaltitle = {Nature},
	author = {Mirhoseini, Azalia and Goldie, Anna and Yazgan, Mustafa and Jiang, Joe Wenjie and Songhori, Ebrahim and Wang, Shen and Lee, Young-Joon and Johnson, Eric and Pathak, Omkar and Nova, Azade and Pak, Jiwoo and Tong, Andy and Srinivasa, Kavya and Hang, William and Tuncer, Emre and Le, Quoc V. and Laudon, James and Ho, Richard and Carpenter, Roger and Dean, Jeff},
	urldate = {2024-11-11},
	date = {2021-06},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Computational science, Electrical and electronic engineering},
}

@inproceedings{ma_rammer_2020,
	title = {Rammer: Enabling Holistic Deep Learning Compiler Optimizations with \{{rTasks}\}},
	isbn = {978-1-939133-19-9},
	url = {https://www.usenix.org/conference/osdi20/presentation/ma},
	shorttitle = {Rammer},
	eventtitle = {14th {USENIX} Symposium on Operating Systems Design and Implementation ({OSDI} 20)},
	pages = {881--897},
	author = {Ma, Lingxiao and Xie, Zhiqiang and Yang, Zhi and Xue, Jilong and Miao, Youshan and Cui, Wei and Hu, Wenxiang and Yang, Fan and Zhang, Lintao and Zhou, Lidong},
	urldate = {2024-11-11},
	date = {2020},
	langid = {english},
}

@inproceedings{turner_neural_2021,
	location = {New York, {NY}, {USA}},
	title = {Neural architecture search as program transformation exploration},
	isbn = {978-1-4503-8317-2},
	url = {https://dl.acm.org/doi/10.1145/3445814.3446753},
	doi = {10.1145/3445814.3446753},
	series = {{ASPLOS} '21},
	abstract = {Improving the performance of deep neural networks ({DNNs}) is important to both the compiler and neural architecture search ({NAS}) communities. Compilers apply program transformations in order to exploit hardware parallelism and memory hierarchy. However, legality concerns mean they fail to exploit the natural robustness of neural networks. In contrast, {NAS} techniques mutate networks by operations such as the grouping or bottlenecking of convolutions, exploiting the resilience of {DNNs}. In this work, we express such neural architecture operations as program transformations whose legality depends on a notion of representational capacity. This allows them to be combined with existing transformations into a unified optimization framework. This unification allows us to express existing {NAS} operations as combinations of simpler transformations. Crucially, it allows us to generate and explore new tensor convolutions. We prototyped the combined framework in {TVM} and were able to find optimizations across different {DNNs}, that significantly reduce inference time - over 3× in the majority of cases. Furthermore, our scheme dramatically reduces {NAS} search time.},
	pages = {915--927},
	booktitle = {Proceedings of the 26th {ACM} International Conference on Architectural Support for Programming Languages and Operating Systems},
	publisher = {Association for Computing Machinery},
	author = {Turner, Jack and Crowley, Elliot J. and O'Boyle, Michael F. P.},
	urldate = {2024-11-11},
	date = {2021-04-17},
}

@article{chen_punica_2024,
	title = {Punica: Multi-Tenant {LoRA} Serving},
	volume = {6},
	url = {https://proceedings.mlsys.org/paper_files/paper/2024/hash/054de805fcceb78a201f5e9d53c85908-Abstract-Conference.html},
	shorttitle = {Punica},
	pages = {1--13},
	journaltitle = {Proceedings of Machine Learning and Systems},
	author = {Chen, Lequn and Ye, Zihao and Wu, Yongji and Zhuo, Danyang and Ceze, Luis and Krishnamurthy, Arvind},
	urldate = {2024-11-11},
	date = {2024-05-29},
	langid = {english},
}

@unpublished{moore_advanced_2019,
	location = {University of Cambridge Computer Laboratory},
	title = {Advanced Topics in Computer Architecture: Testing Processors},
	url = {https://www.cl.cam.ac.uk/teaching/2425/R265/slides/testing.pdf},
	author = {Moore, Simon},
	urldate = {2024-11-11},
	date = {2019},
}

@article{pennisi_integrated_2022,
	title = {The Integrated Circuit Industry at a Crossroads: Threats and Opportunities},
	volume = {1},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2674-0729},
	url = {https://www.mdpi.com/2674-0729/1/3/10},
	doi = {10.3390/chips1030010},
	shorttitle = {The Integrated Circuit Industry at a Crossroads},
	abstract = {With the outbreak of the {COVID}-19 pandemic, the persistent chip shortage, war in Ukraine, and U.S.–China tensions, the semiconductor industry is at a critical stage. Only if it is capable of major changes, will it be able to sustain itself and continue to provide solutions for ongoing exponential technology growth. However, the war has undermined, perhaps definitively, a global order that urged the integration of markets above geopolitical divergences. Now that the trend seems to be reversed, the extent to which the costs of this commercial and technological decoupling can be absorbed and legitimized will have to be understood.},
	pages = {150--171},
	number = {3},
	journaltitle = {Chips},
	author = {Pennisi, Salvatore},
	urldate = {2024-11-11},
	date = {2022-12},
	langid = {english},
	note = {Number: 3
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {fabs, integrated circuits, semiconductors, shortage, talent},
}

@inproceedings{miyake_automatic_1994,
	title = {Automatic test generation for functional verification of microprocessors},
	url = {https://ieeexplore.ieee.org/abstract/document/367216},
	doi = {10.1109/ATS.1994.367216},
	abstract = {A novel method to generate test programs for functional verification of microprocessors is presented. The method combines schemes of random generation and specific sequence generation. Four levels of hierarchical information are used to generate efficient test programs including many complicated sequences. Considerations in the test generation is also discussed.{\textless}{\textgreater}},
	eventtitle = {Proceedings of {IEEE} 3rd Asian Test Symposium ({ATS})},
	pages = {292--297},
	booktitle = {Proceedings of {IEEE} 3rd Asian Test Symposium ({ATS})},
	author = {Miyake, J. and Brown, G. and Ueda, M. and Nishiyama, T.},
	urldate = {2024-11-11},
	date = {1994-11},
	keywords = {Algorithm design and analysis, Automatic testing, Decoding, Frequency, Hardware design languages, Microprocessors, Pipelines, Registers, System testing, Very large scale integration},
}

@online{cadence_design_systems_jasper_nodate,
	title = {Jasper Formal Verification Platform},
	url = {https://www.cadence.com/en_US/home/tools/system-design-and-verification/formal-and-static-verification.html},
	abstract = {Formal verification apps at the C/C++ and {RTL} level that can be used at every stage of the design cycle.},
	titleaddon = {Jasper Formal Verification Platform},
	author = {Cadence Design Systems},
	urldate = {2024-11-10},
	langid = {english},
}

@inproceedings{lahiri_experience_2001,
	title = {Experience with term level modeling and verification of the M*{CORE}/sup {TM}/ microprocessor core},
	url = {https://ieeexplore.ieee.org/document/972816},
	doi = {10.1109/HLDVT.2001.972816},
	abstract = {The paper describes the use of term-level modeling and verification of an industrial microprocessor, M*{CORE}/sup {TM}/ which is a limited dual-issue, super-scalar processor with instruction prefetching mechanism, deep pipeline, multicycle functional units, speculation and interlocks. Term-level modeling uses terms, uninterpreted functions and predicates to abstract the data path complexity of the microprocessor. The verification of the control path is carried out almost mechanically with the aid of {CMU}-{EVC}, an extremely efficient decision procedure based on the Logic of Positive Equality with Uninterpreted Functions ({PEUF}). The verification effort resulted in detection of a couple of non-trivial bugs in the microarchitecture in design exploration phase of the design. The paper demonstrates the effectiveness of {CMU}-{EVC} for automated verification of real-life microprocessor designs and also points out some of the challenges and the future work that need to be addressed in term-level modeling and verification of microprocessors using {CMU}-{EVC}.},
	eventtitle = {Sixth {IEEE} International High-Level Design Validation and Test Workshop},
	pages = {109--114},
	booktitle = {Sixth {IEEE} International High-Level Design Validation and Test Workshop},
	author = {Lahiri, S. and Pixley, C. and Albin, K.},
	urldate = {2024-11-10},
	date = {2001-11},
	keywords = {Arithmetic, Commutation, Computer bugs, Design methodology, Equations, Instruction sets, Manuals, Microarchitecture, Microprocessors, Pipelines},
}

@inproceedings{higgins_simplifying_2004,
	title = {Simplifying design and verification for structural hazards and datapaths in pipelined circuits},
	url = {https://ieeexplore.ieee.org/document/1431229},
	doi = {10.1109/HLDVT.2004.1431229},
	abstract = {This paper describes a technique that automates the specification and verification of structural-hazard and datapath correctness properties for pipelined circuits. The technique is based upon a template for pipeline stages, a control-circuit cell library, a decomposition of structural hazard and datapath correctness into a collection of simple properties, and a prototype design tool that generates verification scripts for use by external tools. Our case studies include scalar and superscalar implementations of a 32-bit {OpenRISC} integer microprocessor.},
	eventtitle = {Proceedings. Ninth {IEEE} International High-Level Design Validation and Test Workshop ({IEEE} Cat. No.04EX940)},
	pages = {31--36},
	booktitle = {Proceedings. Ninth {IEEE} International High-Level Design Validation and Test Workshop ({IEEE} Cat. No.04EX940)},
	author = {Higgins, J.T. and Aagaard, M.D.},
	urldate = {2024-11-10},
	date = {2004-11},
	note = {{ISSN}: 1552-6674},
	keywords = {Automatic control, Computer bugs, Hazards, Humans, Large scale integration, Libraries, Logic circuits, Pipelines, Prototypes, Robustness},
}

@inproceedings{kirankumar_symbolic_2012,
	title = {Symbolic Trajectory Evaluation: The primary validation Vehicle for next generation Intel® Processor Graphics {FPU}},
	url = {https://ieeexplore.ieee.org/abstract/document/6462567},
	shorttitle = {Symbolic Trajectory Evaluation},
	abstract = {Formal Verification ({FV}) is widely acknowledged for improving validation effectiveness. Usually formal verification has been used to supplement more traditional coverage oriented testing activities. Arithmetic Data-path {FV} has matured over the time to completely replace traditional dynamic validation methodologies. Moreover, it gives an additional promise of 100\% data-space coverage. Symbolic Trajectory Evaluation ({STE}) is the best proven method of {FV} on Intel® data-path designs. The Floating Point Units ({FPUs}) are generally very data-path intensive. In the next generation Intel Processor Graphics design, the {FPU} was completely re-architected and this necessitated a methodology which could guarantee complete verification in a tight verification schedule. {STE} was brought in to meet this formidable target. This paper discusses the efficient application of this methodology to achieve convincing results. More than 201 bugs were caught in a very short verification cycle using {STE}.},
	eventtitle = {2012 Formal Methods in Computer-Aided Design ({FMCAD})},
	pages = {149--156},
	booktitle = {2012 Formal Methods in Computer-Aided Design ({FMCAD})},
	author = {{KiranKumar}, V M Achutha and Gupta, Aarti and Ghughal, Rajnish},
	urldate = {2024-11-10},
	date = {2012-10},
	keywords = {Computer bugs, Formal verification, Graphics, Graphics processing units, Microprocessors, Next generation networking, Pipelines},
}

@book{piziali_functional_2007,
	title = {Functional Verification Coverage Measurement and Analysis},
	isbn = {978-1-4020-8026-5},
	abstract = {Functional Verification Coverage Measurement and Analysis addresses a means of quantitatively assessing functional verification progress. Without this process, design and verification engineers, and their management, are left guessing whether or not they have completed verifying the device they are designing. Using the techniques described in this book, they will learn how to build a toolset which allows them to know how close they are to functional closure. Functional Verification Coverage Measurement and Analysis is the first book to introduce a useful taxonomy for coverage metric classification. Using this taxonomy, the reader clearly understands the process of creating an effective coverage model. A must read! Harry Foster, Jasper Design Automation, Co-Author of Assertion-Based Design Andrew's book is the most thoughtful and comprehensive treatment of coverage I have seen. I recommend reading (and re-reading) this book to anybody who is really serious about functional verification. Yoav Hollander, {CTO}, Verisity Design In the last few years, coverage has become a must in hardware verification and in software testing. From having to push people to use coverage, the situation changed to great interest... Andrew's excellent and comprehensive book on coverage, the first of its kind, could not have come at a better time. Shmuel Ur, Research Scientist, {IBM}},
	pagetotal = {222},
	publisher = {Springer Science \& Business Media},
	author = {Piziali, Andrew},
	date = {2007-05-08},
	langid = {english},
	note = {Google-Books-{ID}: {zTK}\_BAAAQBAJ},
	keywords = {Computers / Design, Graphics \& Media / {CAD}-{CAM}, Technology \& Engineering / Electrical, Technology \& Engineering / Electronics / Circuits / General},
}

@article{tasiran_coverage_2001,
	title = {Coverage metrics for functional validation of hardware designs},
	volume = {18},
	issn = {1558-1918},
	url = {https://ieeexplore.ieee.org/abstract/document/936247},
	doi = {10.1109/54.936247},
	abstract = {Software simulation remains the primary means of functional validation for hardware designs. Coverage metrics ensure optimal use of simulation resources, measure the completeness of validation, and direct simulations toward unexplored areas of the design. This article surveys the literature, and discusses the experiences of verification practitioners, regarding coverage metrics.},
	pages = {36--45},
	number = {4},
	journaltitle = {{IEEE} Design \& Test of Computers},
	author = {Tasiran, S. and Keutzer, K.},
	urldate = {2024-11-09},
	date = {2001-07},
	note = {Conference Name: {IEEE} Design \& Test of Computers},
	keywords = {Analytical models, Area measurement, Computational modeling, Computer bugs, Computer industry, Formal verification, Hardware, Particle measurements, System testing, Virtual manufacturing},
}

@inproceedings{aagaard_framework_2001,
	location = {Berlin, Heidelberg},
	title = {A Framework for Microprocessor Correctness Statements},
	isbn = {978-3-540-44798-6},
	doi = {10.1007/3-540-44798-9_33},
	abstract = {Most verifications of out-of-order microprocessors compare state-machine-based implementations and specifications, where the specification is based on the instruction-set architecture. The different efforts use a variety of correctness statements, implementations, and verification approaches. We present a framework for classifying correctness statements about safety that is independent of implementation representation and verification approach. We characterize the relationships between the different statements and illustrate how existing and classical approaches fit within this framework.},
	pages = {433--448},
	booktitle = {Correct Hardware Design and Verification Methods},
	publisher = {Springer},
	author = {Aagaard, Mark D. and Cook, Byron and Day, Nancy A. and Jones, Robert B.},
	editor = {Margaria, Tiziana and Melham, Tom},
	date = {2001},
	langid = {english},
	keywords = {Abstraction Function, Cache Coherence Protocol, Correctness Statement, Implementation State, Intermediate Model},
}

@inproceedings{aagaard_methodology_2000,
	location = {Berlin, Heidelberg},
	title = {A Methodology for Large-Scale Hardware Verification},
	isbn = {978-3-540-40922-9},
	doi = {10.1007/3-540-40922-X_17},
	abstract = {We present a formal verification methodology for datapathdominated hardware. This provides a systematic but flexible framework within which to organize the activities undertaken in large-scale verification efforts and to structure the associated code and proof-script artifacts. The methodology deploys a combination of model checking and lightweight theorem proving in higher-order logic, tightly integrated within a general-purpose functional programming language that allows the framework to be easily customized and also serves as a specification language. We illustrate the methodology-which has has proved highly effective in large-scale industrial trials-with the verification of an {IEEE}- compliant, extended precision floating-point adder.},
	pages = {300--319},
	booktitle = {Formal Methods in Computer-Aided Design},
	publisher = {Springer},
	author = {Aagaard, Mark D. and Jones, Robert B. and Melham, Thomas F. and O’Leary, John W. and Seger, Carl-Johan H.},
	editor = {Hunt, Warren A. and Johnson, Steven D.},
	date = {2000},
	langid = {english},
	keywords = {Circuit Structure, High Order Logic, Model Check, Symbolic Model Check, Theorem Prove},
}

@inproceedings{aharon_test_1995,
	location = {New York, {NY}, {USA}},
	title = {Test program generation for functional verification of {PowerPC} processors in {IBM}},
	isbn = {978-0-89791-725-4},
	url = {https://dl.acm.org/doi/10.1145/217474.217542},
	doi = {10.1145/217474.217542},
	series = {{DAC} '95},
	pages = {279--285},
	booktitle = {Proceedings of the 32nd annual {ACM}/{IEEE} Design Automation Conference},
	publisher = {Association for Computing Machinery},
	author = {Aharon, Aharon and Goodman, Dave and Levinger, Moshe and Lichtenstein, Yossi and Malka, Yossi and Metzger, Charlotte and Molcho, Moshe and Shurek, Gil},
	urldate = {2024-11-09},
	date = {1995-01-01},
}

@software{noauthor_ucb-barriscv-torture_2024,
	title = {ucb-bar/riscv-torture},
	url = {https://github.com/ucb-bar/riscv-torture},
	abstract = {{RISC}-V Torture Test},
	publisher = {{UC} Berkeley Architecture Research},
	urldate = {2024-11-08},
	date = {2024-11-05},
	note = {original-date: 2012-01-26T21:56:52Z},
}

@article{campbell_randomised_2016,
	title = {Randomised testing of a microprocessor model using {SMT}-solver state generation},
	volume = {118},
	issn = {0167-6423},
	url = {https://www.sciencedirect.com/science/article/pii/S0167642315003159},
	doi = {10.1016/j.scico.2015.10.012},
	series = {Formal Methods for Industrial Critical Systems ({FMICS}’2014)},
	abstract = {We validate a {HOL}4 model of the {ARM} Cortex-M0 microcontroller core by testing the model's behaviour on randomly chosen instructions against real chips from several manufacturers. The model and our intended application involve precise timing information about instruction execution, but the implementations are pipelined, so checking the behaviour of single instructions would not give us sufficient confidence in the model. Thus we test the model using sequences of randomly chosen instructions. The main challenge is to meet the constraints on the initial and intermediate execution states: we must ensure that memory accesses are in range and that we respect restrictions on the instructions. By careful transformation of these constraints an off-the-shelf {SMT} solver can be used to find suitable states for executing test sequences. We also use additional constraints to test our hypotheses about the timing anomalies encountered.},
	pages = {60--76},
	journaltitle = {Science of Computer Programming},
	shortjournal = {Science of Computer Programming},
	author = {Campbell, Brian and Stark, Ian},
	urldate = {2024-11-08},
	date = {2016-03-01},
	keywords = {{HOL}, Microprocessor models, Randomised testing, {SMT}},
}

@online{noauthor_sail-riscvdoc_nodate,
	title = {sail-riscv/doc at master · riscv/sail-riscv},
	url = {https://github.com/riscv/sail-riscv/tree/master/doc},
	abstract = {Sail {RISC}-V model. Contribute to riscv/sail-riscv development by creating an account on {GitHub}.},
	titleaddon = {{GitHub}},
	urldate = {2024-11-08},
	langid = {english},
}

@article{armstrong_isa_2019,
	title = {{ISA} semantics for {ARMv}8-a, {RISC}-v, and {CHERI}-{MIPS}},
	volume = {3},
	url = {https://dl.acm.org/doi/10.1145/3290384},
	doi = {10.1145/3290384},
	abstract = {Architecture specifications notionally define the fundamental interface between hardware and software: the envelope of allowed behaviour for processor implementations, and the basic assumptions for software development and verification. But in practice, they are typically prose and pseudocode documents, not rigorous or executable artifacts, leaving software and verification on shaky ground.  In this paper, we present rigorous semantic models for the sequential behaviour of large parts of the mainstream {ARMv}8-A, {RISC}-V, and {MIPS} architectures, and the research {CHERI}-{MIPS} architecture, that are complete enough to boot operating systems, variously Linux, {FreeBSD}, or {seL}4. Our {ARMv}8-A models are automatically translated from authoritative {ARM}-internal definitions, and (in one variant) tested against the {ARM} Architecture Validation Suite.  We do this using a custom language for {ISA} semantics, Sail, with a lightweight dependent type system, that supports automatic generation of emulator code in C and {OCaml}, and automatic generation of proof-assistant definitions for Isabelle, {HOL}4, and (currently only for {MIPS}) Coq. We use the former for validation, and to assess specification coverage. To demonstrate the usability of the latter, we prove (in Isabelle) correctness of a purely functional characterisation of {ARMv}8-A address translation. We moreover integrate the {RISC}-V model into the {RMEM} tool for (user-mode) relaxed-memory concurrency exploration. We prove (on paper) the soundness of the core Sail type system.  We thereby take a big step towards making the architectural abstraction actually well-defined, establishing foundations for verification and reasoning.},
	pages = {71:1--71:31},
	issue = {{POPL}},
	journaltitle = {Proc. {ACM} Program. Lang.},
	author = {Armstrong, Alasdair and Bauereiss, Thomas and Campbell, Brian and Reid, Alastair and Gray, Kathryn E. and Norton, Robert M. and Mundkur, Prashanth and Wassell, Mark and French, Jon and Pulte, Christopher and Flur, Shaked and Stark, Ian and Krishnaswami, Neel and Sewell, Peter},
	urldate = {2024-11-08},
	date = {2019-01-02},
}

@article{reid_who_2017,
	title = {Who guards the guards? formal validation of the Arm v8-m architecture specification},
	volume = {1},
	url = {https://dl.acm.org/doi/10.1145/3133912},
	doi = {10.1145/3133912},
	shorttitle = {Who guards the guards?},
	abstract = {Software and hardware are increasingly being formally verified against specifications, but how can we verify the specifications themselves? This paper explores what it means to formally verify a specification. We solve three challenges: (1) How to create a secondary, higher-level specification that can be effectively reviewed by processor designers who are not experts in formal verification; (2) How to avoid common-mode failures between the specifications; and (3) How to automatically verify the two specifications against each other.  One of the most important specifications for software verification is the processor specification since it defines the behaviour of machine code and of hardware protection features used by operating systems. We demonstrate our approach on {ARM}'s v8-M Processor Specification, which is intended to improve the security of Internet of Things devices. Thus, we focus on establishing the security guarantees the architecture is intended to provide. Despite the fact that the {ARM} v8-M specification had previously been extensively tested, we found twelve bugs (including two security bugs) that have all been fixed by {ARM}.},
	pages = {88:1--88:24},
	issue = {{OOPSLA}},
	journaltitle = {Proc. {ACM} Program. Lang.},
	author = {Reid, Alastair},
	urldate = {2024-11-08},
	date = {2017-10-12},
}

@inproceedings{reid_end--end_2016,
	location = {Cham},
	title = {End-to-End Verification of Processors with {ISA}-Formal},
	isbn = {978-3-319-41540-6},
	doi = {10.1007/978-3-319-41540-6_3},
	abstract = {Despite 20+ years of research on processor verification, it remains hard to use formal verification techniques in commercial processor development. There are two significant factors: scaling issues and return on investment. The scaling issues include the size of modern processor specifications, the size/complexity of processor designs, the size of design/verification teams and the (non)availability of enough formal verification experts. The return on investment issues include the need to start catching bugs early in development, the need to continue catching bugs throughout development, and the need to be able to reuse verification {IP}, tools and techniques across a wide range of design styles.},
	pages = {42--58},
	booktitle = {Computer Aided Verification},
	publisher = {Springer International Publishing},
	author = {Reid, Alastair and Chen, Rick and Deligiannis, Anastasios and Gilday, David and Hoyes, David and Keen, Will and Pathirane, Ashan and Shepherd, Owen and Vrabel, Peter and Zaidi, Ali},
	editor = {Chaudhuri, Swarat and Farzan, Azadeh},
	date = {2016},
	langid = {english},
	keywords = {Bound Model Check, Formal Verification, Forwarding Path, Register File, Verification Technique},
}

@article{adir_genesys-pro_2004,
	title = {Genesys-Pro: innovations in test program generation for functional processor verification},
	volume = {21},
	issn = {1558-1918},
	url = {https://ieeexplore.ieee.org/document/1277900},
	doi = {10.1109/MDT.2004.1277900},
	shorttitle = {Genesys-Pro},
	abstract = {Functional verification is widely recognized as the bottleneck of the hardware design cycle. With the ever-growing demand for greater performance and faster time to market, coupled with the exponential growth in hardware size, verification has become increasingly difficult. Although formal methods such as model checking and theorem proving have resulted in noticeable progress, these approaches apply only to the verification of relatively small design blocks or to very focused verification goals. Current industry practice is to use separate, automatic, random stimuli generators for processor- and multiprocessor-level verification. The generated stimuli, usually in the form of test programs, trigger architecture and microarchitecture events defined by a verification plan. {MAC}-based algorithms are well suited for the test program generation domain because they postpone heuristic decisions until after consideration of all architectural and testing-knowledge constraints. Geneysys-Pro is currently the main test generation tool for functional verification of {IBM} processors, including several complex processors. We've found that the new language considerably reduces the effort needed to define and maintain knowledge specific to an implementation and verification plan.},
	pages = {84--93},
	number = {2},
	journaltitle = {{IEEE} Design \& Test of Computers},
	author = {Adir, A. and Almog, E. and Fournier, L. and Marcus, E. and Rimon, M. and Vinov, M. and Ziv, A.},
	urldate = {2024-11-08},
	date = {2004-03},
	note = {Conference Name: {IEEE} Design \& Test of Computers},
	keywords = {Computer languages, Design engineering, Engines, Knowledge engineering, Microprocessors, Power generation, Power system modeling, Spine, Technological innovation, Testing},
}

@inproceedings{mishra_functional_2005,
	title = {Functional coverage driven test generation for validation of pipelined processors},
	url = {https://ieeexplore.ieee.org/abstract/document/1395653},
	doi = {10.1109/DATE.2005.162},
	abstract = {Functional verification of microprocessors is one of the most complex and expensive tasks in the current system-on-chip design process. A significant bottleneck in the validation of such systems is the lack of a suitable functional coverage metric. The paper presents a functional coverage based test generation technique for pipelined architectures. The proposed methodology makes three important contributions. First, a general graph-theoretic model is developed that can capture the structure and behavior (instruction-set) of a wide variety of pipelined processors. Second, we propose a functional fault model that is used to define the functional coverage for pipelined architectures. Finally, test generation procedures are presented that accept the graph model of the architecture as input and generate test programs to detect all the faults in the functional fault model. Our experimental results on two pipelined processor models demonstrate that the number of test programs generated by our approach to obtain a fault coverage is an order of magnitude less than those generated by traditional random or constrained-random test generation techniques.},
	eventtitle = {Design, Automation and Test in Europe},
	pages = {678--683 Vol. 2},
	booktitle = {Design, Automation and Test in Europe},
	author = {Mishra, P. and Dutt, N.},
	urldate = {2024-11-08},
	date = {2005-03},
	note = {{ISSN}: 1558-1101},
	keywords = {Design engineering, Embedded computing, Fault detection, Information science, Microprocessors, Random number generation, Reduced instruction set computing, System testing, System-on-a-chip, {VLIW}},
}

@inproceedings{mcsherry_scalability_2015,
	title = {Scalability! But at what \{{COST}\}?},
	url = {https://www.usenix.org/conference/hotos15/workshop-program/presentation/mcsherry},
	eventtitle = {15th Workshop on Hot Topics in Operating Systems ({HotOS} {XV})},
	author = {{McSherry}, Frank and Isard, Michael and Murray, Derek G.},
	urldate = {2024-11-04},
	date = {2015},
	langid = {english},
}

@inproceedings{blem_power_2013,
	title = {Power struggles: Revisiting the {RISC} vs. {CISC} debate on contemporary {ARM} and x86 architectures},
	url = {https://ieeexplore.ieee.org/abstract/document/6522302},
	doi = {10.1109/HPCA.2013.6522302},
	shorttitle = {Power struggles},
	abstract = {{RISC} vs. {CISC} wars raged in the 1980s when chip area and processor design complexity were the primary constraints and desktops and servers exclusively dominated the computing landscape. Today, energy and power are the primary design constraints and the computing landscape is significantly different: growth in tablets and smartphones running {ARM} (a {RISC} {ISA}) is surpassing that of desktops and laptops running x86 (a {CISC} {ISA}). Further, the traditionally low-power {ARM} {ISA} is entering the high-performance server market, while the traditionally high-performance x86 {ISA} is entering the mobile low-power device market. Thus, the question of whether {ISA} plays an intrinsic role in performance or energy efficiency is becoming important, and we seek to answer this question through a detailed measurement based study on real hardware running real applications. We analyze measurements on the {ARM} Cortex-A8 and Cortex-A9 and Intel Atom and Sandybridge i7 microprocessors over workloads spanning mobile, desktop, and server computing. Our methodical investigation demonstrates the role of {ISA} in modern microprocessors' performance and energy efficiency. We find that {ARM} and x86 processors are simply engineering design points optimized for different levels of performance, and there is nothing fundamentally more energy efficient in one {ISA} class or the other. The {ISA} being {RISC} or {CISC} seems irrelevant.},
	eventtitle = {2013 {IEEE} 19th International Symposium on High Performance Computer Architecture ({HPCA})},
	pages = {1--12},
	booktitle = {2013 {IEEE} 19th International Symposium on High Performance Computer Architecture ({HPCA})},
	author = {Blem, Emily and Menon, Jaikrishnan and Sankaralingam, Karthikeyan},
	urldate = {2024-11-04},
	date = {2013-02},
	note = {{ISSN}: 1530-0897},
	keywords = {Abstracts, Mobile communication, Reduced instruction set computing, Servers},
}

@online{llvm_llvms_2024,
	title = {{LLVM}’s Analysis and Transform Passes — {LLVM} 20.0.0git documentation},
	url = {https://llvm.org/docs/Passes.html},
	titleaddon = {{LLVM}’s Analysis and Transform Passes — {LLVM} 20.0.0git documentation},
	author = {{LLVM}},
	urldate = {2024-11-04},
	date = {2024-03-11},
}

@online{amd_amd_2023,
	title = {{AMD} Introduces New {AMD} Ryzen Threadripper 7000 Series Processors},
	url = {https://www.amd.com/en/newsroom/press-releases/2023-10-19-amd-introduces-new-amd-ryzen-threadripper-7000-ser.html},
	titleaddon = {{AMD} Introduces New {AMD} Ryzen Threadripper 7000 Series Processors},
	author = {{AMD}},
	urldate = {2024-11-03},
	date = {2023-10-19},
	langid = {english},
}

@inproceedings{takizawa_checuda_2009,
	title = {{CheCUDA}: A Checkpoint/Restart Tool for {CUDA} Applications},
	url = {https://ieeexplore.ieee.org/abstract/document/5372771},
	doi = {10.1109/PDCAT.2009.78},
	shorttitle = {{CheCUDA}},
	abstract = {In this paper, a tool named {CheCUDA} is designed to checkpoint {CUDA} applications that use {GPUs} as accelerators. As existing checkpoint/restart implementations do not support checkpointing the {GPU} status, {CheCUDA} hooks a part of basic {CUDA} driver {API} calls in order to record the status changes on the main memory. At checkpointing, {CheCUDA} stores the status changes in a file after copying all necessary data in the video memory to the main memory and then disabling the {CUDA} runtime. At restarting, {CheCUDA} reads the file, re-initializes the {CUDA} runtime, and recovers the resources on {GPUs} so as to restart from the stored status. This paper demonstrates that a prototype implementation of {CheCUDA} can correctly checkpoint and restart a {CUDA} application written with basic {APIs}. This also indicates that {CheCUDA} can migrate a process from one {PC} to another even if the process uses a {GPU}. Accordingly, {CheCUDA} is useful not only to enhance the dependability of {CUDA} applications but also to enable dynamic task scheduling of {CUDA} applications required especially on heterogeneous {GPU} cluster systems. This paper also shows the timing overhead for checkpointing.},
	eventtitle = {2009 International Conference on Parallel and Distributed Computing, Applications and Technologies},
	pages = {408--413},
	booktitle = {2009 International Conference on Parallel and Distributed Computing, Applications and Technologies},
	author = {Takizawa, Hiroyuki and Sato, Katsuto and Komatsu, Kazuhiko and Kobayashi, Hiroaki},
	urldate = {2024-11-03},
	date = {2009-12},
	note = {{ISSN}: 2379-5352},
	keywords = {Checkpointing, Computer applications, Computer architecture, Distributed computing, Dynamic scheduling, Graphics processing units, Processor scheduling, Prototypes, Runtime, Throughput, Timing, checkpoint/restart, compute unified device architecture},
}

@inproceedings{pena_vocl-ft_2015,
	location = {New York, {NY}, {USA}},
	title = {{VOCL}-{FT}: introducing techniques for efficient soft error coprocessor recovery},
	isbn = {978-1-4503-3723-6},
	url = {https://dl.acm.org/doi/10.1145/2807591.2807640},
	doi = {10.1145/2807591.2807640},
	series = {{SC} '15},
	shorttitle = {{VOCL}-{FT}},
	abstract = {Popular accelerator programming models rely on offloading computation operations and their corresponding data transfers to the coprocessors, leveraging synchronization points where needed. In this paper we identify and explore how such a programming model enables optimization opportunities not utilized in traditional checkpoint/restart systems, and we analyze them as the building blocks for an efficient fault-tolerant system for accelerators. Although we leverage our techniques to protect from detected but uncorrected {ECC} errors in the device memory in {OpenCL}-accelerated applications, coprocessor reliability solutions based on different error detectors and similar {API} semantics can directly adopt the techniques we propose. Adding error detection and protection involves a tradeoff between runtime overhead and recovery time. Although optimal configurations depend on the particular application, the length of the run, the error rate, and the temporary storage speed, our test cases reveal a good balance with significantly reduced runtime overheads.},
	pages = {1--12},
	booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
	publisher = {Association for Computing Machinery},
	author = {Peña, Antonio J. and Bland, Wesley and Balaji, Pavan},
	urldate = {2024-11-03},
	date = {2015-11-15},
}

@inproceedings{feng_encore_2011,
	location = {New York, {NY}, {USA}},
	title = {Encore: low-cost, fine-grained transient fault recovery},
	isbn = {978-1-4503-1053-6},
	url = {https://dl.acm.org/doi/10.1145/2155620.2155667},
	doi = {10.1145/2155620.2155667},
	series = {{MICRO}-44},
	shorttitle = {Encore},
	abstract = {To meet an insatiable consumer demand for greater performance at less power, silicon technology has scaled to unprecedented dimensions. However, the pursuit of faster processors and longer battery life has come at the cost of reliability. Given the rise of processor reliability as a first-order design constraint, there has been a growing interest in low-cost, non-intrusive techniques for transient fault detection. Many of these recent proposals have counted on the availability of hardware recovery mechanisms. Although common in aggressive out-of-order cores, hardware support for speculative rollback and recovery is less common in lower-end commodity processors. This paper presents Encore, a software-based fault recovery mechanism tailored for these lower-cost systems that lack native hardware support for speculative rollback recovery. Encore combines program analysis, profile data, and simple code transformations to create statistically idempotent code regions that can recover from faults at very little cost. Using this software-only, compiler-based approach, Encore provides the ability to recover from transient faults without specialized hardware or the costs of traditional, full-system checkpointing solutions. Experimental results show that Encore, with just 14\% of runtime overhead, can safely recover, on average from 97\% of transient faults when coupled with existing detection schemes.},
	pages = {398--409},
	booktitle = {Proceedings of the 44th Annual {IEEE}/{ACM} International Symposium on Microarchitecture},
	publisher = {Association for Computing Machinery},
	author = {Feng, Shuguang and Gupta, Shantanu and Ansari, Amin and Mahlke, Scott A. and August, David I.},
	urldate = {2024-11-03},
	date = {2011-12-03},
}

@inproceedings{di_martino_lessons_2014,
	title = {Lessons Learned from the Analysis of System Failures at Petascale: The Case of Blue Waters},
	url = {https://ieeexplore.ieee.org/abstract/document/6903615},
	doi = {10.1109/DSN.2014.62},
	shorttitle = {Lessons Learned from the Analysis of System Failures at Petascale},
	abstract = {This paper provides an analysis of failures and their impact for Blue Waters, the Cray hybrid ({CPU}/{GPU}) supercomputer at the University of Illinois at Urbana-Champaign. The analysis is based on both manual failure reports and automatically generated event logs collected over 261 days. Results include i) a characterization of the root causes of single-node failures, ii) a direct assessment of the effectiveness of system-level fail over as well as memory, processor, network, {GPU} accelerator, and file system error resiliency, and iii) an analysis of system-wide outages. The major findings of this study are as follows. Hardware is not the main cause of system downtime. This is notwithstanding the fact that hardware-related failures are 42\% of all failures. Failures caused by hardware were responsible for only 23\% of the total repair time. These results are partially due to the fact that processor and memory protection mechanisms (x8 and x4 Chip kill, {ECC}, and parity) are able to handle a sustained rate of errors as high as 250 errors/h while providing a coverage of 99.997\% out of a set of more than 1.5 million of analyzed errors. Only 28 multiple-bit errors bypassed the employed protection mechanisms. Software, on the other hand, was the largest contributor to the node repair hours (53\%), despite being the cause of only 20\% of the total number of failures. A total of 29 out of 39 system-wide outages involved the Lustre file system with 42\% of them caused by the inadequacy of the automated fail over procedures.},
	eventtitle = {2014 44th Annual {IEEE}/{IFIP} International Conference on Dependable Systems and Networks},
	pages = {610--621},
	booktitle = {2014 44th Annual {IEEE}/{IFIP} International Conference on Dependable Systems and Networks},
	author = {Di Martino, Catello and Kalbarczyk, Zbigniew and Iyer, Ravishankar K. and Baccanico, Fabio and Fullop, Joseph and Kramer, William},
	urldate = {2024-11-03},
	date = {2014-06},
	note = {{ISSN}: 2158-3927},
	keywords = {Blades, Cray {XE}6, Cray {XK}7, Error correction codes, Failure Analysis, Failure Reports, Graphics processing units, Hardware, Machine Check, Maintenance engineering, Nvidia {GPU} errors, Random access memory, Supercomputer},
}

@inproceedings{tiwari_understanding_2015,
	title = {Understanding {GPU} errors on large-scale {HPC} systems and the implications for system design and operation},
	url = {https://ieeexplore.ieee.org/abstract/document/7056044},
	doi = {10.1109/HPCA.2015.7056044},
	abstract = {Increase in graphics hardware performance and improvements in programmability has enabled {GPUs} to evolve from a graphics-specific accelerator to a general-purpose computing device. Titan, the world's second fastest supercomputer for open science in 2014, consists of more dum 18,000 {GPUs} that scientists from various domains such as astrophysics, fusion, climate, and combustion use routinely to run large-scale simulations. Unfortunately, while the performance efficiency of {GPUs} is well understood, their resilience characteristics in a large-scale computing system have not been fully evaluated. We present a detailed study to provide a thorough understanding of {GPU} errors on a large-scale {GPU}-enabled system. Our data was collected from the Titan supercomputer at the Oak Ridge Leadership Computing Facility and a {GPU} cluster at the Los Alamos National Laboratory. We also present results from our extensive neutron-beam tests, conducted at Los Alamos Neutron Science Center ({LANSCE}) and at {ISIS} (Rutherford Appleron Laboratories, {UK}), to measure the resilience of different generations of {GPUs}. We present several findings from our field data and neutron-beam experiments, and discuss the implications of our results for future {GPU} architects, current and future {HPC} computing facilities, and researchers focusing on {GPU} resilience.},
	eventtitle = {2015 {IEEE} 21st International Symposium on High Performance Computer Architecture ({HPCA})},
	pages = {331--342},
	booktitle = {2015 {IEEE} 21st International Symposium on High Performance Computer Architecture ({HPCA})},
	author = {Tiwari, Devesh and Gupta, Saurabh and Rogers, James and Maxwell, Don and Rech, Paolo and Vazhkudai, Sudharshan and Oliveira, Daniel and Londo, Dave and {DeBardeleben}, Nathan and Navaux, Philippe and Carro, Luigi and Bland, Arthur},
	urldate = {2024-11-03},
	date = {2015-02},
	note = {{ISSN}: 2378-203X},
	keywords = {Computer crashes, Error correction codes, Graphics processing units, Laboratories, Neutrons, Resilience, Supercomputers},
}

@inproceedings{schuchman_rescue_2005,
	title = {Rescue: a microarchitecture for testability and defect tolerance},
	url = {https://ieeexplore.ieee.org/abstract/document/1431554},
	doi = {10.1109/ISCA.2005.44},
	shorttitle = {Rescue},
	abstract = {Scaling feature size improves processor performance but increases each device's susceptibility to defects (i.e., hard errors). As a result, fabrication technology must improve significantly to maintain yields. Redundancy techniques in memory have been successful at improving yield in the presence of defects. Apart from core sparing which disables faulty cores in a chip multiprocessor, little has been done to target the core logic. While previous work has proposed that either inherent or added redundancy in the core logic can be used to tolerate defects, the key issues of realistic testing and fault isolation have been ignored. This paper is the first to consider testability and fault isolation in designing modern high-performance, defect-tolerant microarchitectures. We define intra-cycle logic independence ({ICI}) as the condition needed for conventional scan test to isolate faults quickly to the microarchitectural-block granularity. We propose logic transformations to redesign conventional superscalar microarchitecture to comply with {ICI}. We call our novel, testable, and defect-tolerant microarchitecture Rescue.},
	eventtitle = {32nd International Symposium on Computer Architecture ({ISCA}'05)},
	pages = {160--171},
	booktitle = {32nd International Symposium on Computer Architecture ({ISCA}'05)},
	author = {Schuchman, E. and Vijaykumar, T.N.},
	urldate = {2024-11-02},
	date = {2005-06},
	note = {{ISSN}: 1063-6897},
	keywords = {{CMOS} technology, Circuit faults, Fabrication, Isolation technology, Logic testing, Microarchitecture, Power generation economics, Redundancy, Technological innovation, Throughput},
}

@online{taiwan_semiconductor_manufacturing_company_limited_3nm_nodate,
	title = {3nm Technology},
	url = {https://www.tsmc.com/english/dedicatedFoundry/technology/logic/l_3nm},
	abstract = {In 2022, {TSMC} led the foundry to start 3nm {FinFET} (N3) technology high volume production. {TSMC}’s 3nm process is the industry’s most advanced semiconductor technology offering best power, performance, and area ({PPA}), and is a full-node advance from its 5nm generation. Following N3 technology, {TSMC} introduced N3E and N3P, enhanced 3nm processes for better power, performance, and density.},
	titleaddon = {3nm Technology},
	author = {Taiwan Semiconductor Manufacturing Company Limited},
	urldate = {2024-11-02},
	langid = {english},
}

@inproceedings{mcpherson_reliability_2006,
	location = {New York, {NY}, {USA}},
	title = {Reliability challenges for 45nm and beyond},
	isbn = {978-1-59593-381-2},
	url = {https://dl.acm.org/doi/10.1145/1146909.1146959},
	doi = {10.1145/1146909.1146959},
	series = {{DAC} '06},
	abstract = {Scaling, for enhanced performance and cost reduction, has pushed existing {CMOS} materials much closer to their intrinsic reliability limits.This will require that designers will have to be very careful with: high current densities,voltage overshoots, localized hot spots on the chip, high duty-cycle applications, and high thermal-resistance packaging.In addition to the reliability issues, interconnect {RC} time-delay will worsen with scaling because Cu resistivity is expected to increase due to surface and grain boundary scattering in very narrow interconnects.Also, the low-k interconnect-dielectric introduction rate has been much slower than {ITRS} roadmap forecasts.},
	pages = {176--181},
	booktitle = {Proceedings of the 43rd annual Design Automation Conference},
	publisher = {Association for Computing Machinery},
	author = {{McPherson}, J. W.},
	urldate = {2024-11-02},
	date = {2006-07-24},
}

@article{taylor_landscape_2013,
	title = {A Landscape of the New Dark Silicon Design Regime},
	volume = {33},
	issn = {1937-4143},
	url = {https://ieeexplore.ieee.org/abstract/document/6583151},
	doi = {10.1109/MM.2013.90},
	abstract = {Because of the breakdown of Dennard scaling, the percentage of a silicon chip that can switch at full frequency drops exponentially with each process generation. This utilization wall forces designers to ensure that, at any point in time, large fractions of their chips are effectively "dark silicon"–that is, significantly underclocked or idle for large periods of time. As exponentially larger fractions of a chip's transistors become dark, silicon area becomes an exponentially cheaper resource relative to power and energy consumption. This shift is driving a new class of architectural techniques that "spend" area to "buy" energy efficiency. All these techniques seek to introduce new forms of heterogeneity into the computational stack. This article begins by examining four promising directions–the "four horsemen"–that have emerged as top contenders for thriving in the dark silicon age. Each direction carries with its virtues deep-seated restrictions that require a careful understanding of the underlying trade-offs and benefits. Furthermore, the author proposes a set of evolutionary dark silicon design principles and examines how one of the "darkest" computing architectures of all, the human brain, trades off energy and area in ways that provide potential insights into more revolutionary directions for computer architecture.},
	pages = {8--19},
	number = {5},
	journaltitle = {{IEEE} Micro},
	author = {Taylor, Michael B.},
	urldate = {2024-11-02},
	date = {2013-09},
	note = {Conference Name: {IEEE} Micro},
	keywords = {{CMOS} integrated circuits, Capacitance, Dark silicon, Dennard scaling, Electric breakdown, Energy efficiency, Multicore processing, Semiconductor device manufacture, Silicon, Threshold voltage, Transistors, dark silicon, four horsemen, multicore, utilization wall},
}

@article{bohr_30_2007,
	title = {A 30 Year Retrospective on Dennard's {MOSFET} Scaling Paper},
	volume = {12},
	issn = {1098-4232},
	url = {https://ieeexplore.ieee.org/abstract/document/4785534},
	doi = {10.1109/N-SSC.2007.4785534},
	abstract = {The {MOSFET} scaling principles for obtaining simultaneous improvements in transistor density, switching speed, and power dissipation described by Robert H. Dennard and others in "Design of Ion-implanted {MOSFETs} with Very Small Physical Dimensions" (1974 ) became a roadmap for the semiconductor industry to provide systematic and predictable transistor improvements. New technology generations emerging approximately every three years during the 1970's and 1980's and appearing every other year starting in the mid-1990's, promise to continue although we face growing challenges.},
	pages = {11--13},
	number = {1},
	journaltitle = {{IEEE} Solid-State Circuits Society Newsletter},
	author = {Bohr, Mark},
	urldate = {2024-11-02},
	date = {2007},
	note = {Conference Name: {IEEE} Solid-State Circuits Society Newsletter},
	keywords = {Industries, Integrated circuit interconnections, Logic gates, {MOSFET} circuits, Silicon, Transistors, Voltage control},
}

@article{altaf_logca_2017,
	title = {{LogCA}: A High-Level Performance Model for Hardware Accelerators},
	volume = {45},
	issn = {0163-5964},
	url = {https://dl.acm.org/doi/10.1145/3140659.3080216},
	doi = {10.1145/3140659.3080216},
	shorttitle = {{LogCA}},
	abstract = {With the end of Dennard scaling, architects have increasingly turned to special-purpose hardware accelerators to improve the performance and energy efficiency for some applications. Unfortunately, accelerators don't always live up to their expectations and may under-perform in some situations. Understanding the factors which effect the performance of an accelerator is crucial for both architects and programmers early in the design stage. Detailed models can be highly accurate, but often require low-level details which are not available until late in the design cycle. In contrast, simple analytical models can provide useful insights by abstracting away low-level system details.In this paper, we propose {LogCA}---a high-level performance model for hardware accelerators. {LogCA} helps both programmers and architects identify performance bounds and design bottlenecks early in the design cycle, and provide insight into which optimizations may alleviate these bottlenecks. We validate our model across a variety of kernels, ranging from sub-linear to super-linear complexities on both on-chip and off-chip accelerators. We also describe the utility of {LogCA} using two retrospective case studies. First, we discuss the evolution of interface design in {SUN}/Oracle's encryption accelerators. Second, we discuss the evolution of memory interface design in three different {GPU} architectures. In both cases, we show that the adopted design optimizations for these machines are similar to {LogCA}'s suggested optimizations. We argue that architects and programmers can use insights from these retrospective studies for improving future designs.},
	pages = {375--388},
	number = {2},
	journaltitle = {{SIGARCH} Comput. Archit. News},
	author = {Altaf, Muhammad Shoaib Bin and Wood, David A.},
	urldate = {2024-11-02},
	date = {2017-06-24},
}

@inproceedings{ainsworth_paramedic_2019,
	title = {{ParaMedic}: Heterogeneous Parallel Error Correction},
	url = {https://ieeexplore.ieee.org/document/8809510},
	doi = {10.1109/DSN.2019.00032},
	shorttitle = {{ParaMedic}},
	abstract = {Processor error detection can be reduced in cost significantly by exploiting the parallelism that exists in a repeated copy of an execution, which may not exist in the original code, to split up the redundant work on a large number of small, highly efficient cores. However, such schemes don't provide a method for automatic error recovery. We develop {ParaMedic}, an architecture to allow efficient automatic correction of errors detected in a system by using parallel heterogeneous cores, to provide a full fail-safe system that does not propagate errors to other systems, and can recover without manual intervention. This uses logging to roll back any computation that occurred after a detected error, along with a set of techniques to provide error-checking parallelism while still preventing the escape of incorrect processor values in multicore environments, where ordering of individual processors' logs is not enough to be able to roll back execution. Across a set of single and multi-threaded benchmarks, we achieve 3.1\% and 1.5\% overhead respectively, compared with 1.9\% and 1\% for error detection alone.},
	eventtitle = {2019 49th Annual {IEEE}/{IFIP} International Conference on Dependable Systems and Networks ({DSN})},
	pages = {201--213},
	booktitle = {2019 49th Annual {IEEE}/{IFIP} International Conference on Dependable Systems and Networks ({DSN})},
	author = {Ainsworth, Sam and Jones, Timothy M.},
	urldate = {2024-10-31},
	date = {2019-06},
	note = {{ISSN}: 1530-0889},
	keywords = {Error correction, Error correction codes, Hardware, Multicore processing, Out of order, Parallel processing, fault tolerance, microarchitecture, error detection},
}

@inproceedings{swaminathan_bravo_2017,
	title = {{BRAVO}: Balanced Reliability-Aware Voltage Optimization},
	url = {https://ieeexplore.ieee.org/document/7920817},
	doi = {10.1109/HPCA.2017.56},
	shorttitle = {{BRAVO}},
	abstract = {Defining a processor micro-architecture for a targeted productspace involves multi-dimensional optimization across performance, power and reliability axes. A key decision in sucha definition process is the circuit-and technology-driven parameterof the nominal (voltage, frequency) operating point. This is a challenging task, since optimizing individually orpair-wise amongst these metrics usually results in a designthat falls short of the specification in at least one of the threedimensions. Aided by academic research, industry has nowadopted early-stage definition methodologies that considerboth energy-and performance-related metrics. Reliabilityrelatedenhancements, on the other hand, tend to get factoredin via a separate thread of activity. This task is typically pursuedwithout thorough pre-silicon quantifications of the energyor even the performance cost. In the late-{CMOS} designera, reliability needs to move from a post-silicon afterthoughtor validation-only effort to a pre-silicon definitionprocess. In this paper, we present {BRAVO}, a methodologyfor such reliability-aware design space exploration. {BRAVOis} supported by a multi-core simulation framework that integratesperformance, power and reliability modeling capability. Errors induced by both soft and hard fault incidence arecaptured within the reliability models. We introduce the notionof the Balanced Reliability Metric ({BRM}), that we useto evaluate overall reliability of the processor across soft andhard error incidences. We demonstrate up to 79\% improvementin reliability in terms of this metric, for only a 6\% dropin overall energy efficiency over design points that maximizeenergy efficiency. We also demonstrate several real-life usecaseapplications of {BRAVO} in an industrial setting.},
	eventtitle = {2017 {IEEE} International Symposium on High Performance Computer Architecture ({HPCA})},
	pages = {97--108},
	booktitle = {2017 {IEEE} International Symposium on High Performance Computer Architecture ({HPCA})},
	author = {Swaminathan, Karthik and Chandramoorthy, Nandhini and Cher, Chen-Yong and Bertran, Ramon and Buyuktosunoglu, Alper and Bose, Pradip},
	urldate = {2024-10-31},
	date = {2017-02},
	note = {{ISSN}: 2378-203X},
	keywords = {Industries, Integrated circuit reliability, Measurement, Power system reliability, Processor reliability, Reliability engineering, Threshold voltage, hard errors, optimal voltage, soft errors},
}

@inproceedings{powell_architectural_2009,
	location = {New York, {NY}, {USA}},
	title = {Architectural core salvaging in a multi-core processor for hard-error tolerance},
	isbn = {978-1-60558-526-0},
	url = {https://dl.acm.org/doi/10.1145/1555754.1555769},
	doi = {10.1145/1555754.1555769},
	series = {{ISCA} '09},
	abstract = {The incidence of hard errors in {CPUs} is a challenge for future multicore designs due to increasing total core area. Even if the location and nature of hard errors are known a priori, either at manufacture-time or in the field, cores with such errors must be disabled in the absence of hard-error tolerance. While caches, with their regular and repetitive structures, are easily covered against hard errors by providing spare arrays or spare lines, structures within a core are neither as regular nor as repetitive. Previous work has proposed microarchitectural core salvaging to exploit structural redundancy within a core and maintain functionality in the presence of hard errors. Unfortunately microarchitectural salvaging introduces complexity and may provide only limited coverage of core area against hard errors due to a lack of natural redundancy in the core.This paper makes a case for architectural core salvaging. We observe that even if some individual cores cannot execute certain operations, a {CPU} die can be instruction-set-architecture ({ISA}) compliant, that is execute all of the instructions required by its {ISA}, by exploiting natural cross-core redundancy. We propose using hardware to migrate offending threads to another core that can execute the operation. Architectural core salvaging can cover a large core area against faults, and be implemented by leveraging known techniques that minimize changes to the microarchitecture. We show it is possible to optimize architectural core salvaging such that the performance on a faulty die approaches that of a fault-free die--assuring significantly better performance than core disabling for many workloads and no worse performance than core disabling for the remainder.},
	pages = {93--104},
	booktitle = {Proceedings of the 36th annual international symposium on Computer architecture},
	publisher = {Association for Computing Machinery},
	author = {Powell, Michael D. and Biswas, Arijit and Gupta, Shantanu and Mukherjee, Shubhendu S.},
	urldate = {2024-10-31},
	date = {2009-06-20},
}

@inproceedings{leng_asymmetric_2020,
	title = {Asymmetric Resilience: Exploiting Task-Level Idempotency for Transient Error Recovery in Accelerator-Based Systems},
	url = {https://ieeexplore.ieee.org/document/9065577},
	doi = {10.1109/HPCA47549.2020.00014},
	shorttitle = {Asymmetric Resilience},
	abstract = {Accelerators make the task of building systems that are re-silient against transient errors like voltage noise and soft errors hard. Architects integrate accelerators into the system as black box third-party {IP} components. So a fault in one or more accelerators may threaten the system's reliability if there are no established failure semantics for how an error propagates from the accelerator to the main {CPU}. Existing solutions that assure system reliability come at the cost of sacrificing accelerator generality, efficiency, and incur significant overhead, even in the absence of errors. To over-come these drawbacks, we examine reliability management of accelerator systems via hardware-software co-design, coupling an efficient architecture design with compiler and run-time support, to cope with transient errors. We introduce asymmetric resilience that architects reliability at the system level, centered around a hardened {CPU}, rather than at the accelerator level. At runtime, the system exploits task-level idempotency to contain accelerator errors and use memory protection instead of taking checkpoints to mitigate over-heads. We also leverage the fact that errors rarely occur in systems, and exploit the trade-off between error recovery performance and improved error-free performance to enhance system efficiency. Using {GPUs}, which are at the fore-front of accelerator systems, we demonstrate how our system architecture manages reliability in both integrated and discrete systems, under voltage-noise and soft-error related faults, leading to extremely low overhead (less than 1\%) and substantial gains (20\% energy savings on average).},
	eventtitle = {2020 {IEEE} International Symposium on High Performance Computer Architecture ({HPCA})},
	pages = {44--57},
	booktitle = {2020 {IEEE} International Symposium on High Performance Computer Architecture ({HPCA})},
	author = {Leng, Jingwen and Buyuktosunoglu, Alper and Bertran, Ramon and Bose, Pradip and Chen, Quan and Guo, Minyi and Janapa Reddi, Vijay},
	urldate = {2024-10-31},
	date = {2020-02},
	note = {{ISSN}: 2378-203X},
	keywords = {Acceleration, Computer architecture, Reliability, Resilience, Runtime, Task analysis, Transient analysis},
}

@article{nomura_sampling_2011,
	title = {Sampling + {DMR}: practical and low-overhead permanent fault detection},
	volume = {39},
	issn = {0163-5964},
	url = {https://dl.acm.org/doi/10.1145/2024723.2000089},
	doi = {10.1145/2024723.2000089},
	shorttitle = {Sampling + {DMR}},
	abstract = {With technology scaling, manufacture-time and in-field permanent faults are becoming a fundamental problem. Multi-core architectures with spares can tolerate them by detecting and isolating faulty cores, but the required fault detection coverage becomes effectively 100\% as the number of permanent faults increases. Dual-modular redundancy({DMR}) can provide 100\% coverage without assuming device-level fault models, but its overhead is excessive.In this paper, we explore a simple and low-overhead mechanism we call Sampling-{DMR}: run in {DMR} mode for a small percentage (1\% of the time for example) of each periodic execution window (5 million cycles for example). Although Sampling-{DMR} can leave some errors undetected, we argue the permanent fault coverage is 100\% because it can detect all faults eventually. Sampling-{DMR} thus introduces a system paradigm of restricting all permanent faults' effects to small finite windows of error occurrence.We prove an ultimate upper bound exists on total missed errors and develop a probabilistic model to analyze the distribution of the number of undetected errors and detection latency. The model is validated using full gate-level fault injection experiments for an actual processor running full application software. Sampling-{DMR} outperforms conventional techniques in terms of fault coverage, sustains similar detection latency guarantees, and limits energy and performance overheads to less than 2\%.},
	pages = {201--212},
	number = {3},
	journaltitle = {{SIGARCH} Comput. Archit. News},
	author = {Nomura, Shuou and Sinclair, Matthew D. and Ho, Chen-Han and Govindaraju, Venkatraman and de Kruijf, Marc and Sankaralingam, Karthikeyan},
	urldate = {2024-10-31},
	date = {2011-06-04},
}

@online{noauthor_graphx_nodate,
	title = {{GraphX} - Spark 3.5.3 Documentation},
	url = {https://spark.apache.org/docs/latest/graphx-programming-guide.html},
	urldate = {2024-10-29},
}

@software{noauthor_appleturicreate_2024,
	title = {apple/turicreate},
	rights = {{BSD}-3-Clause},
	url = {https://github.com/apple/turicreate},
	abstract = {Turi Create simplifies the development of custom machine learning models.},
	publisher = {Apple},
	urldate = {2024-10-29},
	date = {2024-10-27},
	note = {original-date: 2017-12-01T00:42:04Z},
	keywords = {deep-learning, machine-learning, python},
}

@inproceedings{gonzalez_powergraph_2012,
	title = {{PowerGraph}: Distributed Graph-Parallel Computation on Natural Graphs},
	isbn = {978-1-931971-96-6},
	url = {https://www.usenix.org/conference/osdi12/technical-sessions/presentation/gonzalez},
	eventtitle = {10th {USENIX} Symposium on Operating Systems Design and Implementation ({OSDI} 12)},
	pages = {17--30},
	author = {Gonzalez, Joseph E. and Low, Yucheng and Gu, Haijie and Bickson, Danny and Guestrin, Carlos},
	urldate = {2024-10-23},
	date = {2012},
	langid = {english},
}

@inproceedings{gonzalez_graphx_2014,
	title = {{GraphX}: Graph Processing in a Distributed Dataflow Framework},
	isbn = {978-1-931971-16-4},
	url = {https://www.usenix.org/conference/osdi14/technical-sessions/presentation/gonzalez&sa=U&ei=iqWOVKmxBqafygPrqILQCA&ved=0CC4QuAIwA1AB&usg=AFQjCNHibMBth4tAjIBaqIgher5itftGmA},
	eventtitle = {11th {USENIX} Symposium on Operating Systems Design and Implementation ({OSDI} 14)},
	pages = {599--613},
	author = {Gonzalez, Joseph E. and Xin, Reynold S. and Dave, Ankur and Crankshaw, Daniel and Franklin, Michael J. and Stoica, Ion},
	urldate = {2024-10-28},
	date = {2014},
	langid = {english},
}

@inproceedings{roy_x-stream_2013,
	location = {New York, {NY}, {USA}},
	title = {X-Stream: edge-centric graph processing using streaming partitions},
	isbn = {978-1-4503-2388-8},
	url = {https://dl.acm.org/doi/10.1145/2517349.2522740},
	doi = {10.1145/2517349.2522740},
	series = {{SOSP} '13},
	abstract = {X-Stream is a system for processing both in-memory and out-of-core graphs on a single shared-memory machine. While retaining the scatter-gather programming model with state stored in the vertices, X-Stream is novel in (i) using an edge-centric rather than a vertex-centric implementation of this model, and (ii) streaming completely unordered edge lists rather than performing random access. This design is motivated by the fact that sequential bandwidth for all storage media (main memory, {SSD}, and magnetic disk) is substantially larger than random access bandwidth.We demonstrate that a large number of graph algorithms can be expressed using the edge-centric scatter-gather model. The resulting implementations scale well in terms of number of cores, in terms of number of I/O devices, and across different storage media. X-Stream competes favorably with existing systems for graph processing. Besides sequential access, we identify as one of the main contributors to better performance the fact that X-Stream does not need to sort edge lists during preprocessing.},
	pages = {472--488},
	booktitle = {Proceedings of the Twenty-Fourth {ACM} Symposium on Operating Systems Principles},
	publisher = {Association for Computing Machinery},
	author = {Roy, Amitabha and Mihailovic, Ivo and Zwaenepoel, Willy},
	urldate = {2024-10-28},
	date = {2013-11-03},
}

@inproceedings{malewicz_pregel_2010,
	location = {New York, {NY}, {USA}},
	title = {Pregel: a system for large-scale graph processing},
	isbn = {978-1-4503-0032-2},
	url = {https://dl.acm.org/doi/10.1145/1807167.1807184},
	doi = {10.1145/1807167.1807184},
	series = {{SIGMOD} '10},
	abstract = {Many practical computing problems concern large graphs. Standard examples include the Web graph and various social networks. The scale of these graphs - in some cases billions of vertices, trillions of edges - poses challenges to their efficient processing. In this paper we present a computational model suitable for this task. Programs are expressed as a sequence of iterations, in each of which a vertex can receive messages sent in the previous iteration, send messages to other vertices, and modify its own state and that of its outgoing edges or mutate graph topology. This vertex-centric approach is flexible enough to express a broad set of algorithms. The model has been designed for efficient, scalable and fault-tolerant implementation on clusters of thousands of commodity computers, and its implied synchronicity makes reasoning about programs easier. Distribution-related details are hidden behind an abstract {API}. The result is a framework for processing large graphs that is expressive and easy to program.},
	pages = {135--146},
	booktitle = {Proceedings of the 2010 {ACM} {SIGMOD} International Conference on Management of data},
	publisher = {Association for Computing Machinery},
	author = {Malewicz, Grzegorz and Austern, Matthew H. and Bik, Aart J.C and Dehnert, James C. and Horn, Ilan and Leiser, Naty and Czajkowski, Grzegorz},
	urldate = {2024-10-08},
	date = {2010-06-06},
}

@article{dean_mapreduce_2008,
	title = {{MapReduce}: simplified data processing on large clusters},
	volume = {51},
	issn = {0001-0782},
	url = {https://dl.acm.org/doi/10.1145/1327452.1327492},
	doi = {10.1145/1327452.1327492},
	abstract = {{MapReduce} is a programming model and an associated implementation for processing and generating large datasets that is amenable to a broad variety of real-world tasks. Users specify the computation in terms of a map and a reduce function, and the underlying runtime system automatically parallelizes the computation across large-scale clusters of machines, handles machine failures, and schedules inter-machine communication to make efficient use of the network and disks. Programmers find the system easy to use: more than ten thousand distinct {MapReduce} programs have been implemented internally at Google over the past four years, and an average of one hundred thousand {MapReduce} jobs are executed on Google's clusters every day, processing a total of more than twenty petabytes of data per day.},
	pages = {107--113},
	number = {1},
	journaltitle = {Commun. {ACM}},
	author = {Dean, Jeffrey and Ghemawat, Sanjay},
	urldate = {2024-10-25},
	date = {2008-01-01},
}

@inproceedings{shun_ligra_2013,
	location = {New York, {NY}, {USA}},
	title = {Ligra: a lightweight graph processing framework for shared memory},
	isbn = {978-1-4503-1922-5},
	url = {https://dl.acm.org/doi/10.1145/2442516.2442530},
	doi = {10.1145/2442516.2442530},
	series = {{PPoPP} '13},
	abstract = {There has been significant recent interest in parallel frameworks for processing graphs due to their applicability in studying social networks, the Web graph, networks in biology, and unstructured meshes in scientific simulation. Due to the desire to process large graphs, these systems have emphasized the ability to run on distributed memory machines. Today, however, a single multicore server can support more than a terabyte of memory, which can fit graphs with tens or even hundreds of billions of edges. Furthermore, for graph algorithms, shared-memory multicores are generally significantly more efficient on a per core, per dollar, and per joule basis than distributed memory systems, and shared-memory algorithms tend to be simpler than their distributed counterparts.In this paper, we present a lightweight graph processing framework that is specific for shared-memory parallel/multicore machines, which makes graph traversal algorithms easy to write. The framework has two very simple routines, one for mapping over edges and one for mapping over vertices. Our routines can be applied to any subset of the vertices, which makes the framework useful for many graph traversal algorithms that operate on subsets of the vertices. Based on recent ideas used in a very fast algorithm for breadth-first search ({BFS}), our routines automatically adapt to the density of vertex sets. We implement several algorithms in this framework, including {BFS}, graph radii estimation, graph connectivity, betweenness centrality, {PageRank} and single-source shortest paths. Our algorithms expressed using this framework are very simple and concise, and perform almost as well as highly optimized code. Furthermore, they get good speedups on a 40-core machine and are significantly more efficient than previously reported results using graph frameworks on machines with many more cores.},
	pages = {135--146},
	booktitle = {Proceedings of the 18th {ACM} {SIGPLAN} symposium on Principles and practice of parallel programming},
	publisher = {Association for Computing Machinery},
	author = {Shun, Julian and Blelloch, Guy E.},
	urldate = {2024-10-28},
	date = {2013-02-23},
}

@misc{low_distributed_2012,
	title = {Distributed {GraphLab}: A Framework for Machine Learning in the Cloud},
	url = {http://arxiv.org/abs/1204.6078},
	doi = {10.48550/arXiv.1204.6078},
	abstract = {While high-level data parallel frameworks, like {MapReduce}, simplify the design and implementation of large-scale data processing systems, they do not naturally or efficiently support many important data mining and machine learning algorithms and can lead to inefficient learning systems. To help fill this critical void, we introduced the {GraphLab} abstraction which naturally expresses asynchronous, dynamic, graph-parallel computation while ensuring data consistency and achieving a high degree of parallel performance in the shared-memory setting. In this paper, we extend the {GraphLab} framework to the substantially more challenging distributed setting while preserving strong data consistency guarantees. We develop graph based extensions to pipelined locking and data versioning to reduce network congestion and mitigate the effect of network latency. We also introduce fault tolerance to the {GraphLab} abstraction using the classic Chandy-Lamport snapshot algorithm and demonstrate how it can be easily implemented by exploiting the {GraphLab} abstraction itself. Finally, we evaluate our distributed implementation of the {GraphLab} abstraction on a large Amazon {EC}2 deployment and show 1-2 orders of magnitude performance gains over Hadoop-based implementations.},
	number = {{arXiv}:1204.6078},
	publisher = {{arXiv}},
	author = {Low, Yucheng and Gonzalez, Joseph and Kyrola, Aapo and Bickson, Danny and Guestrin, Carlos and Hellerstein, Joseph M.},
	urldate = {2024-10-23},
	date = {2012-04-26},
	eprinttype = {arxiv},
	eprint = {1204.6078},
	keywords = {Computer Science - Databases, Computer Science - Machine Learning},
}

@misc{36249,
	title = {{MapReduce}: The programming model and practice},
	url = {http://research.google.com/archive/papers/mapreduce-sigmetrics09-tutorial.pdf},
	author = {Zhao, Jerry and Pjesivac-Grbovic, Jelena},
	date = {2009},
}

@misc{36249,
	title = {{MapReduce}: The programming model and practice},
	url = {http://research.google.com/archive/papers/mapreduce-sigmetrics09-tutorial.pdf},
	author = {Zhao, Jerry and Pjesivac-Grbovic, Jelena},
	date = {2009},
}

@inproceedings{power2010piccolo,
	title = {Piccolo: Building fast, distributed programs with partitioned tables},
	booktitle = {9th {USENIX} symposium on operating systems design and implementation ({OSDI} 10)},
	author = {Power, Russell and Li, Jinyang},
	date = {2010},
}

@inproceedings{zaharia2010spark,
	title = {Spark: Cluster computing with working sets},
	booktitle = {2nd {USENIX} workshop on hot topics in cloud computing ({HotCloud} 10)},
	author = {Zaharia, Matei and Chowdhury, Mosharaf and Franklin, Michael J and Shenker, Scott and Stoica, Ion},
	date = {2010},
}

@article{jia_distributed_2017,
	title = {A distributed multi-{GPU} system for fast graph processing},
	volume = {11},
	issn = {2150-8097},
	url = {https://dl.acm.org/doi/10.14778/3157794.3157799},
	doi = {10.14778/3157794.3157799},
	abstract = {We present Lux, a distributed multi-{GPU} system that achieves fast graph processing by exploiting the aggregate memory bandwidth of multiple {GPUs} and taking advantage of locality in the memory hierarchy of multi-{GPU} clusters. Lux provides two execution models that optimize algorithmic efficiency and enable important {GPU} optimizations, respectively. Lux also uses a novel dynamic load balancing strategy that is cheap and achieves good load balance across {GPUs}. In addition, we present a performance model that quantitatively predicts the execution times and automatically selects the runtime configurations for Lux applications. Experiments show that Lux achieves up to 20X speedup over state-of-the-art shared memory systems and up to two orders of magnitude speedup over distributed systems.},
	pages = {297--310},
	number = {3},
	journaltitle = {Proc. {VLDB} Endow.},
	author = {Jia, Zhihao and Kwon, Yongkee and Shipman, Galen and {McCormick}, Pat and Erez, Mattan and Aiken, Alex},
	urldate = {2024-10-28},
	date = {2017-11-01},
}

@online{ArmCortexA78AECore,
	title = {Arm Cortex-A78AE Core Technical Reference Manual Revision r0p1},
	url = {https://developer.arm.com/documentation/101779/0001/Register-descriptions/AArch64-system-registers/CPUECTLR-EL1--CPU-Extended-Control-Register--EL1},
	urldate = {2024-10-25},
}

@online{ArmCortexX1Core,
	title = {Arm Cortex‑X1 Core Technical Reference Manual},
	url = {https://developer.arm.com/documentation/101433/0102/Register-descriptions/AArch64-system-registers/CPUECTLR-EL1--CPU-Extended-Control-Register--EL1-},
	urldate = {2024-10-25},
}

@inproceedings{jain_linearizing_2013,
	location = {New York, {NY}, {USA}},
	title = {Linearizing irregular memory accesses for improved correlated prefetching},
	isbn = {978-1-4503-2638-4},
	url = {https://dl.acm.org/doi/10.1145/2540708.2540730},
	doi = {10.1145/2540708.2540730},
	series = {{MICRO}-46},
	abstract = {This paper introduces the Irregular Stream Buffer ({ISB}), a prefetcher that targets irregular sequences of temporally correlated memory references. The key idea is to use an extra level of indirection to translate arbitrary pairs of correlated physical addresses into consecutive addresses in a new structural address space, which is visible only to the {ISB}. This structural address space allows the {ISB} to organize prefetching meta-data so that it is simultaneously temporally and spatially ordered, which produces technical benefits in terms of coverage, accuracy, and memory traffic overhead.We evaluate the {ISB} using the Marss full system simulator and the irregular memory-intensive programs of {SPEC} {CPU} 2006 for both single-core and multi-core systems. For example, on a single core, the {ISB} exhibits an average speedup of 23.1\% with 93.7\% accuracy, compared to 9.9\% speedup and 64.2\% accuracy for an idealized prefetcher that over-approximates the {STMS} prefetcher, the previous best temporal stream prefetcher; this {ISB} prefetcher uses 32 {KB} of on-chip storage and sees 8.4\% memory traffic overhead due to meta-data accesses. We also show that a hybrid prefetcher that combines a stride-prefetcher and an {ISB} with just 8 {KB} of on-chip storage exhibits 40.8\% speedup and 66.2\% accuracy.},
	pages = {247--259},
	booktitle = {Proceedings of the 46th Annual {IEEE}/{ACM} International Symposium on Microarchitecture},
	publisher = {Association for Computing Machinery},
	author = {Jain, Akanksha and Lin, Calvin},
	urldate = {2024-10-25},
	date = {2013-12-07},
}

@inproceedings{joseph_prefetching_1997,
	location = {New York, {NY}, {USA}},
	title = {Prefetching using Markov predictors},
	isbn = {978-0-89791-901-2},
	url = {https://dl.acm.org/doi/10.1145/264107.264207},
	doi = {10.1145/264107.264207},
	series = {{ISCA} '97},
	abstract = {Prefetching is one approach to reducing the latency of memory operations in modern computer systems. In this paper, we describe the Markov prefetcher. This prefetcher acts as an interface between the on-chip and off-chip cache, and can be added to existing computer designs. The Markov prefetcher is distinguished by prefetching multiple reference predictions from the memory subsystem, and then prioritizing the delivery of those references to the processor.This design results in a prefetching system that provides good coverage, is accurate and produces timely results that can be effectively used by the processor. In our cycle-level simulations, the Markov Prefetcher reduces the overall execution stalls due to instruction and data memory operations by an average of 54\% for various commercial benchmarks while only using two thirds the memory of a demand-fetch cache organization.},
	pages = {252--263},
	booktitle = {Proceedings of the 24th annual international symposium on Computer architecture},
	publisher = {Association for Computing Machinery},
	author = {Joseph, Doug and Grunwald, Dirk},
	urldate = {2024-10-25},
	date = {1997-05-01},
}

@article{smith_cache_1982,
	title = {Cache Memories},
	volume = {14},
	issn = {0360-0300},
	url = {https://dl.acm.org/doi/10.1145/356887.356892},
	doi = {10.1145/356887.356892},
	pages = {473--530},
	number = {3},
	journaltitle = {{ACM} Comput. Surv.},
	author = {Smith, Alan Jay},
	urldate = {2024-10-25},
	date = {1982-09-01},
}

@misc{ainsworth_triangel_2024,
	title = {Triangel: A High-Performance, Accurate, Timely On-Chip Temporal Prefetcher},
	url = {http://arxiv.org/abs/2406.10627},
	doi = {10.48550/arXiv.2406.10627},
	shorttitle = {Triangel},
	abstract = {Temporal prefetching, where correlated pairs of addresses are logged and replayed on repeat accesses, has recently become viable in commercial designs. Arm's latest processors include Correlating Miss Chaining prefetchers, which store such patterns in a partition of the on-chip cache. However, the state-of-the-art on-chip temporal prefetcher in the literature, Triage, features some design inconsistencies and inaccuracies that pose challenges for practical implementation. We first examine and design fixes for these inconsistencies to produce an implementable baseline. We then introduce Triangel, a prefetcher that extends Triage with novel sampling-based methodologies to allow it to be aggressive and timely when the prefetcher is able to handle observed long-term patterns, and to avoid inaccurate prefetches when less able to do so. Triangel gives a 26.4\% speedup compared to a baseline system with a conventional stride prefetcher alone, compared with 9.3\% for Triage at degree 1 and 14.2\% at degree 4. At the same time Triangel only increases memory traffic by 10\% relative to baseline, versus 28.5\% for Triage.},
	number = {{arXiv}:2406.10627},
	publisher = {{arXiv}},
	author = {Ainsworth, Sam and Mukhanov, Lev},
	urldate = {2024-10-25},
	date = {2024-06-15},
	eprinttype = {arxiv},
	eprint = {2406.10627},
	keywords = {Computer Science - Hardware Architecture},
}

@article{wu_practical_2022,
	title = {Practical Temporal Prefetching With Compressed On-Chip Metadata},
	volume = {71},
	issn = {1557-9956},
	url = {https://ieeexplore.ieee.org/document/9376935/?arnumber=9376935},
	doi = {10.1109/TC.2021.3065909},
	abstract = {Temporal prefetchers are powerful because they can prefetch irregular sequences of memory accesses, but temporal prefetchers are commercially infeasible because they store large amounts of metadata in {DRAM}. This article presents Triage, the first temporal data prefetcher that does not require off-chip metadata. Triage builds on two insights: (1) Metadata are not equally useful, so the less useful metadata need not be saved, and (2) for irregular workloads, it is more profitable to use portions of the {LLC} to store metadata than data. We also introduce novel schemes to identify useful metadata, to compress metadata, and to determine the fraction of the {LLC} to dedicate for metadata. Using an industrial-strength simulator running irregular workloads on a single-core system, we show that at a prefetch degree of 4, Triage improves performance by 41.1 percent compared to a baseline with no prefetching, whereas {BO}, a state-of-the-art prefetcher that uses only on-chip metadata, sees only 10.9 percent improvement. Compared with {MISB}, a temporal prefetcher that uses off-chip metadata, Triage provides a design alternative that reduces memory traffic by an order of magnitude (260.8 percent extra traffic for {MISB} at degree 1 versus 56.9 percent for Triage), while reducing coverage by 20 percent.},
	pages = {2858--2871},
	number = {11},
	journaltitle = {{IEEE} Transactions on Computers},
	author = {Wu, Hao and Nathella, Krishnendra and Pabst, Matthew and Sunwoo, Dam and Jain, Akanksha and Lin, Calvin},
	urldate = {2024-10-25},
	date = {2022-11},
	note = {Conference Name: {IEEE} Transactions on Computers},
	keywords = {Bandwidth, Correlation, Memory systems, Metadata, Organizations, Prefetching, Random access memory, System-on-chip, prefetching, temporal prefetching},
}

@online{standard_performance_evaluation_corporation_spec_nodate,
	title = {{SPEC} {CPU}® 2006 (Retired: January 2018)},
	url = {https://www.spec.org/cpu2006/},
	titleaddon = {{SPEC} {CPU}® 2006},
	author = {{\textbackslash}\{{\textbackslash}\{Standard Performance Evaluation Corporation{\textbackslash}\}{\textbackslash}\}},
	urldate = {2024-10-25},
}

@article{henning2006spec,
	title = {{SPEC} {CPU}2006 benchmark descriptions},
	volume = {34},
	pages = {1--17},
	number = {4},
	journaltitle = {{ACM} {SIGARCH} Computer Architecture News},
	author = {Henning, John L},
	date = {2006},
	note = {Publisher: {ACM} New York, {NY}, {USA}},
}

@inproceedings{wenisch_practical_2009,
	title = {Practical off-chip meta-data for temporal memory streaming},
	url = {https://ieeexplore.ieee.org/abstract/document/4798239},
	doi = {10.1109/HPCA.2009.4798239},
	abstract = {Prior research demonstrates that temporal memory streaming and related address-correlating prefetchers improve performance of commercial server workloads though increased memory level parallelism. Unfortunately, these prefetchers require large on-chip meta-data storage, making previously-proposed designs impractical. Hence, to improve practicality, researchers have sought ways to enable timely prefetch while locating meta-data entirely off-chip. Unfortunately, current solutions for off-chip meta-data increase memory traffic by over a factor of three. We observe three requirements to store meta-data off chip: minimal off-chip lookup latency, bandwidth-efficient meta-data updates, and off-chip lookup amortized over many prefetches. In this work, we show: (1) minimal off-chip meta-data lookup latency can be achieved through a hardware-managed main memory hash table, (2) bandwidth-efficient updates can be performed through probabilistic sampling of meta-data updates, and (3) off-chip lookup costs can be amortized by organizing meta-data to allow a single lookup to yield long prefetch sequences. Using these techniques, we develop sampled temporal memory streaming ({STMS}), a practical address-correlating prefetcher that keeps predictor meta-data in main memory while achieving 90\% of the performance potential of idealized on-chip meta-data storage.},
	eventtitle = {2009 {IEEE} 15th International Symposium on High Performance Computer Architecture},
	pages = {79--90},
	booktitle = {2009 {IEEE} 15th International Symposium on High Performance Computer Architecture},
	author = {Wenisch, Thomas F. and Ferdman, Michael and Ailamaki, Anastasia and Falsafi, Babak and Moshovos, Andreas},
	urldate = {2024-10-25},
	date = {2009-02},
	note = {{ISSN}: 2378-203X},
	keywords = {Bandwidth, Costs, Delay, Hardware, Organizing, Prefetching, Sampling methods, Table lookup, Throughput, Web server},
}

@inproceedings{wu_efficient_2019,
	location = {New York, {NY}, {USA}},
	title = {Efficient metadata management for irregular data prefetching},
	isbn = {978-1-4503-6669-4},
	url = {https://dl.acm.org/doi/10.1145/3307650.3322225},
	doi = {10.1145/3307650.3322225},
	series = {{ISCA} '19},
	abstract = {Temporal prefetchers have the potential to prefetch arbitrary memory access patterns, but they require large amounts of metadata that must typically be stored in {DRAM}. In 2013, the Irregular Stream Buffer ({ISB}), showed how this metadata could be cached on chip and managed implicitly by synchronizing its contents with that of the {TLB}. This paper reveals the inefficiency of that approach and presents a new metadata management scheme that uses a simple metadata prefetcher to feed the metadata cache. The result is the Managed {ISB} ({MISB}), a temporal prefetcher that significantly advances the state-of-the-art in terms of both traffic overhead and {IPC}.Using a highly accurate proprietary simulator for single-core workloads, and using the {ChampSim} simulator for multi-core workloads, we evaluate {MISB} on programs from the {SPEC} {CPU} 2006 and {CloudSuite} benchmarks suites. Our results show that for single-core workloads, {MISB} improves performance by 22.7\%, compared to 10.6\% for an idealized {STMS} and 4.5\% for a realistic {ISB}. {MISB} also significantly reduces off-chip traffic; for {SPEC}, {MISB}'s traffic overhead of 70\% is roughly one fifth of {STMS}'s (342\%) and one sixth of {ISB}'s (411\%). On 4-core multi-programmed workloads, {MISB} improves performance by 27.5\%, compared to 13.6\% for idealized {STMS}. For {CloudSuite}, {MISB} improves performance by 12.8\% (vs. 6.0\% for idealized {STMS}), while achieving a traffic reduction of 7 × (83.5\% for {MISB} vs. 572.3\% for {STMS}).},
	pages = {449--461},
	booktitle = {Proceedings of the 46th International Symposium on Computer Architecture},
	publisher = {Association for Computing Machinery},
	author = {Wu, Hao and Nathella, Krishnendra and Sunwoo, Dam and Jain, Akanksha and Lin, Calvin},
	urldate = {2024-10-25},
	date = {2019-06-22},
}

@inproceedings{nori_criticality_2018,
	title = {Criticality Aware Tiered Cache Hierarchy: A Fundamental Relook at Multi-Level Cache Hierarchies},
	url = {https://ieeexplore.ieee.org/abstract/document/8416821},
	doi = {10.1109/ISCA.2018.00019},
	shorttitle = {Criticality Aware Tiered Cache Hierarchy},
	abstract = {On-die caches are a popular method to help hide the main memory latency. However, it is difficult to build large caches without substantially increasing their access latency, which in turn hurts performance. To overcome this difficulty, on-die caches are typically built as a multi-level cache hierarchy. One such popular hierarchy that has been adopted by modern microprocessors is the three level cache hierarchy. Building a three level cache hierarchy enables a low average hit latency since most requests are serviced from faster inner level caches. This has motivated recent microprocessors to deploy large level-2 (L2) caches that can help further reduce the average hit latency. In this paper, we do a fundamental analysis of the popular three level cache hierarchy and understand its performance delivery using program criticality. Through our detailed analysis we show that the current trend of increasing L2 cache sizes to reduce average hit latency is, in fact, an inefficient design choice. We instead propose Criticality Aware Tiered Cache Hierarchy ({CATCH}) that utilizes an accurate detection of program criticality in hardware and using a novel set of inter-cache prefetchers ensures that on-die data accesses that lie on the critical path of execution are served at the latency of the fastest level-1 (L1) cache. The last level cache ({LLC}) serves the purpose of reducing slow memory accesses, thereby making the large L2 cache redundant for most applications. The area saved by eliminating the L2 cache can then be used to create more efficient processor configurations. Our simulation results show that {CATCH} outperforms the three level cache hierarchy with a large 1MB L2 and exclusive {LLC} by an average of 8.4\%, and a baseline with 256KB L2 and inclusive {LLC} by 10.3\%. We also show that {CATCH} enables a powerful framework to explore broad chip-level area, performance and power trade-offs in cache hierarchy design. Supported by {CATCH}, we evaluate radical architecture directions such as eliminating the L2 altogether and show that such architectures can yield 4.5\% performance gain over the baseline at nearly 30\% lesser area or improve the performance by 7.3\% at the same area while reducing energy consumption by 11\%.},
	eventtitle = {2018 {ACM}/{IEEE} 45th Annual International Symposium on Computer Architecture ({ISCA})},
	pages = {96--109},
	booktitle = {2018 {ACM}/{IEEE} 45th Annual International Symposium on Computer Architecture ({ISCA})},
	author = {Nori, Anant Vithal and Gaur, Jayesh and Rai, Siddharth and Subramoney, Sreenivas and Wang, Hong},
	urldate = {2024-10-25},
	date = {2018-06},
	note = {{ISSN}: 2575-713X},
	keywords = {Caching, Criticality, Hardware, Market research, Microprocessors, Out of order, Prefetching, Resource management, Servers},
}

@inproceedings{shahab_farewell_2018,
	title = {Farewell My Shared {LLC}! A Case for Private Die-Stacked {DRAM} Caches for Servers},
	url = {https://ieeexplore.ieee.org/abstract/document/8574569},
	doi = {10.1109/MICRO.2018.00052},
	abstract = {The slowdown in technology scaling mandates rethinking of conventional {CPU} architectures in a quest for higher performance and new capabilities. This work takes a step in this direction by questioning the value of on-chip shared last-level caches ({LLCs}) in server processors and argues for a better alternative. Shared {LLCs} have a number of limitations, including on-chip area constraints that limit storage capacity, long planar interconnect spans that increase access latency, and contention for the shared cache capacity that hurts performance under workload colocation. To overcome these limitations, we propose a Die-Stacked Private {LLC} Organization ({SILO}), which combines conventional on-chip private L1 (and optionally, L2) caches with a per-core private {LLC} in die-stacked {DRAM}. By stacking {LLC} slices directly above each core, {SILO} avoids long planar wire spans. The use of private caches inherently avoids inter-core cache contention. Last but not the least, engineering the {DRAM} for latency affords low access delays while still providing over 100MB of capacity per core in today's technology. Evaluation results show that {SILO} outperforms state-of-the-art conventional cache architectures on a range of scale-out and traditional workloads while delivering strong performance isolation under colocation.},
	eventtitle = {2018 51st Annual {IEEE}/{ACM} International Symposium on Microarchitecture ({MICRO})},
	pages = {559--572},
	booktitle = {2018 51st Annual {IEEE}/{ACM} International Symposium on Microarchitecture ({MICRO})},
	author = {Shahab, Amna and Zhu, Mingcan and Margaritov, Artemiy and Grot, Boris},
	urldate = {2024-10-25},
	date = {2018-10},
	keywords = {{DRAM}, Delays, Program processors, Random access memory, Sensitivity, Servers, System-on-chip, Web search, die stacking, last-level cache, private cache, server workloads},
}

@inproceedings{michaud_best-offset_2016,
	title = {Best-offset hardware prefetching},
	url = {https://ieeexplore.ieee.org/document/7446087},
	doi = {10.1109/HPCA.2016.7446087},
	abstract = {Hardware prefetching is an important feature of modern high-performance processors. When the application working set is too large to fit in on-chip caches, disabling hardware pre-fetchers may result in severe performance reduction. A new prefetcher was recently introduced, the Sandbox prefetcher, that tries to find dynamically the best prefetch offset using the sandbox method. The Sandbox prefetcher uses simple hardware and was shown to be quite effective. However, the sandbox method does not take into account prefetch timeliness. We propose an offset prefetcher with a new method for selecting the prefetch offset that takes into account prefetch timeliness. We show that our Best-Offset prefetcher outperforms the Sandbox prefetcher on the {SPEC} {CPU}2006 benchmarks, with equally simple hardware.},
	eventtitle = {2016 {IEEE} International Symposium on High Performance Computer Architecture ({HPCA})},
	pages = {469--480},
	booktitle = {2016 {IEEE} International Symposium on High Performance Computer Architecture ({HPCA})},
	author = {Michaud, Pierre},
	urldate = {2024-10-25},
	date = {2016-03},
	note = {{ISSN}: 2378-203X},
	keywords = {Benchmark testing, Hardware, History, Pollution, Prefetching, System-on-chip},
}

@article{jain_back_2016,
	title = {Back to the future: leveraging Belady's algorithm for improved cache replacement},
	volume = {44},
	issn = {0163-5964},
	url = {https://dl.acm.org/doi/10.1145/3007787.3001146},
	doi = {10.1145/3007787.3001146},
	shorttitle = {Back to the future},
	abstract = {Belady's algorithm is optimal but infeasible because it requires knowledge of the future. This paper explains how a cache replacement algorithm can nonetheless learn from Belady's algorithm by applying it to past cache accesses to inform future cache replacement decisions. We show that the implementation is surprisingly efficient, as we introduce a new method of efficiently simulating Belady's behavior, and we use known sampling techniques to compactly represent the long history information that is needed for high accuracy. For a 2MB {LLC}, our solution uses a 16KB hardware budget (excluding replacement state in the tag array). When applied to a memory-intensive subset of the {SPEC} 2006 {CPU} benchmarks, our solution improves performance over {LRU} by 8.4\%, as opposed to 6.2\% for the previous state-of-the-art. For a 4-core system with a shared 8MB {LLC}, our solution improves performance by 15.0\%, compared to 12.0\% for the previous state-of-the-art.},
	pages = {78--89},
	number = {3},
	journaltitle = {{SIGARCH} Comput. Archit. News},
	author = {Jain, Akanksha and Lin, Calvin},
	urldate = {2024-10-25},
	date = {2016-06-18},
}

@inproceedings{zhu_msrl_2023,
	title = {\{{MSRL}\}: Distributed Reinforcement Learning with Dataflow Fragments},
	isbn = {978-1-939133-35-9},
	url = {https://www.usenix.org/conference/atc23/presentation/zhu-huanzhou},
	shorttitle = {\{{MSRL}\}},
	eventtitle = {2023 {USENIX} Annual Technical Conference ({USENIX} {ATC} 23)},
	pages = {977--993},
	author = {Zhu, Huanzhou and Zhao, Bo and Chen, Gang and Chen, Weifeng and Chen, Yijie and Shi, Liang and Yang, Yaodong and Pietzuch, Peter and Chen, Lei},
	urldate = {2024-10-25},
	date = {2023},
	langid = {english},
}

@article{barham_pathways_2022,
	title = {Pathways: Asynchronous Distributed Dataflow for {ML}},
	volume = {4},
	url = {https://proceedings.mlsys.org/paper_files/paper/2022/hash/37385144cac01dff38247ab11c119e3c-Abstract.html},
	shorttitle = {Pathways},
	pages = {430--449},
	journaltitle = {Proceedings of Machine Learning and Systems},
	author = {Barham, Paul and Chowdhery, Aakanksha and Dean, Jeff and Ghemawat, Sanjay and Hand, Steven and Hurt, Daniel and Isard, Michael and Lim, Hyeontaek and Pang, Ruoming and Roy, Sudip and Saeta, Brennan and Schuh, Parker and Sepassi, Ryan and Shafey, Laurent and Thekkath, Chandu and Wu, Yonghui},
	urldate = {2024-10-25},
	date = {2022-04-22},
	langid = {english},
}

@inproceedings{moritz_ray_2018,
	title = {Ray: A Distributed Framework for Emerging \{{AI}\} Applications},
	isbn = {978-1-939133-08-3},
	url = {https://www.usenix.org/conference/osdi18/presentation/moritz},
	shorttitle = {Ray},
	eventtitle = {13th {USENIX} Symposium on Operating Systems Design and Implementation ({OSDI} 18)},
	pages = {561--577},
	author = {Moritz, Philipp and Nishihara, Robert and Wang, Stephanie and Tumanov, Alexey and Liaw, Richard and Liang, Eric and Elibol, Melih and Yang, Zongheng and Paul, William and Jordan, Michael I. and Stoica, Ion},
	urldate = {2024-10-25},
	date = {2018},
	langid = {english},
}

@inproceedings{yu_dynamic_2018,
	location = {New York, {NY}, {USA}},
	title = {Dynamic control flow in large-scale machine learning},
	isbn = {978-1-4503-5584-1},
	url = {https://dl.acm.org/doi/10.1145/3190508.3190551},
	doi = {10.1145/3190508.3190551},
	series = {{EuroSys} '18},
	abstract = {Many recent machine learning models rely on fine-grained dynamic control flow for training and inference. In particular, models based on recurrent neural networks and on reinforcement learning depend on recurrence relations, data-dependent conditional execution, and other features that call for dynamic control flow. These applications benefit from the ability to make rapid control-flow decisions across a set of computing devices in a distributed system. For performance, scalability, and expressiveness, a machine learning system must support dynamic control flow in distributed and heterogeneous environments.This paper presents a programming model for distributed machine learning that supports dynamic control flow. We describe the design of the programming model, and its implementation in {TensorFlow}, a distributed machine learning system. Our approach extends the use of dataflow graphs to represent machine learning models, offering several distinctive features. First, the branches of conditionals and bodies of loops can be partitioned across many machines to run on a set of heterogeneous devices, including {CPUs}, {GPUs}, and custom {ASICs}. Second, programs written in our model support automatic differentiation and distributed gradient computations, which are necessary for training machine learning models that use control flow. Third, our choice of non-strict semantics enables multiple loop iterations to execute in parallel across machines, and to overlap compute and I/O operations.We have done our work in the context of {TensorFlow}, and it has been used extensively in research and production. We evaluate it using several real-world applications, and demonstrate its performance and scalability.},
	pages = {1--15},
	booktitle = {Proceedings of the Thirteenth {EuroSys} Conference},
	publisher = {Association for Computing Machinery},
	author = {Yu, Yuan and Abadi, Martín and Barham, Paul and Brevdo, Eugene and Burrows, Mike and Davis, Andy and Dean, Jeff and Ghemawat, Sanjay and Harley, Tim and Hawkins, Peter and Isard, Michael and Kudlur, Manjunath and Monga, Rajat and Murray, Derek and Zheng, Xiaoqiang},
	urldate = {2024-10-25},
	date = {2018-04-23},
}

@inproceedings{murray2011ciel,
	title = {\{{CIEL}\}: A universal execution engine for distributed \{Data-Flow\} computing},
	booktitle = {8th {USENIX} symposium on networked systems design and implementation ({NSDI} 11)},
	author = {Murray, Derek G and Schwarzkopf, Malte and Smowton, Christopher and Smith, Steven and Madhavapeddy, Anil and Hand, Steven},
	date = {2011},
}

@inproceedings{abadi_computational_2017,
	location = {New York, {NY}, {USA}},
	title = {A computational model for {TensorFlow}: an introduction},
	isbn = {978-1-4503-5071-6},
	url = {https://dl.acm.org/doi/10.1145/3088525.3088527},
	doi = {10.1145/3088525.3088527},
	series = {{MAPL} 2017},
	shorttitle = {A computational model for {TensorFlow}},
	abstract = {{TensorFlow} is a powerful, programmable system for machine learning. This paper aims to provide the basics of a conceptual framework for understanding the behavior of {TensorFlow} models during training and inference: it describes an operational semantics, of the kind common in the literature on programming languages. More broadly, the paper suggests that a programming-language perspective is fruitful in designing and in explaining systems such as {TensorFlow}.},
	pages = {1--7},
	booktitle = {Proceedings of the 1st {ACM} {SIGPLAN} International Workshop on Machine Learning and Programming Languages},
	publisher = {Association for Computing Machinery},
	author = {Abadi, Martín and Isard, Michael and Murray, Derek G.},
	urldate = {2024-10-25},
	date = {2017-06-18},
}

@inproceedings{patterson1994have,
	title = {How to have a bad career in research/academia},
	booktitle = {Keynote, 1994 {USENIX} Symposium on Operating System Design and Implementation, http://www. cs. utah. edu/ ̃ lepreau/osdi/keynote/slides-1up. ps. gz},
	author = {Patterson, David A},
	date = {1994},
}

@online{jones_how_nodate,
	title = {How to Give a Great Research Talk},
	url = {https://simon.peytonjones.org/great-research-talk/},
	abstract = {Simon Peyton Jones’ personal website.},
	titleaddon = {Simon Peyton Jones},
	author = {Jones, Simon Peyton},
	urldate = {2024-10-25},
	langid = {english},
}

@misc{roscoe2007writing,
	title = {Writing reviews for systems conferences},
	author = {Roscoe, Timothy},
	date = {2007},
}

@article{keshav_how_2007,
	title = {How to read a paper},
	volume = {37},
	issn = {0146-4833},
	url = {https://dl.acm.org/doi/10.1145/1273445.1273458},
	doi = {10.1145/1273445.1273458},
	abstract = {Researchers spend a great deal of time reading research papers. However, this skill is rarely taught, leading to much wasted effort. This article outlines a practical and efficient three-pass method for reading research papers. I also describe how to use this method to do a literature survey.},
	pages = {83--84},
	number = {3},
	journaltitle = {{SIGCOMM} Comput. Commun. Rev.},
	author = {Keshav, S.},
	urldate = {2024-10-25},
	date = {2007-07-20},
}

@inproceedings{naithani_vector_2021,
	title = {Vector Runahead},
	url = {https://ieeexplore.ieee.org/document/9499866},
	doi = {10.1109/ISCA52012.2021.00024},
	abstract = {The memory wall places a significant limit on performance for many modern workloads. These applications feature complex chains of dependent, indirect memory accesses, which cannot be picked up by even the most advanced microar-chitectural prefetchers. The result is that current out-of-order superscalar processors spend the majority of their time stalled. While it is possible to build special-purpose architectures to exploit the fundamental memory-level parallelism, a microarchi-tectural technique to automatically improve their performance in conventional processors has remained elusive.Runahead execution is a tempting proposition for hiding latency in program execution. However, to achieve high memory-level parallelism, a standard runahead execution skips ahead of cache misses. In modern workloads, this means it only prefetches the first cache-missing load in each dependent chain. We argue that this is not a fundamental limitation. If runahead were instead to stall on cache misses to generate dependent chain loads, then it could regain performance if it could stall on many at once. With this insight, we present Vector Runahead, a technique that prefetches entire load chains and speculatively reorders scalar operations from multiple loop iterations into vector format to bring in many independent loads at once. Vectorization of the runahead instruction stream increases the effective fetch/decode bandwidth with reduced resource requirements, to achieve high degrees of memory-level parallelism at a much faster rate. Across a variety of memory-latency-bound indirect workloads, Vector Runahead achieves a 1.79× performance speedup on a large out-of-order superscalar system, significantly improving on state-of-the-art techniques.},
	eventtitle = {2021 {ACM}/{IEEE} 48th Annual International Symposium on Computer Architecture ({ISCA})},
	pages = {195--208},
	booktitle = {2021 {ACM}/{IEEE} 48th Annual International Symposium on Computer Architecture ({ISCA})},
	author = {Naithani, Ajeya and Ainsworth, Sam and Jones, Timothy M. and Eeckhout, Lieven},
	urldate = {2024-10-25},
	date = {2021-06},
	note = {{ISSN}: 2575-713X},
	keywords = {Bandwidth, {CPU}, Computer architecture, Out of order, Parallel processing, Prefetching, Program processors, Standards, microarchitecture, prefetching, runahead},
}

@software{gober_championship_2022,
	title = {The Championship Simulator: Architectural Simulation for Education and Competition},
	rights = {Apache-2.0},
	url = {https://github.com/ChampSim/ChampSim},
	shorttitle = {The Championship Simulator},
	abstract = {{ChampSim} is an open-source trace based simulator maintained at Texas A\&M University and through the support of the computer architecture community.},
	author = {Gober, Nathan and Chacon, Gino and Wang, Lei and Gratz, Paul V. and Jimenez, Daniel A. and Teran, Elvira and Pugsley, Seth and Kim, Jinchun},
	urldate = {2024-10-25},
	date = {2022},
	doi = {10.48550/arXiv.2210.14324},
	note = {original-date: 2017-06-30T05:41:50Z},
}

@article{faloutsos_power-law_1999,
	title = {On power-law relationships of the Internet topology},
	volume = {29},
	issn = {0146-4833},
	url = {https://dl.acm.org/doi/10.1145/316194.316229},
	doi = {10.1145/316194.316229},
	abstract = {Despite the apparent randomness of the Internet, we discover some surprisingly simple power-laws of the Internet topology. These power-laws hold for three snapshots of the Internet, between November 1997 and December 1998, despite a 45\% growth of its size during that period. We show that our power-laws fit the real data very well resulting in correlation coefficients of 96\% or higher.Our observations provide a novel perspective of the structure of the Internet. The power-laws describe concisely skewed distributions of graph properties such as the node outdegree. In addition, these power-laws can be used to estimate important parameters such as the average neighborhood size, and facilitate the design and the performance analysis of protocols. Furthermore, we can use them to generate and select realistic topologies for simulation purposes.},
	pages = {251--262},
	number = {4},
	journaltitle = {{SIGCOMM} Comput. Commun. Rev.},
	author = {Faloutsos, Michalis and Faloutsos, Petros and Faloutsos, Christos},
	urldate = {2024-10-23},
	date = {1999-08-30},
}

@article{valiant_bridging_1990,
	title = {A bridging model for parallel computation},
	volume = {33},
	issn = {0001-0782},
	url = {https://dl.acm.org/doi/10.1145/79173.79181},
	doi = {10.1145/79173.79181},
	abstract = {The success of the von Neumann model of sequential computation is attributable to the fact that it is an efficient bridge between software and hardware: high-level languages can be efficiently compiled on to this model; yet it can be effeciently implemented in hardware. The author argues that an analogous bridge between software and hardware in required for parallel computation if that is to become as widely used. This article introduces the bulk-synchronous parallel ({BSP}) model as a candidate for this role, and gives results quantifying its efficiency both in implementing high-level language features and algorithms, as well as in being implemented in hardware.},
	pages = {103--111},
	number = {8},
	journaltitle = {Commun. {ACM}},
	author = {Valiant, Leslie G.},
	urldate = {2024-10-23},
	date = {1990-08-01},
}

@inproceedings{lee_occamy_2023,
	title = {Occamy: Memory-efficient {GPU} Compiler for {DNN} Inference},
	url = {https://ieeexplore.ieee.org/abstract/document/10247839},
	doi = {10.1109/DAC56929.2023.10247839},
	shorttitle = {Occamy},
	abstract = {This work proposes Occamy, a new memory-efficient {DNN} compiler that reduces the memory usage of a {DNN} model without affecting its accuracy. For each {DNN} operation, Occamy analyzes the dimensions of input and output tensors, and their liveness within the operation. Across all the operations, Occamy analyzes liveness of all the tensors, generates a memory pool after calculating the maximum required memory size, and schedules when and where to place each tensor in the memory pool. Compared to {PyTorch}, on an integrated embedded {GPU} for six {DNNs}, Occamy reduces the memory usage by 34.6\% and achieves a geometric mean speedup of 1.25×.},
	eventtitle = {2023 60th {ACM}/{IEEE} Design Automation Conference ({DAC})},
	pages = {1--6},
	booktitle = {2023 60th {ACM}/{IEEE} Design Automation Conference ({DAC})},
	author = {Lee, Jaeho and Jeong, Shinnung and Song, Seungbin and Kim, Kunwoo and Choi, Heelim and Kim, Youngsok and Kim, Hanjun},
	urldate = {2024-10-21},
	date = {2023-07},
	keywords = {Analytical models, Design automation, Memory management, Runtime, Schedules, Scheduling algorithms, Tensors},
}

@article{zaruba_snitch_2021,
	title = {Snitch: A Tiny Pseudo Dual-Issue Processor for Area and Energy Efficient Execution of Floating-Point Intensive Workloads},
	volume = {70},
	issn = {1557-9956},
	url = {https://ieeexplore.ieee.org/document/9216552},
	doi = {10.1109/TC.2020.3027900},
	shorttitle = {Snitch},
	abstract = {Data-parallel applications, such as data analytics, machine learning, and scientific computing, are placing an ever-growing demand on floating-point operations per second on emerging systems. With increasing integration density, the quest for energy efficiency becomes the number one design concern. While dedicated accelerators provide high energy efficiency, they are over-specialized and hard to adjust to algorithmic changes. We propose an architectural concept that tackles the issues of achieving extreme energy efficiency while still maintaining high flexibility as a general-purpose compute engine. The key idea is to pair a tiny 10kGE (kilo gate equivalent) control core, called Snitch, with a double-precision floating-point unit ({FPU}) to adjust the compute to control ratio. While traditionally minimizing non-floating-point unit ({FPU}) area and achieving high floating-point utilization has been a trade-off, with Snitch, we achieve them both, by enhancing the {ISA} with two minimally intrusive extensions: stream semantic registers ({SSR}) and a floating-point repetition instruction ({FREP}). {SSRs} allow the core to implicitly encode load/store instructions as register reads/writes, eliding many explicit memory instructions. The {FREP} extension decouples the floating-point and integer pipeline by sequencing instructions from a micro-loop buffer. These {ISA} extensions significantly reduce the pressure on the core and free it up for other tasks, making Snitch and {FPU} effectively dual-issue at a minimal incremental cost of 3.2 percent. The two low overhead {ISA} extensions make Snitch more flexible than a contemporary vector processor lane, achieving a 2{\textbackslash}times2× energy-efficiency improvement. We have evaluated the proposed core and {ISA} extensions on an octa-core cluster in 22 nm technology. We achieve more than 6{\textbackslash}times6× multi-core speed-up and a 3.5{\textbackslash}times3.5× gain in energy efficiency on several parallel microkernels.},
	pages = {1845--1860},
	number = {11},
	journaltitle = {{IEEE} Transactions on Computers},
	author = {Zaruba, Florian and Schuiki, Fabian and Hoefler, Torsten and Benini, Luca},
	urldate = {2024-10-21},
	date = {2021-11},
	note = {Conference Name: {IEEE} Transactions on Computers},
	keywords = {Computer architecture, Hardware, Instruction sets, Kernel, {RISC}-V, Registers, Semantics, Task analysis, energy efficiency, general purpose, many-core},
}

@online{noauthor_meet_nodate,
	title = {Meet Snitch: the Small and Agile {RISC}-V Processor - {IEEE} Spectrum},
	url = {https://spectrum.ieee.org/snitch-riscv-processor-6x-faster},
	shorttitle = {Meet Snitch},
	abstract = {Tests suggest it is six times faster than other comparable processors},
	urldate = {2024-10-21},
	langid = {english},
}

@video{tobias_grosser_compilation_2024,
	title = {The Compilation Game},
	url = {https://www.youtube.com/watch?v=fZSXJzDMEc8},
	author = {{Tobias Grosser}},
	urldate = {2024-10-21},
	date = {2024-08-09},
}

@online{noauthor_prodigy_nodate,
	title = {Prodigy: Improving the Memory Latency of Data-Indirect Irregular Workloads Using Hardware-Software Co-Design {\textbar} {IEEE} Conference Publication {\textbar} {IEEE} Xplore},
	url = {https://ieeexplore.ieee.org/document/9407222},
	urldate = {2024-10-21},
}

@inproceedings{zhang_rnr_2020,
	title = {{RnR}: A Software-Assisted Record-and-Replay Hardware Prefetcher},
	url = {https://ieeexplore.ieee.org/document/9251959},
	doi = {10.1109/MICRO50266.2020.00057},
	shorttitle = {{RnR}},
	abstract = {Applications with irregular memory access patterns do not benefit well from the memory hierarchy as applications that have good locality do. Relatively high miss ratio and long memory access latency can cause the processor to stall and degrade system performance. Prefetching can help to hide the miss penalty by predicting which memory addresses will be accessed in the near future and issuing memory requests ahead of the time. However, software prefetchers add instruction overhead, whereas hardware prefetchers cannot efficiently predict irregular memory access sequences with high accuracy. Fortunately, in many important irregular applications (e.g., iterative solvers, graph algorithms, and sparse matrix-vector multiplication), memory access sequences repeat over multiple iterations or program phases. When the patterns are long, a conventional spatial-temporal prefetcher can not achieve high prefetching accuracy, but these repeating patterns can be identified by programmers.In this work, we propose a software-assisted hardware prefetcher that focuses on repeating irregular memory access patterns for data structures that cannot benefit from conventional hardware prefetchers. The key idea is to provide a programming interface to record cache miss sequence on the first appearance of a memory access pattern and prefetch through replaying the pattern on the following repeats. The proposed Record-and-Replay ({RnR}) prefetcher provides a lightweight software interface so that the programmers can specify in the application code: 1) which data structures have irregular memory accesses, 2) when to start the recording, and 3) when to start the replay (prefetching). This work evaluated three irregular workloads with different inputs. For the evaluated workloads and inputs, the proposed {RnR} prefetcher can achieve on average 2.16× speedup for graph applications and 2.91× speedup for an iterative solver with a sparse matrix-vector multiplication kernel. By leveraging the knowledge from the programmers, the proposed {RnR} prefetcher can achieve over 95\% prefetching accuracy and miss coverage.},
	eventtitle = {2020 53rd Annual {IEEE}/{ACM} International Symposium on Microarchitecture ({MICRO})},
	pages = {609--621},
	booktitle = {2020 53rd Annual {IEEE}/{ACM} International Symposium on Microarchitecture ({MICRO})},
	author = {Zhang, Chao and Zeng, Yuan and Shalf, John and Guo, Xiaochen},
	urldate = {2024-10-21},
	date = {2020-10},
	keywords = {Data structures, Hardware, Memory management, Prefetching, Software, Sparse matrices, System performance, hardware prefetcher, irregular memory access, iterative algorithm},
}

@inproceedings{wu_temporal_2019,
	location = {New York, {NY}, {USA}},
	title = {Temporal Prefetching Without the Off-Chip Metadata},
	isbn = {978-1-4503-6938-1},
	url = {https://dl.acm.org/doi/10.1145/3352460.3358300},
	doi = {10.1145/3352460.3358300},
	series = {{MICRO} '52},
	abstract = {Temporal prefetching offers great potential, but this potential is difficult to achieve because of the need to store large amounts of prefetcher metadata off chip. To reduce the latency and traffic of off-chip metadata accesses, recent advances in temporal prefetching have proposed increasingly complex mechanisms that cache and prefetch this off-chip metadata. This paper suggests a return to simplicity: We present a temporal prefetcher whose metadata resides entirely on chip. The key insights are (1) only a small portion of prefetcher metadata is important, and (2) for most workloads with irregular accesses, the benefits of an effective prefetcher outweigh the marginal benefits of a larger data cache. Thus, our solution, the Triage prefetcher, identifies important metadata and uses a portion of the {LLC} to store this metadata, and it dynamically partitions the {LLC} between data and metadata.Our empirical results show that when compared against spatial prefetchers that use only on-chip metadata, Triage performs well, achieving speedups on irregular subset of {SPEC}2006 of 23.5\% compared to 5.8\% for the previous state-of-the-art. When compared against state-of-the-art temporal prefetchers that use off-chip metadata, Triage sacrifices performance on single-core systems (23.5\% speedup vs. 34.7\% speedup), but its 62\% lower traffic overhead translates to better performance in bandwidth-constrained 16-core systems (6.2\% speedup vs. 4.3\% speedup).},
	pages = {996--1008},
	booktitle = {Proceedings of the 52nd Annual {IEEE}/{ACM} International Symposium on Microarchitecture},
	publisher = {Association for Computing Machinery},
	author = {Wu, Hao and Nathella, Krishnendra and Pusdesris, Joseph and Sunwoo, Dam and Jain, Akanksha and Lin, Calvin},
	urldate = {2024-10-21},
	date = {2019-10-12},
}

@inproceedings{bera_hermes_2022,
	title = {Hermes: Accelerating Long-Latency Load Requests via Perceptron-Based Off-Chip Load Prediction},
	url = {https://ieeexplore.ieee.org/document/9923900},
	doi = {10.1109/MICRO56248.2022.00015},
	shorttitle = {Hermes},
	abstract = {Long-latency load requests continue to limit the performance of modern high-performance processors. To increase the latency tolerance of a processor, architects have primarily relied on two key techniques: sophisticated data prefetchers and large on-chip caches. In this work, we show that: (1) even a sophisticated state-of-the-art prefetcher can only predict half of the off-chip load requests on average across a wide range of workloads, and (2) due to the increasing size and complexity of on-chip caches, a large fraction of the latency of an off-chip load request is spent accessing the on-chip cache hierarchy to solely determine that it needs to go off-chip. The goal of this work is to accelerate off-chip load requests by removing the on-chip cache access latency from their critical path. To this end, we propose a new technique called Hermes, whose key idea is to: (1) accurately predict which load requests might go off-chip, and (2) speculatively fetch the data required by the predicted off-chip loads directly from the main memory, while also concurrently accessing the cache hierarchy for such loads. To enable Hermes, we develop a new lightweight, perceptron-based off-chip load prediction technique that learns to identify off-chip load requests using multiple program features (e.g., sequence of program counters, byte offset of a load request). For every load request generated by the processor, the predictor observes a set of program features to predict whether or not the load would go off-chip. If the load is predicted to go off-chip, Hermes issues a speculative load request directly to the main memory controller once the load’s physical address is generated. If the prediction is correct, the load eventually misses the cache hierarchy and waits for the ongoing speculative load request to finish, and thus Hermes completely hides the on-chip cache hierarchy access latency from the critical path of the correctly-predicted off-chip load. Our extensive evaluation using a wide range of workloads shows that Hermes provides consistent performance improvement on top of a state-of-the-art baseline system across a wide range of configurations with varying core count, main memory bandwidth, high-performance data prefetchers, and on-chip cache hierarchy access latencies, while incurring only modest storage overhead. The source code of Hermes is freely available at: https://github.com/{CMU}-{SAFARI}/Hermes.},
	eventtitle = {2022 55th {IEEE}/{ACM} International Symposium on Microarchitecture ({MICRO})},
	pages = {1--18},
	booktitle = {2022 55th {IEEE}/{ACM} International Symposium on Microarchitecture ({MICRO})},
	author = {Bera, Rahul and Kanellopoulos, Konstantinos and Balachandran, Shankar and Novo, David and Olgun, Ataberk and Sadrosadat, Mohammad and Mutlu, Onur},
	urldate = {2024-10-21},
	date = {2022-10},
	keywords = {Bandwidth, Caching, Memory management, Microarchitecture, Perceptron, Prefetcher, Prefetching, Program processors, Source coding, System-on-chip},
}

@inproceedings{navarro-torres_berti_2022,
	title = {Berti: an Accurate Local-Delta Data Prefetcher},
	url = {https://ieeexplore.ieee.org/document/9923806},
	doi = {10.1109/MICRO56248.2022.00072},
	shorttitle = {Berti},
	abstract = {Data prefetching is a technique that plays a crucial role in modern high-performance processors by hiding long latency memory accesses. Several state-of-the-art hardware prefetchers exploit the concept of deltas, defined as the difference between the cache line addresses of two demand accesses. Existing delta prefetchers, such as best offset prefetching ({BOP}) and multi-lookahead prefetching ({MLOP}), train and predict future accesses based on global deltas. We observed that the use of global deltas results in missed opportunities to anticipate memory accesses.In this paper, we propose Berti, a first-level data cache prefetcher that selects the best local deltas, i.e., those that consider only demand accesses issued by the same instruction. Thanks to a high-confidence mechanism that precisely detects the timely local deltas with high coverage, Berti generates accurate prefetch requests. Then, it orchestrates the prefetch requests to the memory hierarchy, using the selected deltas.Our empirical results using {ChampSim} and {SPEC} {CPU}2017 and {GAP} workloads show that, with a storage overhead of just 2.55 {KB}, Berti improves performance by 8.5\% compared to a baseline {IP}-stride and 3.5\% compared to {IPCP}, a state-of-the-art prefetcher. Our evaluation also shows that Berti reduces dynamic energy at the memory hierarchy by 33.6\% compared to {IPCP}, thanks to its high prefetch accuracy.},
	eventtitle = {2022 55th {IEEE}/{ACM} International Symposium on Microarchitecture ({MICRO})},
	pages = {975--991},
	booktitle = {2022 55th {IEEE}/{ACM} International Symposium on Microarchitecture ({MICRO})},
	author = {Navarro-Torres, Agustín and Panda, Biswabandan and Alastruey-Benedé, Jesús and Ibáñez, Pablo and Viñals-Yúfera, Víctor and Ros, Alberto},
	urldate = {2024-10-21},
	date = {2022-10},
	keywords = {Bandwidth, Hardware, Microarchitecture, Multicore processing, Prefetching, Program processors, Random access memory, accuracy, data prefetching, first-level cache, hardware prefetching, local deltas, timeliness},
}

@video{cambridgecomputerlab_2020_2020,
	title = {2020 Wheeler Lecture: The Future of Microprocessors},
	url = {https://www.youtube.com/watch?v=R2SdSLCMKEA},
	shorttitle = {2020 Wheeler Lecture},
	abstract = {Expect laws, graphs and references to Star Wars in this, the department's 9th annual Wheeler Lecture. It looks at the history of microprocessors, how we got to where we are now, and what constraints there are on the future. The lecture is given by Dr Sophie Wilson, an alumna of the department. She co-designed, with her colleague Steve Furber, the {BBC} Microcomputer, {BBC} {BASIC} and the Acorn Assembler. They then went on to design the {ARM} processor, which originally powered Acorn's computers, and is now the core of virtually every mobile phone and tablet in the world.},
	author = {{CambridgeComputerLab}},
	urldate = {2024-10-21},
	date = {2020-05-21},
}

@video{strange_loop_conference_python_2022,
	title = {"Python Performance Matters" by Emery Berger (Strange Loop 2022)},
	url = {https://www.youtube.com/watch?v=vVUnCXKuNOg},
	abstract = {It's 2022. Moore's Law and Dennard scaling have run out of steam, making it harder than ever to achieve high performance - especially in Python. This talk first explains in detail the unique challenges that Python poses to programmers. It then presents Scalene, a novel high-performance {CPU}, {GPU} and memory profiler for Python that does many things that past Python profilers do not and cannot do. Scalene both runs orders of magnitude faster than other profilers while delivering more accurate and more actionable information that's especially valuable to Python programmers.

Emery Berger
Professor, University of Massachusetts Amherst
@emeryberger

Emery Berger is a Professor of Computer Sciences at the University of Massachusetts Amherst, the flagship campus of the {UMass} system. Professor Berger and his collaborators have built numerous widely adopted software systems including Hoard, a fast and scalable memory manager that accelerates multithreaded applications (on which the Mac {OS} X memory manager is based); {DieHard}/{DieHarder}, error-avoiding and secure memory managers that influenced Windows, and Coz, a "causal profiler" that ships with modern Linux distros. He is also the developer and maintainer of {CSrankings}.org. His honors include an {NSF} {CAREER} Award, Most Influential Paper Awards at {OOPSLA}, at {PLDI}, and {ASPLOS}; five {CACM} Research Highlights, and Best Paper Awards at {FAST}, {OOPSLA}, and {SOSP}; he is an {ACM} Fellow. Professor Berger served six years as an elected member of the {SIGPLAN} Executive Committee; a decade as Associate Editor of {TOPLAS}; he was Program Chair for {PLDI} 2016 and co-Program Chair of {ASPLOS} 2021.

------- Sponsored by: -------

Stream is the \# 1 Chat {API} for custom messaging apps. Activate your free 30-day trial to explore Stream Chat. https://gstrm.io/tsl},
	author = {{Strange Loop Conference}},
	urldate = {2024-10-21},
	date = {2022-10-06},
}

@video{strange_loop_conference_performance_2019,
	title = {"Performance Matters" by Emery Berger},
	url = {https://www.youtube.com/watch?v=r-TLSBdHe1A},
	abstract = {Performance clearly matters to users. For example, the most common software update on the {AppStore} is "Bug fixes and performance enhancements." Now that Moore's Law has ended, programmers have to work hard to get high performance for their applications. But why is performance hard to deliver?

I will first explain why current approaches to evaluating and optimizing performance don't work, especially on modern hardware and for modern applications. I then present two systems that address these challenges. Stabilizer is a tool that enables statistically sound performance evaluation, making it possible to understand the impact of optimizations and conclude things like the fact that the -O2 and -O3 optimization levels are indistinguishable from noise (sadly true).

Since compiler optimizations have run out of steam, we need better profiling support, especially for modern concurrent, multi-threaded applications. Coz is a new "causal profiler" that lets programmers optimize for throughput or latency, and which pinpoints and accurately predicts the impact of optimizations. Coz's approach unlocks previously unknown optimization opportunities. Guided by Coz, we improved the performance of Memcached (9\%), {SQLite} (25\%), and accelerated six other applications by as much as 68\%; in most cases, this involved modifying less than 10 lines of code and took under half an hour (without any prior understanding of the programs!). Coz now ships as part of standard Linux distros (apt install coz-profiler).

Emery Berger
University of Massachusetts Amherst
@emeryberger

Emery Berger is a Professor in the College of Information and Computer Sciences at the University of Massachusetts Amherst, the flagship campus of the {UMass} system. He graduated with a Ph.D. in Computer Science from the University of Texas at Austin in 2002. Professor Berger has been a Visiting Scientist at Microsoft Research (where he is currently on sabbatical), the University of Washington, and at the Universitat Politècnica de Catalunya ({UPC}) / Barcelona Supercomputing Center ({BSC}). Professor Berger's research spans programming languages, runtime systems, and operating systems, with a particular focus on systems that transparently improve reliability, security, and performance. He and his collaborators have created a number of influential software systems including Hoard, a fast and scalable memory manager that accelerates multithreaded applications (used by companies including British Telecom, Cisco, Crédit Suisse, Reuters, Royal Bank of Canada, {SAP}, and Tata, and on which the Mac {OS} X memory manager is based); {DieHard}, an error-avoiding memory manager that directly influenced the design of the Windows 7 Fault-Tolerant Heap; and {DieHarder}, a secure memory manager that was an inspiration for hardening changes made to the Windows 8 heap. His honors include a Microsoft Research Fellowship, an {NSF} {CAREER} Award, a Lilly Teaching Fellowship, the Distinguished Artifact Award for {PLDI} 2014, Most Influential Paper Awards at {OOPSLA}, {PLDI}, and {ASPLOS}, three {CACM} Research Highlights, a Google Research Award, a Microsoft {SEIF} Award, and Best Paper Awards at {FAST}, {OOPSLA}, and {SOSP}; he was named an {ACM} Distinguished Member in 2018. Professor Berger is currently serving his second term as an elected member of the {SIGPLAN} Executive Committee; he served for a decade (2007-2017) as Associate Editor of the {ACM} Transactions on Programming Languages and Systems, and was Program Chair for {PLDI} 2016.},
	author = {{Strange Loop Conference}},
	urldate = {2024-10-21},
	date = {2019-09-15},
}

@software{noauthor_opencomplquidditch_2024,
	title = {opencompl/Quidditch},
	rights = {Apache-2.0},
	url = {https://github.com/opencompl/Quidditch},
	abstract = {{IREE} compiler and runtime for Snitch},
	publisher = {opencompl},
	urldate = {2024-10-21},
	date = {2024-09-23},
	note = {original-date: 2024-05-01T15:49:40Z},
}

@unpublished{noauthor_2024-07-24_nodate,
	title = {2024-07-24 {\textbar} {ETH} {\textbar} An End-to-End Deep Learning Compiler for Occamy using {IREE} {\textbackslash}x26 {xDSL}},
	url = {https://docs.google.com/presentation/d/1tA33ChVxxLvBuDySzkLgr0svxMv-GNCNuknFc_cSj8M},
	urldate = {2024-10-21},
}

@software{noauthor_xdslprojectxdsl_2024,
	title = {xdslproject/xdsl},
	url = {https://github.com/xdslproject/xdsl},
	abstract = {A Python Compiler Design Toolkit},
	publisher = {xdslproject},
	urldate = {2024-10-21},
	date = {2024-10-21},
	note = {original-date: 2021-09-12T14:02:30Z},
}

@software{noauthor_riscvsail-riscv_2024,
	title = {riscv/sail-riscv},
	url = {https://github.com/riscv/sail-riscv},
	abstract = {Sail {RISC}-V model},
	publisher = {{RISC}-V},
	urldate = {2024-10-21},
	date = {2024-10-20},
	note = {original-date: 2018-11-27T15:24:33Z},
}

@video{llvm_2024_2024,
	title = {2024 {EuroLLVM} - How Slow is {MLIR}},
	url = {https://www.youtube.com/watch?v=7qvVMUSxqz4},
	abstract = {2024 European {LLVM} Developers' Meeting
https://llvm.org/devmtg/2024-04/
------
How Slow is {MLIR}
Speaker: Mehdi Amini, Jeff Niu
------
Slides: https://llvm.org/devmtg/2024-04/slide...
-----
This talk will dig into the performance aspects involved in implementing a compiler with {MLIR}. We’re interested here in the compile-time performance (the efficiency of the compiler implementation) instead of the generated code. We will go through implementation details of {MLIR} and quantify the cost of common operations (traversing or mutating the {IR}). We will then expose some anti-patterns that we unfortunately commonly see in {MLIR}-based compilers. Finally we will go through a few elements that are impacting the performance of the {IR}: for example the threading model of {MLIR}, how to use resources for zero-overhead management of large constants, taking advantage of the Properties custom storage on operations, or the aspect related to Type/Attribute intrinsic to the storage in the {MLIRContext}.
-----
Videos Edited by Bash Films: http://www.{BashFilms}.com},
	author = {{LLVM}},
	urldate = {2024-10-21},
	date = {2024-06-21},
}

@incollection{harris_7_2022,
	title = {7 - Microarchitecture},
	isbn = {978-0-12-820064-3},
	url = {https://www.sciencedirect.com/science/article/pii/B9780128200643000076},
	abstract = {This chapter discusses microarchitecture, particularly the design of three {RISC}-V processors: single-cycle, multicycle, and pipelined {RISC}-V processors that perform a subset of {RISC}-V instructions. It also discusses processor performance, dealing with data and control hazards, and advanced microarchitecture techniques, such as superscalar and out-of-order processors.},
	pages = {392--497},
	booktitle = {Digital Design and Computer Architecture},
	publisher = {Morgan Kaufmann},
	author = {Harris, Sarah L. and Harris, David},
	editor = {Harris, Sarah L. and Harris, David},
	urldate = {2024-10-19},
	date = {2022-01-01},
	doi = {10.1016/B978-0-12-820064-3.00007-6},
	keywords = {{RISC}-V, advanced microarchitecture, hazards, microarchitecture, multicycle, pipelined, processor, single-cycle},
}

@article{suguna_survey_2018,
	title = {Survey on power optimization techniques for low power {VLSI} circuit in deep submicron technology},
	volume = {9},
	pages = {1--15},
	number = {1},
	journaltitle = {International Journal of {VLSI} design and Communication Systems},
	author = {Suguna, T and Rani, M Janaki},
	date = {2018},
}

@online{cutress_intel_2016,
	title = {Intel Announces 7th Gen Kaby Lake},
	url = {https://www.anandtech.com/show/10610/intel-announces-7th-gen-kaby-lake-14nm-plus-six-notebook-skus-desktop-coming-in-january},
	author = {Cutress, Ian and Ganesh, T S},
	urldate = {2024-10-19},
	date = {2016-08-30},
}

@misc{intel_corporation_form_2016,
	title = {Form 10-K 2016},
	url = {https://www.sec.gov/Archives/edgar/data/50863/000005086317000012/a10kdocument12312016q4.htm},
	author = {Intel Corporation},
	date = {2016},
}

@inproceedings{lipp_meltdown_2018,
	title = {Meltdown: Reading kernel memory from user space},
	booktitle = {27th {USENIX} security symposium ({USENIX} security 18)},
	author = {Lipp, Moritz and Schwarz, Michael and Gruss, Daniel and Prescher, Thomas and Haas, Werner and Fogh, Anders and Horn, Jann and Mangard, Stefan and Kocher, Paul and Genkin, Daniel and Yarom, Yuval and Hamburg, Mike},
	date = {2018},
}

@inproceedings{kocher_spectre_2019,
	title = {Spectre attacks: Exploiting speculative execution},
	booktitle = {40th {IEEE} symposium on security and privacy (S\&P'19)},
	author = {Kocher, Paul and Horn, Jann and Fogh, Anders and Genkin, \{and\} Daniel and Gruss, Daniel and Haas, Werner and Hamburg, Mike and Lipp, Moritz and Mangard, Stefan and Prescher, Thomas and Schwarz, Michael and Yarom, Yuval},
	date = {2019},
}

@article{yeager_mips_1996,
	title = {The Mips R10000 superscalar microprocessor},
	volume = {16},
	issn = {1937-4143},
	url = {https://ieeexplore.ieee.org/document/491460},
	doi = {10.1109/40.491460},
	abstract = {The Mips R10000 is a dynamic, superscalar microprocessor that implements the 64-bit Mips 4 instruction set architecture. It fetches and decodes four instructions per cycle and dynamically issues them to five fully-pipelined, low-latency execution units. Instructions can be fetched and executed speculatively beyond branches. Instructions graduate in order upon completion. Although execution is out of order, the processor still provides sequential memory consistency and precise exception handling. The R10000 is designed for high performance, even in large, real-world applications with poor memory locality. With speculative execution, it calculates memory addresses and initiates cache refills early. Its hierarchical, nonblocking memory system helps hide memory latency with two levels of set-associative, write-back caches.},
	pages = {28--41},
	number = {2},
	journaltitle = {{IEEE} Micro},
	author = {Yeager, K.C.},
	urldate = {2024-10-19},
	date = {1996-04},
	note = {Conference Name: {IEEE} Micro},
	keywords = {Adaptive arrays, {CMOS} logic circuits, Delay, Design optimization, Logic arrays, Logic design, Microprocessors, Out of order, Pipelines, Registers},
}

@inproceedings{bachrach_chisel_2012,
	location = {New York, {NY}, {USA}},
	title = {Chisel: constructing hardware in a Scala embedded language},
	isbn = {978-1-4503-1199-1},
	url = {https://dl.acm.org/doi/10.1145/2228360.2228584},
	doi = {10.1145/2228360.2228584},
	series = {{DAC} '12},
	shorttitle = {Chisel},
	abstract = {In this paper we introduce Chisel, a new hardware construction language that supports advanced hardware design using highly parameterized generators and layered domain-specific hardware languages. By embedding Chisel in the Scala programming language, we raise the level of hardware design abstraction by providing concepts including object orientation, functional programming, parameterized types, and type inference. Chisel can generate a high-speed C++-based cycle-accurate software simulator, or low-level Verilog designed to map to either {FPGAs} or to a standard {ASIC} flow for synthesis. This paper presents Chisel, its embedding in Scala, hardware examples, and results for C++ simulation, Verilog emulation and {ASIC} synthesis.},
	pages = {1216--1225},
	booktitle = {Proceedings of the 49th Annual Design Automation Conference},
	publisher = {Association for Computing Machinery},
	author = {Bachrach, Jonathan and Vo, Huy and Richards, Brian and Lee, Yunsup and Waterman, Andrew and Avižienis, Rimas and Wawrzynek, John and Asanović, Krste},
	urldate = {2024-10-19},
	date = {2012-06-03},
}

@article{waterman_risc-v_2014,
	title = {The {RISC}-V instruction set manual, volume I: User-level {ISA}, version 2.0},
	pages = {4},
	journaltitle = {{EECS} Department, University of California, Berkeley, Tech. Rep. {UCB}/{EECS}-2014-54},
	author = {Waterman, Andrew and Lee, Yunsup and Patterson, David A and Asanovic, Krste},
	date = {2014},
}

@inproceedings{lei_reconfigurable_2024,
	title = {A Reconfigurable Fused Multiply-Accumulate For Miscellaneous Operators in Deep Neural Network},
	url = {https://ieeexplore.ieee.org/abstract/document/10558516},
	doi = {10.1109/ISCAS58744.2024.10558516},
	abstract = {In this paper, a novel general-purpose multiple-precision reconfigurable fused multiply-accumulate ({RE}-{FMA}) is proposed for deep neural network. Data pre-processing, post-processing, look-up-table ({LUT}) are added, and accumulate functions are enriched. In addition, the various tensor operations are performed individually, requiring only one data buffer. The tensor operations include matrix multiplication, softmax function, dot-product, quantized-add, max-pooling, average-pooling, etc. The {RE}-{FMA} flexibly combines the basic elements to accomplish the tensor operators with a smaller area compared to traditional {FMAs}. It also features high speed and energy efficiency. The {RE}-{FMA} has significant potential to accelerate neural network inference in resource-constrained devices. Experiment results show the {RE}-{FMA} with parallelism of N = 32 is able to operate at a maximum frequency of 625 {MHz}. The full-load power consumption and area are only 131.92 {mW} and 0.126 mm2. Compared to the sum of four dedicated operator hardware accelerators, the reductions are 19 \% and 25.6 \%, respectively.},
	eventtitle = {2024 {IEEE} International Symposium on Circuits and Systems ({ISCAS})},
	pages = {1--5},
	booktitle = {2024 {IEEE} International Symposium on Circuits and Systems ({ISCAS})},
	author = {Lei, Lei and Chen, Zhiming},
	urldate = {2024-10-19},
	date = {2024-05},
	note = {{ISSN}: 2158-1525},
	keywords = {Artificial neural networks, Computer architecture, Costs, Libraries, Parallel processing, Power demand, Tensors, deep neural network, fused multiply-accumulate, multiple-precision, reconfigurable, softmax, tensor operator},
}

@online{arm_power_nodate,
	title = {Power, performance, and area analysis},
	url = {https://developer.arm.com/documentation/102738/0100/Power--performance--and-area-analysis},
	titleaddon = {{PPA} analysis overview},
	author = {{ARM}},
	urldate = {2024-10-18},
}

@book{patterson_computer_2013,
	location = {San Francisco, {CA}, {USA}},
	edition = {5},
	title = {Computer Organization and Design, Fifth Edition: The Hardware/Software Interface},
	isbn = {0-12-407726-9},
	abstract = {The 5th edition of Computer Organization and Design moves forward into the post-{PC} era with new examples, exercises, and material highlighting the emergence of mobile computing and the cloud. This generational change is emphasized and explored with updated content featuring tablet computers, cloud infrastructure, and the {ARM} (mobile computing devices) and x86 (cloud computing) architectures. Because an understanding of modern hardware is essential to achieving good performance and energy efficiency, this edition adds a new concrete example, "Going Faster," used throughout the text to demonstrate extremely effective optimization techniques. Also new to this edition is discussion of the "Eight Great Ideas" of computer architecture. As with previous editions, a {MIPS} processor is the core used to present the fundamentals of hardware technologies, assembly language, computer arithmetic, pipelining, memory hierarchies and I/O. Instructors looking for4th Edition teaching materials should e-mail textbook@elsevier.com. Includes new examples, exercises, and material highlighting the emergence of mobile computing and the Cloud. Covers parallelism in depth with examples and content highlighting parallel hardware and software topics Features the Intel Core i7, {ARM} Cortex-A8 and {NVIDIA} Fermi {GPU} as real-world examples throughout the book Adds a new concrete example, "Going Faster," to demonstrate how understanding hardware can inspire software optimizations that improve performance by 200 times. Discusses and highlights the "Eight Great Ideas" of computer architecture: Performance via Parallelism; Performance via Pipelining; Performance via Prediction; Design for Moore's Law; Hierarchy of Memories; Abstraction to Simplify Design; Make the Common Case Fast; and Dependability via Redundancy. Includes a full set of updated and improved exercises.},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Patterson, David A. and Hennessy, John L.},
	date = {2013},
}

@article{burg_moores_2021,
	title = {Moore’s Law revisited through Intel chip density},
	volume = {16},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0256245},
	doi = {10.1371/journal.pone.0256245},
	abstract = {Gordon Moore famously observed that the number of transistors in state-of-the-art integrated circuits (units per chip) increases exponentially, doubling every 12–24 months. Analysts have debated whether simple exponential growth describes the dynamics of computer processor evolution. We note that the increase encompasses two related phenomena, integration of larger numbers of transistors and transistor miniaturization. Growth in the number of transistors per unit area, or chip density, allows examination of the evolution with a single measure. Density of Intel processors between 1959 and 2013 are consistent with a biphasic sigmoidal curve with characteristic times of 9.5 years. During each stage, transistor density increased at least tenfold within approximately six years, followed by at least three years with negligible growth rates. The six waves of transistor density increase account for and give insight into the underlying processes driving advances in processor manufacturing and point to future limits that might be overcome.},
	pages = {e0256245},
	number = {8},
	journaltitle = {{PLOS} {ONE}},
	shortjournal = {{PLOS} {ONE}},
	author = {Burg, David and Ausubel, Jesse H.},
	urldate = {2024-10-18},
	date = {2021-08-18},
	langid = {english},
	note = {Publisher: Public Library of Science},
	keywords = {Artificial intelligence, Autocorrelation, Evolutionary processes, Machine learning, Machine learning algorithms, Mathematical models, Microprocessors, Semiconductors},
}

@thesis{park_global_2008,
	title = {Global product development in semiconductor industry : Intel -- Tick-Tock product development cadence},
	rights = {M.I.T. theses are protected by  copyright. They may be viewed from this source for any purpose, but  reproduction or distribution in any format is prohibited without written  permission. See provided {URL} for inquiries about permission.},
	url = {https://dspace.mit.edu/handle/1721.1/43113},
	shorttitle = {Global product development in semiconductor industry},
	abstract = {This thesis investigates on changes in semiconductor industry's product development methodology by following Intel's product development from year 2000. Intel was challenged by customer's preference change, competitors new enhanced product, internet bubble burst economy, and miss steps in the business strategy. Dynamics of these challenges drove Intel to develop a new product strategy: Tick-Tock product cadence. The paper discusses reasons why Intel landed at the Tick-tock strategy and results how strong product portfolio Intel ended up constructing. The thesis further discusses how the new "Global Product Development" strategy evolves, which can take advantage of {TickTock} cadence and deliver it to the next level helped from the effective {GPD} and systems engineering deployment.},
	institution = {Massachusetts Institute of Technology},
	type = {Thesis},
	author = {Park, Cheolmin},
	urldate = {2024-10-18},
	date = {2008},
}

@inproceedings{zhao2020sonicboom,
	title = {Sonicboom: The 3rd generation berkeley out-of-order machine},
	volume = {5},
	pages = {1--7},
	booktitle = {Fourth workshop on computer architecture research with {RISC}-v},
	author = {Zhao, Jerry and Korpan, Ben and Gonzalez, Abraham and Asanovic, Krste},
	date = {2020},
}

@article{rupley_samsung_2019,
	title = {Samsung M3 Processor},
	volume = {39},
	issn = {1937-4143},
	url = {https://ieeexplore.ieee.org/document/8634890},
	doi = {10.1109/MM.2019.2897556},
	abstract = {The M3 Processor is Samsung's third-generation custom microarchitecture. As performance demands continue to grow, major design improvements are required. In this generation, the core is enhanced with a 6-wide microarchitecture, deeper out-of-order resources, and faster instructions. The M3 delivers a new level of performance to the Android eco-system.},
	pages = {37--44},
	number = {2},
	journaltitle = {{IEEE} Micro},
	author = {Rupley, Jeff and Burgess, Brad and Grayson, Brian and Zuraski, Gerald D},
	urldate = {2024-10-15},
	date = {2019-03},
	note = {Conference Name: {IEEE} Micro},
	keywords = {Bandwidth, Benchmark testing, Ecosystems, Microarchitecture, Microprocessors},
}

@article{davidson_celerity_2018,
	title = {The Celerity Open-Source 511-Core {RISC}-V Tiered Accelerator Fabric: Fast Architectures and Design Methodologies for Fast Chips},
	volume = {38},
	issn = {1937-4143},
	url = {https://ieeexplore.ieee.org/document/8344478},
	doi = {10.1109/MM.2018.022071133},
	shorttitle = {The Celerity Open-Source 511-Core {RISC}-V Tiered Accelerator Fabric},
	abstract = {Rapidly emerging workloads require rapidly developed chips. The Celerity 16-nm open-source {SoC} was implemented in nine months using an architectural trifecta to minimize development time: a general-purpose tier comprised of open-source Linux-capable {RISC}-V cores, a massively parallel tier comprised of a {RISC}-V tiled manycore array that can be scaled to arbitrary sizes, and a specialization tier that uses high-level synthesis ({HLS}) to create an algorithmic neural-network accelerator. These tiers are tied together with an efficient heterogeneous remote store programming model on top of a flexible partial global address space memory system.},
	pages = {30--41},
	number = {2},
	journaltitle = {{IEEE} Micro},
	author = {Davidson, Scott and Xie, Shaolin and Torng, Christopher and Al-Hawai, Khalid and Rovinski, Austin and Ajayi, Tutu and Vega, Luis and Zhao, Chun and Zhao, Ritchie and Dai, Steve and Amarnath, Aporva and Veluri, Bandhav and Gao, Paul and Rao, Anuj and Liu, Gai and Gupta, Rajesh K. and Zhang, Zhiru and Dreslinski, Ronald and Batten, Christopher and Taylor, Michael Bedford},
	urldate = {2024-10-15},
	date = {2018-03},
	note = {Conference Name: {IEEE} Micro},
	keywords = {Energy efficiency, Memory management, Open source software, Programming, Reduced instruction set computing, System-on-chip, hardware, microchips},
}

@article{doweck_inside_2017,
	title = {Inside 6th-Generation Intel Core: New Microarchitecture Code-Named Skylake},
	volume = {37},
	issn = {1937-4143},
	url = {https://ieeexplore.ieee.org/document/7924286},
	doi = {10.1109/MM.2017.38},
	shorttitle = {Inside 6th-Generation Intel Core},
	abstract = {Skylake's core, processor graphics, and system on chip were designed to meet a demanding set of requirements for a wide range of power-performance points. Its coherent fabric was designed to provide high-memory bandwidth from multiple memory sources. Skylake's power management, which includes Intel Speed Shift technology, was designed to provide the largest dynamic power range among prior Intel processors. The Intel Architecture core delivers higher power efficiency, higher frequency, and a wider dynamic power range, supporting smaller form factors. Skylake's Gen9 graphics provides new features designed to maximize energy efficiency and bring the best visual experience for gaming and media. Skylake offers a rich performance monitoring unit that enhances software developers' ability to optimize their applications.},
	pages = {52--62},
	number = {2},
	journaltitle = {{IEEE} Micro},
	author = {Doweck, Jack and Kao, Wen-Fu and Lu, Allen Kuan-yu and Mandelblat, Julius and Rahatekar, Anirudha and Rappoport, Lihu and Rotem, Efraim and Yasin, Ahmad and Yoaz, Adi},
	urldate = {2024-10-15},
	date = {2017-03},
	note = {Conference Name: {IEEE} Micro},
	keywords = {Bandwidth, Central Processing Unit, Dynamic range, {GPU}, Graphics, Graphics processing units, Intel Speed Shift, Microarchitecture, Performance evaluation, Ports (Computers), Skylake, Turbo, {eDRAM}, microarchitecture, performance measurements, performance monitoring, power management},
}

@article{celio_broom_2019,
	title = {{BROOM}: An Open-Source Out-of-Order Processor With Resilient Low-Voltage Operation in 28-nm {CMOS}},
	volume = {39},
	issn = {1937-4143},
	url = {https://ieeexplore.ieee.org/document/8634812},
	doi = {10.1109/MM.2019.2897782},
	shorttitle = {{BROOM}},
	abstract = {The Berkeley resilient out-of-order machine ({BROOM}) is a resilient, wide-voltage-range implementation of an open-source out-of-order ({OoO}) {RISC}-V processor implemented in an {ASIC} flow. A 28-nm test-chip contains a {BOOM} {OoO} core and a 1-{MiB} level-2 (L2) cache, enhanced with architectural error tolerance for low-voltage operation. It was implemented by using an agile design methodology, where the initial {OoO} architecture was transformed to perform well in a high-performance, low-leakage {CMOS} process, informed by synthesis, place, and route data by using foundry-provided standard-cell library and memory compiler. The two-person-team productivity was improved in part thanks to a number of open-source artifacts: The Chisel hardware construction language, the {RISC}-V instruction set architecture, the rocket-chip {SoC} generator, and the open-source {BOOM} core. The resulting chip, taped out using {TSMC}’s 28-nm {HPM} process, runs at 1.0 {GHz} at 0.9 V, and is able to operate down to 0.47 V.},
	pages = {52--60},
	number = {2},
	journaltitle = {{IEEE} Micro},
	author = {Celio, Christopher and Chiu, Pi-Feng and Asanović, Krste and Nikolić, Borivoje and Patterson, David},
	urldate = {2024-10-15},
	date = {2019-03},
	note = {Conference Name: {IEEE} Micro},
	keywords = {Agile software development, {CMOS} process, Design methodology, Generators, Open source software, Random access memory, Voltage control},
}

@online{noauthor_new_2019,
	title = {A New Golden Age for Computer Architecture – Communications of the {ACM}},
	url = {https://cacm.acm.org/research/a-new-golden-age-for-computer-architecture/},
	urldate = {2024-10-14},
	date = {2019-02-01},
	langid = {american},
}

@inproceedings{fuchs_accelerator_2019,
	title = {The Accelerator Wall: Limits of Chip Specialization},
	url = {https://ieeexplore.ieee.org/document/8675237},
	doi = {10.1109/HPCA.2019.00023},
	shorttitle = {The Accelerator Wall},
	abstract = {Specializing chips using hardware accelerators has become the prime means to alleviate the gap between the growing computational demands and the stagnating transistor budgets caused by the slowdown of {CMOS} scaling. Much of the benefits of chip specialization stems from optimizing a computational problem within a given chip's transistor budget. Unfortunately, the stagnation of the number of transistors available on a chip will limit the accelerator design optimization space, leading to diminishing specialization returns, ultimately hitting an accelerator wall. In this work, we tackle the question of what are the limits of future accelerators and chip specialization? We do this by characterizing how current accelerators depend on {CMOS} scaling, based on a physical modeling tool that we constructed using datasheets of thousands of chips. We identify key concepts used in chip specialization, and explore case studies to understand how specialization has progressed over time in different applications and chip platforms (e.g., {GPUs}, {FPGAs}, {ASICs})1. Utilizing these insights, we build a model which projects forward to see what future gains can and cannot be enabled from chip specialization. A quantitative analysis of specialization returns and technological boundaries is critical to help researchers understand the limits of accelerators and develop methods to surmount them.},
	eventtitle = {2019 {IEEE} International Symposium on High Performance Computer Architecture ({HPCA})},
	pages = {1--14},
	booktitle = {2019 {IEEE} International Symposium on High Performance Computer Architecture ({HPCA})},
	author = {Fuchs, Adi and Wentzlaff, David},
	urldate = {2024-10-14},
	date = {2019-02},
	note = {{ISSN}: 2378-203X},
	keywords = {Accelerator Wall, {CMOS} Scaling, Computer architecture, Field programmable gate arrays, Mathematical model, Measurement, Moore's Law, Semiconductor device modeling, Throughput, Transistors},
}

@article{esmaeilzadeh_dark_2012,
	title = {Dark Silicon and the End of Multicore Scaling},
	volume = {32},
	issn = {1937-4143},
	url = {https://ieeexplore.ieee.org/document/6175879},
	doi = {10.1109/MM.2012.17},
	abstract = {A key question for the microprocessor research and design community is whether scaling multicores will provide the performance and value needed to scale down many more technology generations. To provide a quantitative answer to this question, a comprehensive study that projects the speedup potential of future multicores and examines the underutilization of integration capacity—dark silicon—is timely and crucial.},
	pages = {122--134},
	number = {3},
	journaltitle = {{IEEE} Micro},
	author = {Esmaeilzadeh, Hadi and Blem, Emily and St. Amant, Renee and Sankaralingam, Karthikeyan and Burger, Doug},
	urldate = {2024-10-14},
	date = {2012-05},
	note = {Conference Name: {IEEE} Micro},
	keywords = {Benchmark testing, Microarchitecture, Moore's law, Multicore processing, Network topology, Performance evaluation, Silicon, Transistors, dark silicon, modeling, multicore, power, technology scaling},
}

@inproceedings{agarwal_clock_2000,
	title = {Clock rate versus {IPC}: the end of the road for conventional microarchitectures},
	url = {https://ieeexplore.ieee.org/document/854395},
	shorttitle = {Clock rate versus {IPC}},
	abstract = {The doubling microprocessor performance every three years has been the result of two factors: more transistors per chip and superlinear scaling of the processor dock with technology generation. Our results show that, due to both diminishing improvements in clock rates and poor wire scaling as semiconductor devices shrink, the achievable performance growth of conventional microarchitectures will slow substantially. In this paper, we describe technology-driven models for wire capacitance wire delay, and microarchitectural component delay. Using the results of these models, we measure the simulated performance-estimating both clock rate and {IPC}-of an aggressive out-of-order microarchitecture as it is scaled from a 250 nm technology to a 35 nm technology. We perform this analysis for three clock scaling targets and two microarchitecture scaling strategies: pipeline scaling and capacity scaling. We find that no scaling strategy permits annual performance improvements of better than 12.5\% which is far worse than the annual 50-60\% to which we have grown accustomed.},
	eventtitle = {Proceedings of 27th International Symposium on Computer Architecture ({IEEE} Cat. No.{RS}00201)},
	pages = {248--259},
	booktitle = {Proceedings of 27th International Symposium on Computer Architecture ({IEEE} Cat. No.{RS}00201)},
	author = {Agarwal, V. and Hrishikesh, M.S. and Keckler, S.W. and Burger, D.},
	urldate = {2024-10-14},
	date = {2000-06},
	note = {{ISSN}: 1063-6897},
	keywords = {Capacitance, Clocks, Delay, Microarchitecture, Microprocessors, Performance evaluation, Roads, Semiconductor devices, Transistors, Wire},
}

@inproceedings{bisbas_shared_2024,
	location = {New York, {NY}, {USA}},
	title = {A shared compilation stack for distributed-memory parallelism in stencil {DSLs}},
	volume = {3},
	isbn = {9798400703867},
	url = {https://dl.acm.org/doi/10.1145/3620666.3651344},
	doi = {10.1145/3620666.3651344},
	series = {{ASPLOS} '24},
	abstract = {Domain Specific Languages ({DSLs}) increase programmer productivity and provide high performance. Their targeted abstractions allow scientists to express problems at a high level, providing rich details that optimizing compilers can exploit to target current- and next-generation supercomputers. The convenience and performance of {DSLs} come with significant development and maintenance costs. The siloed design of {DSL} compilers and the resulting inability to benefit from shared infrastructure cause uncertainties around longevity and the adoption of {DSLs} at scale. By tailoring the broadly-adopted {MLIR} compiler framework to {HPC}, we bring the same synergies that the machine learning community already exploits across their {DSLs} (e.g. Tensorflow, {PyTorch}) to the finite-difference stencil {HPC} community. We introduce new {HPC}-specific abstractions for message passing targeting distributed stencil computations. We demonstrate the sharing of common components across three distinct {HPC} stencil-{DSL} compilers: Devito, {PSyclone}, and the Open Earth Compiler, showing that our framework generates high-performance executables based upon a shared compiler ecosystem.},
	pages = {38--56},
	booktitle = {Proceedings of the 29th {ACM} International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3},
	publisher = {Association for Computing Machinery},
	author = {Bisbas, George and Lydike, Anton and Bauer, Emilien and Brown, Nick and Fehr, Mathieu and Mitchell, Lawrence and Rodriguez-Canal, Gabriel and Jamieson, Maurice and Kelly, Paul H. J. and Steuwer, Michel and Grosser, Tobias},
	urldate = {2024-10-14},
	date = {2024-04-27},
}

@misc{fehr_sidekick_2024,
	title = {Sidekick compilation with {xDSL}},
	url = {http://arxiv.org/abs/2311.07422},
	doi = {10.48550/arXiv.2311.07422},
	abstract = {Traditionally, compiler researchers either conduct experiments within an existing production compiler or develop their own prototype compiler; both options come with trade-offs. On one hand, prototyping in a production compiler can be cumbersome, as they are often optimized for program compilation speed at the expense of software simplicity and development speed. On the other hand, the transition from a prototype compiler to production requires significant engineering work. To bridge this gap, we introduce the concept of sidekick compiler frameworks, an approach that uses multiple frameworks that interoperate with each other by leveraging textual interchange formats and declarative descriptions of abstractions. Each such compiler framework is specialized for specific use cases, such as performance or prototyping. Abstractions are by design shared across frameworks, simplifying the transition from prototyping to production. We demonstrate this idea with {xDSL}, a sidekick for {MLIR} focused on prototyping and teaching. {xDSL} interoperates with {MLIR} through a shared textual {IR} and the exchange of {IRs} through an {IR} Definition Language. The benefits of sidekick compiler frameworks are evaluated by showing on three use cases how {xDSL} impacts their development: teaching, {DSL} compilation, and rewrite system prototyping. We also investigate the trade-offs that {xDSL} offers, and demonstrate how we simplify the transition between frameworks using the {IRDL} dialect. With sidekick compilation, we envision a future in which engineers minimize the cost of development by choosing a framework built for their immediate needs, and later transitioning to production with minimal overhead.},
	number = {{arXiv}:2311.07422},
	publisher = {{arXiv}},
	author = {Fehr, Mathieu and Weber, Michel and Ulmann, Christian and Lopoukhine, Alexandre and Lücke, Martin and Degioanni, Théo and Steuwer, Michel and Grosser, Tobias},
	urldate = {2024-10-14},
	date = {2024-06-17},
	eprinttype = {arxiv},
	eprint = {2311.07422},
	keywords = {Computer Science - Programming Languages},
}

@inproceedings{ikarashi_exocompilation_2022,
	location = {New York, {NY}, {USA}},
	title = {Exocompilation for productive programming of hardware accelerators},
	isbn = {978-1-4503-9265-5},
	url = {https://dl.acm.org/doi/10.1145/3519939.3523446},
	doi = {10.1145/3519939.3523446},
	series = {{PLDI} 2022},
	abstract = {High-performance kernel libraries are critical to exploiting accelerators and specialized instructions in many applications. Because compilers are difficult to extend to support diverse and rapidly-evolving hardware targets, and automatic optimization is often insufficient to guarantee state-of-the-art performance, these libraries are commonly still coded and optimized by hand, at great expense, in low-level C and assembly. To better support development of high-performance libraries for specialized hardware, we propose a new programming language, Exo, based on the principle of exocompilation: externalizing target-specific code generation support and optimization policies to user-level code. Exo allows custom hardware instructions, specialized memories, and accelerator configuration state to be defined in user libraries. It builds on the idea of user scheduling to externalize hardware mapping and optimization decisions. Schedules are defined as composable rewrites within the language, and we develop a set of effect analyses which guarantee program equivalence and memory safety through these transformations. We show that Exo enables rapid development of state-of-the-art matrix-matrix multiply and convolutional neural network kernels, for both an embedded neural accelerator and x86 with {AVX}-512 extensions, in a few dozen lines of code each.},
	pages = {703--718},
	booktitle = {Proceedings of the 43rd {ACM} {SIGPLAN} International Conference on Programming Language Design and Implementation},
	publisher = {Association for Computing Machinery},
	author = {Ikarashi, Yuka and Bernstein, Gilbert Louis and Reinking, Alex and Genc, Hasan and Ragan-Kelley, Jonathan},
	urldate = {2024-10-14},
	date = {2022-06-09},
}

@article{ragan-kelley_halide_2017,
	title = {Halide: decoupling algorithms from schedules for high-performance image processing},
	volume = {61},
	issn = {0001-0782},
	url = {https://dl.acm.org/doi/10.1145/3150211},
	doi = {10.1145/3150211},
	shorttitle = {Halide},
	abstract = {Writing high-performance code on modern machines requires not just locally optimizing inner loops, but globally reorganizing computations to exploit parallelism and locality---doing things such as tiling and blocking whole pipelines to fit in cache. This is especially true for image processing pipelines, where individual stages do much too little work to amortize the cost of loading and storing results to and from off-chip memory. As a result, the performance difference between a naive implementation of a pipeline and one globally optimized for parallelism and locality is often an order of magnitude. However, using existing programming tools, writing high-performance image processing code requires sacrificing simplicity, portability, and modularity. We argue that this is because traditional programming models conflate the computations defining the algorithm with decisions about intermediate storage and the order of computation, which we call the schedule.We propose a new programming language for image processing pipelines, called Halide, that separates the algorithm from its schedule. Programmers can change the schedule to express many possible organizations of a single algorithm. The Halide compiler then synthesizes a globally combined loop nest for an entire algorithm, given a schedule. Halide models a space of schedules which is expressive enough to describe organizations that match or outperform state-of-the-art hand-written implementations of many computational photography and computer vision algorithms. Its model is simple enough to do so often in only a few lines of code, and small changes generate efficient implementations for x86, {ARM}, Graphics Processors ({GPUs}), and specialized image processors, all from a single algorithm.Halide has been public and open source for over four years, during which it has been used by hundreds of programmers to deploy code to tens of thousands of servers and hundreds of millions of phones, processing billions of images every day.},
	pages = {106--115},
	number = {1},
	journaltitle = {Commun. {ACM}},
	author = {Ragan-Kelley, Jonathan and Adams, Andrew and Sharlet, Dillon and Barnes, Connelly and Paris, Sylvain and Levoy, Marc and Amarasinghe, Saman and Durand, Frédo},
	urldate = {2024-10-14},
	date = {2017-12-27},
}

@article{liu_compiler_2022,
	title = {Compiler Optimization Parameter Selection Method Based on Ensemble Learning},
	volume = {11},
	doi = {10.3390/electronics11152452},
	abstract = {Iterative compilation based on machine learning can effectively predict a program’s compiler optimization parameters. Although having some limits, such as the low efficiency of optimization parameter search and prediction accuracy, machine learning-based solutions have been a frontier research field in the field of iterative compilation and have gained increasing attention. The research challenges are focused on learning algorithm selection, optimal parameter search, and program feature representation. For the existing problems, we propose an ensemble learning-based optimization parameter selection ({ELOPS}) method for the compiler. First, in order to further improve the optimization parameter search efficiency and accuracy, we proposed a multi-objective particle swarm optimization ({PSO}) algorithm to determine the optimal compiler parameters of the program. Second, we extracted the mixed features of the program through the feature-class relevance method, rather than using static or dynamic features alone. Finally, as the existing research usually uses a separate machine learning algorithm to build prediction models, an ensemble learning model using program features and optimization parameters was constructed to effectively predict compiler optimization parameters of the new program. Using standard performance evaluation corporation 2006 ({SPEC}2006) and {NAS} parallel benchmark ({NPB}) benchmarks as well as some typical scientific computing programs, we compared {ELOPS} with the existing methods. The experimental results showed that we can respectively achieve 1.29× and 1.26× speedup when using our method on two platforms, which are better results than those of existing methods.},
	pages = {2452},
	journaltitle = {Electronics},
	shortjournal = {Electronics},
	author = {Liu, Hui and Xu, Jinlong and Chen, Sen and Guo, Te},
	date = {2022-08-06},
}

@inproceedings{murray_naiad_2013,
	location = {New York, {NY}, {USA}},
	title = {Naiad: a timely dataflow system},
	isbn = {978-1-4503-2388-8},
	url = {https://dl.acm.org/doi/10.1145/2517349.2522738},
	doi = {10.1145/2517349.2522738},
	series = {{SOSP} '13},
	shorttitle = {Naiad},
	abstract = {Naiad is a distributed system for executing data parallel, cyclic dataflow programs. It offers the high throughput of batch processors, the low latency of stream processors, and the ability to perform iterative and incremental computations. Although existing systems offer some of these features, applications that require all three have relied on multiple platforms, at the expense of efficiency, maintainability, and simplicity. Naiad resolves the complexities of combining these features in one framework.A new computational model, timely dataflow, underlies Naiad and captures opportunities for parallelism across a wide class of algorithms. This model enriches dataflow computation with timestamps that represent logical points in the computation and provide the basis for an efficient, lightweight coordination mechanism.We show that many powerful high-level programming models can be built on Naiad's low-level primitives, enabling such diverse tasks as streaming data analysis, iterative machine learning, and interactive graph mining. Naiad outperforms specialized systems in their target application domains, and its unique features enable the development of new high-performance applications.},
	pages = {439--455},
	booktitle = {Proceedings of the Twenty-Fourth {ACM} Symposium on Operating Systems Principles},
	publisher = {Association for Computing Machinery},
	author = {Murray, Derek G. and {McSherry}, Frank and Isaacs, Rebecca and Isard, Michael and Barham, Paul and Abadi, Martín},
	urldate = {2024-10-08},
	date = {2013-11-03},
}

@book{jain_art_1991,
	location = {New York},
	edition = {1st edition},
	title = {The Art of Computer Systems Performance Analysis: Techniques for Experimental Design, Measurement, Simulation, and Modeling},
	isbn = {978-0-471-50336-1},
	shorttitle = {The Art of Computer Systems Performance Analysis},
	abstract = {The Art of Computer Systems Performance Analysis "At last, a welcome and needed text for computer professionals who require practical, ready-to-apply techniques for performance analysis. Highly recommended!" -Dr. Leonard Kleinrock University of California, Los Angeles "An entirely refreshing text which has just the right mixture of theory and real world practice. The book is ideal for both classroom instruction and self-study." -Dr. Raymond L. Pickholtz President, {IEEE} Communications Society "An extraordinarily comprehensive treatment of both theoretical and practical issues." -Dr. Jeffrey P. Buzen Internationally recognized performance analysis expert ". it is the most thorough book available to date" -Dr. Erol Gelenbe Université René Descartes, Paris ". an extraordinary book.. A worthy addition to the bookshelf of any practicing computer or communications engineer" -Dr. Vinton G. Cer??? Chairman, {ACM} {SIGCOMM} "This is an unusual object, a textbook that one wants to sit down and peruse. The prose is clear and fluent, but more important, it is witty." -Allison Mankin The Mitre Washington Networking Center Newsletter},
	pagetotal = {720},
	publisher = {Wiley},
	author = {Jain, Raj},
	date = {1991-04-30},
}

@book{gregg_systems_2013,
	location = {{USA}},
	edition = {1st},
	title = {Systems Performance: Enterprise and the Cloud},
	isbn = {978-0-13-339009-4},
	shorttitle = {Systems Performance},
	abstract = {The Complete Guide to Optimizing Systems Performance Written by the winner of the2013 {LISA} Award for Outstanding Achievement in System Administration Large-scale enterprise, cloud, and virtualized computing systems have introduced serious performance challenges. Now, internationally renowned performance expert Brendan Gregg has brought together proven methodologies, tools, and metrics for analyzing and tuning even the most complex environments. Systems Performance: Enterprise and the Cloud focuses on Linux and Unix performance, while illuminating performance issues that are relevant to all operating systems. Youll gain deep insight into how systems work and perform, and learn methodologies for analyzing and improving system and application performance. Gregg presents examples from bare-metal systems and virtualized cloud tenants running Linux-based Ubuntu, Fedora, {CentOS}, and the illumos-based Joyent {SmartOS} and {OmniTI} {OmniOS}. He systematically covers modern systems performance, including the traditional analysis of {CPUs}, memory, disks, and networks, and new areas including cloud computing and dynamic tracing. This book also helps you identify and fix the unknown unknowns of complex performance: bottlenecks that emerge from elements and interactions you were not aware of. The text concludes with a detailed case study, showing how a real cloud customer issue was analyzed from start to finish. Coverage includes Modern performance analysis and tuning: terminology, concepts, models, methods, and techniques Dynamic tracing techniques and tools, including examples of {DTrace}, {SystemTap}, and perf Kernel internals: uncovering what the {OS} is doing Using system observability tools, interfaces, and frameworks Understanding and monitoring application performance Optimizing {CPUs}: processors, cores, hardware threads, caches, interconnects, and kernel scheduling Memory optimization: virtual memory, paging, swapping, memory architectures, busses, address spaces, and allocators File system I/O, including caching Storage devices/controllers, disk I/O workloads, {RAID}, and kernel I/O Network-related performance issues: protocols, sockets, interfaces, and physical connections Performance implications of {OS} and hardware-based virtualization, and new issues encountered with cloud computing Benchmarking: getting accurate results and avoiding common mistakes This guide is indispensable for anyone who operates enterprise or cloud environments: system, network, database, and web admins; developers; and other professionals. For students and others new to optimization, it also provides exercises reflecting Greggs extensive instructional experience.},
	pagetotal = {792},
	publisher = {Prentice Hall Press},
	author = {Gregg, Brendan},
	date = {2013-09},
}

@book{crovella_internet_2006,
	location = {{USA}},
	title = {Internet Measurement: Infrastructure, Traffic and Applications},
	isbn = {978-0-470-01461-5},
	shorttitle = {Internet Measurement},
	publisher = {John Wiley \& Sons, Inc.},
	author = {Crovella, Mark and Krishnamurthy, Balachander},
	date = {2006-06},
}

@book{varghese_network_2004,
	location = {Amsterdam Boston},
	edition = {Illustrated edition},
	title = {Network Algorithmics: An Interdisciplinary Approach to Designing Fast Networked Devices},
	isbn = {978-0-12-088477-3},
	shorttitle = {Network Algorithmics},
	abstract = {In designing a network device, you make dozens of decisions that affect the speed with which it will perform―sometimes for better, but sometimes for worse. Network Algorithmics provides a complete, coherent methodology for maximizing speed while meeting your other design goals.Author George Varghese begins by laying out the implementation bottlenecks that are most often encountered at four disparate levels of implementation: protocol, {OS}, hardware, and architecture. He then derives 15 solid principles―ranging from the commonly recognized to the groundbreaking―that are key to breaking these bottlenecks.The rest of the book is devoted to a systematic application of these principles to bottlenecks found specifically in endnodes, interconnect devices, and specialty functions such as security and measurement that can be located anywhere along the network. This immensely practical, clearly presented information will benefit anyone involved with network implementation, as well as students who have made this work their goal.{FOR} {INSTRUCTORS}: To obtain access to the solutions manual for this title simply register on our textbook website (textbooks.elsevier.com)and request access to the Computer Science subject area. Once approved (usually within one business day) you will be able to access all of the instructor-only materials through the "Instructor Manual" link on this book's academic web page at textbooks.elsevier.com.Addresses the bottlenecks found in all kinds of network devices, (data copying, control transfer, demultiplexing, timers, and more) and offers ways to break {themPresents} techniques suitable specifically for endnodes, including Web {serversPresents} techniques suitable specifically for interconnect devices, including routers, bridges, and {gatewaysWritten} as a practical guide for implementers but full of valuable insights for students, teachers, and {researchersIncludes} end-of-chapter summaries and exercises},
	pagetotal = {492},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Varghese, George},
	date = {2004-12-01},
}

@book{hennessy_computer_2012,
	title = {Computer Architecture: A Quantitative Approach},
	isbn = {978-0-12-383872-8},
	shorttitle = {Computer Architecture},
	abstract = {Computer Architecture: A Quantitative Approach, Fifth Edition, explores the ways that software and technology in the cloud are accessed by digital media, such as cell phones, computers, tablets, and other mobile devices. The book, which became a part of Intel's 2012 recommended reading list for developers, covers the revolution of mobile computing. It also highlights the two most important factors in architecture today: parallelism and memory hierarchy. This fully updated edition is comprised of six chapters that follow a consistent framework: explanation of the ideas in each chapter; a crosscutting issues section, which presents how the concepts covered in one chapter connect with those given in other chapters; a putting it all together section that links these concepts by discussing how they are applied in real machine; and detailed examples of misunderstandings and architectural traps commonly encountered by developers and architects. Formulas for energy, static and dynamic power, integrated circuit costs, reliability, and availability are included. The book also covers virtual machines, {SRAM} and {DRAM} technologies, and new material on Flash memory. Other topics include the exploitation of instruction-level parallelism in high-performance processors, superscalar execution, dynamic scheduling and multithreading, vector architectures, multicore processors, and warehouse-scale computers ({WSCs}). There are updated case studies and completely new exercises. Additional reference appendices are available online. This book will be a valuable reference for computer architects, programmers, application developers, compiler and system software developers, computer system designers and application developers.   Part of Intel's 2012 Recommended Reading List for Developers Updated to cover the mobile computing revolution Emphasizes the two most important topics in architecture today: memory hierarchy and parallelism in all its forms. Develops common themes throughout each chapter: power, performance, cost, dependability, protection, programming models, and emerging trends ("What's Next") Includes three review appendices in the printed text. Additional reference appendices are available online. Includes updated Case Studies and completely new exercises.},
	pagetotal = {858},
	publisher = {Elsevier},
	author = {Hennessy, John L. and Patterson, David A.},
	date = {2012},
	langid = {english},
	keywords = {Computers / Computer Architecture},
}

@book{CaseMethodFastTrack,
	title = {Case method fast-track: a {RAD} approach},
	abstract = {From the Book: In writing this book I tried to achieve two different objectives. The first objective was to provide an overview of fast-track, the techniques it applies, and particularly the manage...},
	publisher = {Addison-Wesley Longman Publishing Co., Inc.},
	author = {Clegg, Dai and Barker, Richard},
	urldate = {2023-10-11},
	date = {1994},
}

@article{gustafsonReevaluatingAmdahlLaw1988,
	title = {Reevaluating Amdahl's law},
	volume = {31},
	issn = {0001-0782},
	doi = {10.1145/42411.42415},
	pages = {532--533},
	number = {5},
	journaltitle = {Communications of the {ACM}},
	shortjournal = {Commun. {ACM}},
	author = {Gustafson, John L.},
	urldate = {2024-04-13},
	date = {1988-05-01},
}

@inproceedings{lattner2004llvm,
	title = {{LLVM}: A compilation framework for lifelong program analysis \& transformation},
	pages = {75--86},
	booktitle = {International symposium on code generation and optimization, 2004. {CGO} 2004.},
	publisher = {{IEEE}},
	author = {Lattner, Chris and Adve, Vikram},
	date = {2004},
}

@online{witkowskiMooreLawDead,
	title = {'Moore's Law's dead,' Nvidia {CEO} Jensen Huang says in justifying gaming-card price hike},
	url = {https://www.marketwatch.com/story/moores-laws-dead-nvidia-ceo-jensen-says-in-justifying-gaming-card-price-hike-11663798618},
	abstract = {Nvidia Corp. Chief Executive Jensen Huang on Wednesday said he thinks it's going to be "a pretty terrific Q4 for Ada," the company's next-generation chip...},
	titleaddon = {{MarketWatch}},
	author = {Witkowski, Wallace},
	urldate = {2024-04-05},
	note = {Section: Industries},
}

@article{theisEndMooreLaw2017,
	title = {The End of Moore's Law: A New Beginning for Information Technology},
	volume = {19},
	issn = {1558-366X},
	url = {https://ieeexplore.ieee.org/abstract/document/7878935},
	doi = {10.1109/MCSE.2017.29},
	shorttitle = {The End of Moore's Law},
	abstract = {The insights contained in Gordon Moore's now famous 1965 and 1975 papers have broadly guided the development of semiconductor electronics for over 50 years. However, the field-effect transistor is approaching some physical limits to further miniaturization, and the associated rising costs and reduced return on investment appear to be slowing the pace of development. Far from signaling an end to progress, this gradual "end of Moore's law" will open a new era in information technology as the focus of research and development shifts from miniaturization of long-established technologies to the coordinated introduction of new devices, new integration technologies, and new architectures for computing.},
	pages = {41--50},
	number = {2},
	journaltitle = {Computing in Science \& Engineering},
	author = {Theis, Thomas N. and Wong, H.-S. Philip},
	urldate = {2024-04-05},
	date = {2017-03},
	note = {Conference Name: Computing in Science \& Engineering},
	keywords = {Algorithm design and analysis, Computer architecture, Field effect transistors, Memory management, Moore's Law, Random access memory, Scientific computing, Switching circuits, algorithms implemented in hardware, emerging technologies, introductory and survey, memory technologies, neural nets, scientific computing},
}

@inproceedings{mooreLithographyFutureMoore1995,
	title = {Lithography and the future of Moore's law},
	volume = {2439},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/2439/0000/Lithography-and-the-future-of-Moores-law/10.1117/12.209195.full},
	doi = {10.1117/12.209195},
	abstract = {The definition of"Moore's Law" has come to refer to almost anything related to the semiconductor industry that when plotted on semi-log paper approximates a straight line. I hesitate to review it's origins and by doing so restrict it's definition. However, today I will review the history and past performance relative to predictions and show where the advances have come from. I will leave the future performance up to you. Certainly continuing on the same slope doesn't get any easier. It presents a difficult challenge to the industry. The original paper that postulated the first version ofthe "law" was an article I wrote for the 3 5th anniversary issue {ofElectronics} Magazine in 1 965 . My assignment was to predict what was going to happen in the semiconductor components industry over the next ten years --to 1975 . In 1965 the integrated circuit was only a few years old and in many cases was not very well accepted. There was still a large contingent in the user community who wanted to design their own circuits and who considered the job of the semiconductor industry to be to supply them with transistors and diodes so they could get on with their jobs. I was trying to emphasize the fact that integrated circuits really did have an important role to play.},
	eventtitle = {Integrated Circuit Metrology, Inspection, and Process Control {IX}},
	pages = {2--17},
	booktitle = {Integrated Circuit Metrology, Inspection, and Process Control {IX}},
	publisher = {{SPIE}},
	author = {Moore, Gordon E.},
	urldate = {2024-04-05},
	date = {1995-05-22},
}

@book{pmbok,
	location = {Newtown Square, {PA}},
	title = {A Guide to the Project Management Body of Knowledge ({PMBOK}® Guide) – Seventh Edition and The Standard for Project Management},
	isbn = {978-1-935589-67-9},
	publisher = {Project Management Institute},
	author = {{Project Management Institute}},
	date = {2021},
}

@online{ZoteroYourPersonal,
	title = {Zotero {\textbar} Your personal research assistant},
	url = {https://www.zotero.org/},
	author = {Corporation for Digital Scholarship},
	urldate = {2023-10-07},
}

@online{OverleafOnlineLaTeX,
	title = {Overleaf, Online {LaTeX} Editor},
	url = {https://www.overleaf.com},
	abstract = {An online {LaTeX} editor that’s easy to use. No installation, real-time collaboration, version control, hundreds of {LaTeX} templates, and more.},
	author = {{WriteLaTeX} Limited},
	urldate = {2023-10-07},
	langid = {english},
}

@misc{beckManifestoAgileSoftware2001,
	title = {Manifesto for Agile Software Development},
	url = {http://www.agilemanifesto.org/},
	author = {Beck, Kent and Beedle, Mike and van Bennekum, Arie and Cockburn, Alistair and Cunningham, Ward and Fowler, Martin and Grenning, James and Highsmith, Jim and Hunt, Andrew and Jeffries, Ron and Kern, Jon and Marick, Brian and Martin, Robert C. and Mellor, Steve and Schwaber, Ken and Sutherland, Jeff and Thomas, Dave},
	date = {2001},
	note = {Publication Title: Manifesto for Agile Software Development},
	keywords = {imported},
}
